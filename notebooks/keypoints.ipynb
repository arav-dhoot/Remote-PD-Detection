{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (8.0.173)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (1.22.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (4.8.0.74)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (9.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (1.12.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (0.13.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (1.4.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: psutil in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from matplotlib>=3.2.2->ultralytics) (4.37.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from matplotlib>=3.2.2->ultralytics) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2022.2.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2022.6.15)\n",
      "Requirement already satisfied: typing-extensions in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aravdhoot/miniforge3/envs/ml_env/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.4 has a non-standard dependency specifier torch>=1.9.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('/Users/aravdhoot/Downloads/yolov8m-pose.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/50.jpg: 384x640 1 person, 182.8ms\n",
      "Speed: 1.1ms preprocess, 182.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model('/Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/50.jpg', save=True, show_labels=True, show_conf=True, line_width=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = '/Users/aravdhoot/Remote-PD-Detection/segmented_yolov8'\n",
    "frame_path = '/Users/aravdhoot/Remote-PD-Detection/frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_bg = Image.open('/Users/aravdhoot/Remote-PD-Detection/white.png')\n",
    "white_bg = np.array(white_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/610.jpg: 384x640 1 person, 128.6ms\n",
      "Speed: 1.3ms preprocess, 128.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/360.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.6ms preprocess, 121.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/200.jpg: 384x640 1 person, 128.0ms\n",
      "Speed: 0.8ms preprocess, 128.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/60.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/570.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.5ms preprocess, 127.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/410.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.8ms preprocess, 122.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/160.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.5ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/170.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.7ms preprocess, 123.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/400.jpg: 384x640 1 person, 125.2ms\n",
      "Speed: 0.6ms preprocess, 125.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/560.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.8ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/70.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.5ms preprocess, 121.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/210.jpg: 384x640 1 person, 136.2ms\n",
      "Speed: 0.7ms preprocess, 136.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/370.jpg: 384x640 1 person, 131.1ms\n",
      "Speed: 0.8ms preprocess, 131.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/600.jpg: 384x640 1 person, 128.5ms\n",
      "Speed: 0.7ms preprocess, 128.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/510.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/470.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/100.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/670.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.7ms preprocess, 127.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/300.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/260.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.5ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/710.jpg: 384x640 (no detections), 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/700.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.8ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/270.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/310.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.8ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/660.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/110.jpg: 384x640 1 person, 146.3ms\n",
      "Speed: 0.6ms preprocess, 146.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/460.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/500.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/10.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.6ms preprocess, 116.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/120.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.5ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/450.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/530.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/280.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.9ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/690.jpg: 384x640 1 person, 130.1ms\n",
      "Speed: 0.8ms preprocess, 130.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/20.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.6ms preprocess, 123.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/490.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/240.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.6ms preprocess, 125.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/320.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.8ms preprocess, 127.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/650.jpg: 384x640 1 person, 126.3ms\n",
      "Speed: 0.8ms preprocess, 126.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/640.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.8ms preprocess, 122.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/330.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.5ms preprocess, 122.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/250.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/480.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.6ms preprocess, 124.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/680.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.9ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/30.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.6ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/290.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.5ms preprocess, 121.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/520.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/440.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.7ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/130.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/180.jpg: 384x640 1 person, 126.1ms\n",
      "Speed: 0.8ms preprocess, 126.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/590.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.8ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/220.jpg: 384x640 1 person, 126.4ms\n",
      "Speed: 0.8ms preprocess, 126.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/340.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.8ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/630.jpg: 384x640 1 person, 156.3ms\n",
      "Speed: 0.8ms preprocess, 156.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/80.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.8ms preprocess, 116.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/140.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/430.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/550.jpg: 384x640 1 person, 129.4ms\n",
      "Speed: 0.7ms preprocess, 129.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/380.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/40.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.7ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/50.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/390.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.8ms preprocess, 123.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/540.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/420.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.9ms preprocess, 124.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/150.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.5ms preprocess, 123.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/620.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/90.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.6ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/350.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.8ms preprocess, 126.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/230.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/580.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/0.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.8ms preprocess, 116.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_6.mp4/190.jpg: 384x640 1 person, 127.9ms\n",
      "Speed: 0.8ms preprocess, 127.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/610.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.8ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/360.jpg: 384x640 1 person, 133.8ms\n",
      "Speed: 0.6ms preprocess, 133.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/200.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.7ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/60.jpg: 384x640 1 person, 124.1ms\n",
      "Speed: 0.6ms preprocess, 124.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/570.jpg: 384x640 1 person, 133.6ms\n",
      "Speed: 0.7ms preprocess, 133.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/410.jpg: 384x640 1 person, 128.9ms\n",
      "Speed: 1.0ms preprocess, 128.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/160.jpg: 384x640 1 person, 125.1ms\n",
      "Speed: 0.7ms preprocess, 125.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/170.jpg: 384x640 1 person, 125.2ms\n",
      "Speed: 0.7ms preprocess, 125.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/400.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/560.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.7ms preprocess, 117.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/70.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/210.jpg: 384x640 1 person, 124.1ms\n",
      "Speed: 0.6ms preprocess, 124.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/370.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.7ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/600.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/510.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.7ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/470.jpg: 384x640 1 person, 127.4ms\n",
      "Speed: 0.8ms preprocess, 127.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/100.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/670.jpg: 384x640 1 person, 141.0ms\n",
      "Speed: 0.7ms preprocess, 141.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/300.jpg: 384x640 1 person, 127.4ms\n",
      "Speed: 0.8ms preprocess, 127.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/260.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/710.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/700.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.6ms preprocess, 122.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/270.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.7ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/310.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.5ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/660.jpg: 384x640 1 person, 171.4ms\n",
      "Speed: 0.8ms preprocess, 171.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/110.jpg: 384x640 1 person, 134.3ms\n",
      "Speed: 0.7ms preprocess, 134.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/460.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/500.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/10.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.8ms preprocess, 118.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/120.jpg: 384x640 1 person, 148.3ms\n",
      "Speed: 1.1ms preprocess, 148.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/450.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.7ms preprocess, 121.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/530.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.7ms preprocess, 117.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/280.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/690.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.7ms preprocess, 116.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/20.jpg: 384x640 1 person, 127.4ms\n",
      "Speed: 0.7ms preprocess, 127.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/490.jpg: 384x640 1 person, 128.0ms\n",
      "Speed: 0.6ms preprocess, 128.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/240.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.7ms preprocess, 127.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/320.jpg: 384x640 1 person, 133.8ms\n",
      "Speed: 0.6ms preprocess, 133.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/650.jpg: 384x640 1 person, 162.8ms\n",
      "Speed: 0.8ms preprocess, 162.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/640.jpg: 384x640 1 person, 143.3ms\n",
      "Speed: 4.7ms preprocess, 143.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/330.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/250.jpg: 384x640 1 person, 150.0ms\n",
      "Speed: 0.6ms preprocess, 150.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/480.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.8ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/680.jpg: 384x640 1 person, 135.3ms\n",
      "Speed: 0.6ms preprocess, 135.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/30.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/290.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/520.jpg: 384x640 1 person, 131.1ms\n",
      "Speed: 0.6ms preprocess, 131.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/440.jpg: 384x640 1 person, 137.9ms\n",
      "Speed: 1.0ms preprocess, 137.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/130.jpg: 384x640 1 person, 149.9ms\n",
      "Speed: 0.8ms preprocess, 149.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/180.jpg: 384x640 1 person, 142.2ms\n",
      "Speed: 0.6ms preprocess, 142.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/590.jpg: 384x640 1 person, 146.4ms\n",
      "Speed: 0.9ms preprocess, 146.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/220.jpg: 384x640 1 person, 150.3ms\n",
      "Speed: 0.8ms preprocess, 150.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/340.jpg: 384x640 1 person, 148.8ms\n",
      "Speed: 0.8ms preprocess, 148.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/630.jpg: 384x640 1 person, 220.1ms\n",
      "Speed: 0.7ms preprocess, 220.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/80.jpg: 384x640 1 person, 166.5ms\n",
      "Speed: 0.6ms preprocess, 166.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/140.jpg: 384x640 1 person, 238.1ms\n",
      "Speed: 0.8ms preprocess, 238.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/430.jpg: 384x640 1 person, 278.5ms\n",
      "Speed: 0.7ms preprocess, 278.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/550.jpg: 384x640 1 person, 178.4ms\n",
      "Speed: 1.0ms preprocess, 178.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/380.jpg: 384x640 1 person, 152.5ms\n",
      "Speed: 2.4ms preprocess, 152.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/40.jpg: 384x640 1 person, 136.9ms\n",
      "Speed: 0.7ms preprocess, 136.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/50.jpg: 384x640 1 person, 155.0ms\n",
      "Speed: 0.9ms preprocess, 155.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/390.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.8ms preprocess, 125.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/540.jpg: 384x640 1 person, 129.2ms\n",
      "Speed: 0.7ms preprocess, 129.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/420.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/150.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.6ms preprocess, 123.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/620.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.5ms preprocess, 122.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/90.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.8ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/350.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.6ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/230.jpg: 384x640 1 person, 145.5ms\n",
      "Speed: 0.8ms preprocess, 145.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/580.jpg: 384x640 1 person, 142.5ms\n",
      "Speed: 0.7ms preprocess, 142.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/0.jpg: 384x640 1 person, 164.2ms\n",
      "Speed: 0.6ms preprocess, 164.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_24012022_7.mp4/190.jpg: 384x640 1 person, 206.3ms\n",
      "Speed: 0.8ms preprocess, 206.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/360.jpg: 384x640 1 person, 135.0ms\n",
      "Speed: 0.7ms preprocess, 135.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/200.jpg: 384x640 1 person, 137.1ms\n",
      "Speed: 0.7ms preprocess, 137.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/60.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.9ms preprocess, 119.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/160.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/170.jpg: 384x640 1 person, 142.5ms\n",
      "Speed: 0.8ms preprocess, 142.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/70.jpg: 384x640 1 person, 149.3ms\n",
      "Speed: 0.6ms preprocess, 149.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/210.jpg: 384x640 1 person, 148.8ms\n",
      "Speed: 0.7ms preprocess, 148.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/370.jpg: 384x640 1 person, 126.9ms\n",
      "Speed: 0.6ms preprocess, 126.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/100.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/300.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/260.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.8ms preprocess, 118.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/270.jpg: 384x640 1 person, 152.5ms\n",
      "Speed: 0.6ms preprocess, 152.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/310.jpg: 384x640 1 person, 125.2ms\n",
      "Speed: 0.8ms preprocess, 125.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/110.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/10.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.8ms preprocess, 128.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/120.jpg: 384x640 1 person, 139.6ms\n",
      "Speed: 0.7ms preprocess, 139.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/280.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.7ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/20.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/240.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.5ms preprocess, 119.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/320.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/330.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/250.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/30.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.7ms preprocess, 119.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/290.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.6ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/130.jpg: 384x640 1 person, 132.5ms\n",
      "Speed: 0.8ms preprocess, 132.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/180.jpg: 384x640 1 person, 162.7ms\n",
      "Speed: 0.8ms preprocess, 162.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/220.jpg: 384x640 1 person, 146.8ms\n",
      "Speed: 0.6ms preprocess, 146.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/340.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.8ms preprocess, 116.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/80.jpg: 384x640 1 person, 135.0ms\n",
      "Speed: 0.6ms preprocess, 135.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/140.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.7ms preprocess, 137.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/380.jpg: 384x640 1 person, 159.9ms\n",
      "Speed: 0.7ms preprocess, 159.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/40.jpg: 384x640 1 person, 162.2ms\n",
      "Speed: 0.6ms preprocess, 162.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/50.jpg: 384x640 1 person, 238.2ms\n",
      "Speed: 0.7ms preprocess, 238.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/150.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.9ms preprocess, 127.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/90.jpg: 384x640 1 person, 135.6ms\n",
      "Speed: 0.9ms preprocess, 135.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/350.jpg: 384x640 1 person, 154.0ms\n",
      "Speed: 0.6ms preprocess, 154.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/230.jpg: 384x640 1 person, 192.1ms\n",
      "Speed: 0.6ms preprocess, 192.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/0.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_13122021_5.mp4/190.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.6ms preprocess, 123.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/200.jpg: 384x640 2 persons, 137.2ms\n",
      "Speed: 0.6ms preprocess, 137.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/60.jpg: 384x640 1 person, 142.1ms\n",
      "Speed: 1.0ms preprocess, 142.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/160.jpg: 384x640 2 persons, 129.8ms\n",
      "Speed: 0.8ms preprocess, 129.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/170.jpg: 384x640 2 persons, 122.2ms\n",
      "Speed: 0.8ms preprocess, 122.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/70.jpg: 384x640 2 persons, 121.6ms\n",
      "Speed: 0.7ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/210.jpg: 384x640 2 persons, 119.2ms\n",
      "Speed: 0.7ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/100.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/260.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.7ms preprocess, 121.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/270.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/110.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.7ms preprocess, 119.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/10.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/120.jpg: 384x640 1 person, 128.0ms\n",
      "Speed: 0.6ms preprocess, 128.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/20.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/240.jpg: 384x640 2 persons, 116.1ms\n",
      "Speed: 0.5ms preprocess, 116.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/250.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.6ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/30.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.8ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/130.jpg: 384x640 1 person, 114.4ms\n",
      "Speed: 0.7ms preprocess, 114.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/180.jpg: 384x640 1 person, 114.5ms\n",
      "Speed: 0.7ms preprocess, 114.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/220.jpg: 384x640 2 persons, 119.2ms\n",
      "Speed: 0.7ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/80.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.7ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/140.jpg: 384x640 2 persons, 120.3ms\n",
      "Speed: 0.7ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/40.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.7ms preprocess, 127.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/50.jpg: 384x640 2 persons, 129.6ms\n",
      "Speed: 0.8ms preprocess, 129.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/150.jpg: 384x640 2 persons, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/90.jpg: 384x640 1 person, 137.6ms\n",
      "Speed: 0.6ms preprocess, 137.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/230.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/0.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_2.mp4/190.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/610.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.8ms preprocess, 122.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/360.jpg: 384x640 1 person, 129.9ms\n",
      "Speed: 0.6ms preprocess, 129.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/200.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.7ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/60.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.7ms preprocess, 126.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/570.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/410.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.9ms preprocess, 121.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/160.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.5ms preprocess, 122.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/170.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.8ms preprocess, 122.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/400.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.7ms preprocess, 122.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/560.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.6ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/70.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/210.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/370.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/600.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/510.jpg: 384x640 1 person, 129.4ms\n",
      "Speed: 0.8ms preprocess, 129.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/470.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.6ms preprocess, 125.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/100.jpg: 384x640 1 person, 129.9ms\n",
      "Speed: 0.8ms preprocess, 129.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/300.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.8ms preprocess, 128.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/260.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.7ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/270.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.8ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/310.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.5ms preprocess, 120.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/110.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.8ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/460.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/500.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.5ms preprocess, 117.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/10.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/120.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/450.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.5ms preprocess, 117.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/530.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.5ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/280.jpg: 384x640 1 person, 144.8ms\n",
      "Speed: 0.6ms preprocess, 144.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/20.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.6ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/490.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/240.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/320.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.5ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/650.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/640.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.5ms preprocess, 115.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/330.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/250.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.6ms preprocess, 122.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/480.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/30.jpg: 384x640 1 person, 132.2ms\n",
      "Speed: 0.5ms preprocess, 132.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/290.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.7ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/520.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.8ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/440.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/130.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.5ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/180.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/590.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.7ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/220.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/340.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.6ms preprocess, 124.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/630.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.6ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/80.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/140.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.9ms preprocess, 125.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/430.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/550.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/380.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.8ms preprocess, 123.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/40.jpg: 384x640 1 person, 131.5ms\n",
      "Speed: 0.8ms preprocess, 131.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/50.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.8ms preprocess, 116.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/390.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.7ms preprocess, 115.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/540.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/420.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.7ms preprocess, 115.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/150.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/620.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/90.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/350.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/230.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/580.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.8ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/0.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.5ms preprocess, 119.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_23.mp4/190.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/610.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.7ms preprocess, 117.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/360.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.6ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/200.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/980.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/770.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1030.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1150.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/60.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.5ms preprocess, 118.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/820.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/940.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1230.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.8ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/570.jpg: 384x640 2 persons, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1190.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/410.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.5ms preprocess, 119.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/160.jpg: 384x640 (no detections), 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/170.jpg: 384x640 (no detections), 135.2ms\n",
      "Speed: 0.5ms preprocess, 135.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1180.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/400.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.7ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/560.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.5ms preprocess, 115.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/950.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.5ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1220.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.6ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/830.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/70.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1140.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.5ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1020.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.6ms preprocess, 125.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/990.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.6ms preprocess, 120.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/760.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/210.jpg: 384x640 (no detections), 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/370.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.6ms preprocess, 122.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/600.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/840.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/920.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1090.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/510.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/470.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.5ms preprocess, 125.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/100.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.5ms preprocess, 120.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/880.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/670.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/300.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/260.jpg: 384x640 (no detections), 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/710.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.7ms preprocess, 126.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1050.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.7ms preprocess, 125.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1130.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.7ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1120.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1040.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.7ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/700.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.6ms preprocess, 122.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/270.jpg: 384x640 1 person, 146.9ms\n",
      "Speed: 0.8ms preprocess, 146.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/310.jpg: 384x640 (no detections), 124.4ms\n",
      "Speed: 0.5ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/890.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/660.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/110.jpg: 384x640 (no detections), 126.1ms\n",
      "Speed: 0.5ms preprocess, 126.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/460.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 1.6ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1080.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/500.jpg: 384x640 1 person, 141.4ms\n",
      "Speed: 0.7ms preprocess, 141.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/930.jpg: 384x640 1 person, 130.5ms\n",
      "Speed: 0.8ms preprocess, 130.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/850.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.7ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/10.jpg: 384x640 1 person, 114.1ms\n",
      "Speed: 0.5ms preprocess, 114.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/120.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/450.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.6ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/530.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.7ms preprocess, 120.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/900.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.6ms preprocess, 127.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/280.jpg: 384x640 (no detections), 128.3ms\n",
      "Speed: 0.6ms preprocess, 128.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/690.jpg: 384x640 1 person, 123.4ms\n",
      "Speed: 0.6ms preprocess, 123.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/860.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.6ms preprocess, 123.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/20.jpg: 384x640 1 person, 130.1ms\n",
      "Speed: 0.8ms preprocess, 130.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/490.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1110.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.7ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1070.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/730.jpg: 384x640 1 person, 129.9ms\n",
      "Speed: 0.6ms preprocess, 129.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/240.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.6ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/320.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.7ms preprocess, 123.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/650.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/640.jpg: 384x640 (no detections), 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/330.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.6ms preprocess, 125.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/250.jpg: 384x640 (no detections), 121.2ms\n",
      "Speed: 0.8ms preprocess, 121.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/720.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1060.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/480.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.8ms preprocess, 118.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1100.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.6ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/680.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.6ms preprocess, 123.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/30.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.5ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/870.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/290.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.6ms preprocess, 117.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/910.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/520.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.6ms preprocess, 125.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/440.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.7ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/130.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.7ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/180.jpg: 384x640 1 person, 137.3ms\n",
      "Speed: 0.5ms preprocess, 137.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1170.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.5ms preprocess, 120.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/590.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1010.jpg: 384x640 1 person, 160.2ms\n",
      "Speed: 0.6ms preprocess, 160.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/750.jpg: 384x640 1 person, 129.6ms\n",
      "Speed: 0.8ms preprocess, 129.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/220.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.9ms preprocess, 127.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/340.jpg: 384x640 1 person, 128.1ms\n",
      "Speed: 0.8ms preprocess, 128.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/630.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/80.jpg: 384x640 1 person, 156.2ms\n",
      "Speed: 0.6ms preprocess, 156.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/140.jpg: 384x640 (no detections), 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/430.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.8ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/550.jpg: 384x640 1 person, 114.1ms\n",
      "Speed: 0.6ms preprocess, 114.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/790.jpg: 384x640 1 person, 148.9ms\n",
      "Speed: 0.7ms preprocess, 148.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1210.jpg: 384x640 1 person, 171.0ms\n",
      "Speed: 0.6ms preprocess, 171.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/960.jpg: 384x640 1 person, 125.1ms\n",
      "Speed: 0.8ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/380.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.6ms preprocess, 123.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/800.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.6ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/40.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.7ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/50.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/810.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 1.0ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/390.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.6ms preprocess, 117.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/780.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.5ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1200.jpg: 384x640 1 person, 113.8ms\n",
      "Speed: 0.5ms preprocess, 113.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/970.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/540.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.7ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/420.jpg: 384x640 1 person, 135.9ms\n",
      "Speed: 0.6ms preprocess, 135.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/150.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.6ms preprocess, 123.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/620.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.6ms preprocess, 123.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/90.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.7ms preprocess, 120.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/350.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/230.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.5ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/740.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/580.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1000.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/1160.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/0.jpg: 384x640 (no detections), 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_22.mp4/190.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/610.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.7ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/360.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.5ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/200.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/60.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/570.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.5ms preprocess, 119.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/410.jpg: 384x640 (no detections), 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/160.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/170.jpg: 384x640 1 person, 114.0ms\n",
      "Speed: 0.8ms preprocess, 114.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/400.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/560.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/70.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.5ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/210.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/370.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.7ms preprocess, 122.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/600.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/510.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/470.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/100.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/670.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.7ms preprocess, 122.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/300.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/260.jpg: 384x640 1 person, 126.5ms\n",
      "Speed: 1.2ms preprocess, 126.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/710.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.6ms preprocess, 125.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/700.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/270.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/310.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.5ms preprocess, 116.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/660.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.8ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/110.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/460.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/500.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/10.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/120.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/450.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.5ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/530.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.6ms preprocess, 126.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/280.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/690.jpg: 384x640 2 persons, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/20.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/490.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/240.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.8ms preprocess, 122.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/320.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/650.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.7ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/640.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/330.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/250.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/480.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.5ms preprocess, 118.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/680.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/30.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.5ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/290.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.7ms preprocess, 122.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/520.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.6ms preprocess, 122.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/440.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.5ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/130.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/180.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/590.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.7ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/220.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.6ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/340.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.7ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/630.jpg: 384x640 1 person, 114.3ms\n",
      "Speed: 0.6ms preprocess, 114.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/80.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/140.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.5ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/430.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.7ms preprocess, 119.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/550.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/380.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/40.jpg: 384x640 1 person, 147.2ms\n",
      "Speed: 0.6ms preprocess, 147.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/50.jpg: 384x640 1 person, 126.5ms\n",
      "Speed: 0.8ms preprocess, 126.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/390.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/540.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/420.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/150.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.5ms preprocess, 120.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/620.jpg: 384x640 2 persons, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/90.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/350.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/230.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.5ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/580.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.5ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/0.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_20.mp4/190.jpg: 384x640 1 person, 135.8ms\n",
      "Speed: 0.6ms preprocess, 135.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/200.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/60.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.5ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/160.jpg: 384x640 1 person, 127.1ms\n",
      "Speed: 0.8ms preprocess, 127.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/170.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.5ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/70.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/210.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.5ms preprocess, 118.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/100.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.5ms preprocess, 117.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/110.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/10.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.5ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/120.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.7ms preprocess, 118.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/20.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/30.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/130.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/180.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.6ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/80.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/140.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.7ms preprocess, 118.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/40.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.5ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/50.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/150.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/90.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.8ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/0.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.5ms preprocess, 116.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_10012022_1.mp4/190.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/360.jpg: 384x640 1 person, 135.5ms\n",
      "Speed: 0.6ms preprocess, 135.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/200.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/60.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/410.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/160.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/170.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/400.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.5ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/70.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.7ms preprocess, 123.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/210.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/370.jpg: 384x640 1 person, 157.3ms\n",
      "Speed: 0.5ms preprocess, 157.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/510.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/470.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/100.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/300.jpg: 384x640 1 person, 129.3ms\n",
      "Speed: 0.7ms preprocess, 129.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/260.jpg: 384x640 1 person, 129.5ms\n",
      "Speed: 0.6ms preprocess, 129.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/270.jpg: 384x640 (no detections), 128.1ms\n",
      "Speed: 0.6ms preprocess, 128.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/310.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 1.0ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/110.jpg: 384x640 1 person, 129.3ms\n",
      "Speed: 0.6ms preprocess, 129.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/460.jpg: 384x640 1 person, 130.3ms\n",
      "Speed: 0.7ms preprocess, 130.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/500.jpg: 384x640 1 person, 128.2ms\n",
      "Speed: 0.5ms preprocess, 128.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/10.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.7ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/120.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/450.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/530.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.5ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/280.jpg: 384x640 1 person, 138.1ms\n",
      "Speed: 0.5ms preprocess, 138.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/20.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/490.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/240.jpg: 384x640 1 person, 132.8ms\n",
      "Speed: 0.6ms preprocess, 132.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/320.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.7ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/330.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.7ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/250.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/480.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/30.jpg: 384x640 1 person, 141.8ms\n",
      "Speed: 0.5ms preprocess, 141.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/290.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/520.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/440.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/130.jpg: 384x640 1 person, 114.0ms\n",
      "Speed: 0.5ms preprocess, 114.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/180.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.5ms preprocess, 115.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/220.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/340.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.7ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/80.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/140.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.7ms preprocess, 124.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/430.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/380.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.5ms preprocess, 118.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/40.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/50.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.5ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/390.jpg: 384x640 1 person, 135.5ms\n",
      "Speed: 0.6ms preprocess, 135.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/420.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.7ms preprocess, 119.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/150.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.5ms preprocess, 123.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/90.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.7ms preprocess, 122.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/350.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.8ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/230.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.7ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/0.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.7ms preprocess, 122.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_21.mp4/190.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.7ms preprocess, 121.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/200.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/60.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/160.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.6ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/170.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.6ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/70.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.5ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/100.jpg: 384x640 1 person, 134.2ms\n",
      "Speed: 0.6ms preprocess, 134.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/110.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.6ms preprocess, 114.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/10.jpg: 384x640 1 person, 114.5ms\n",
      "Speed: 0.6ms preprocess, 114.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/120.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/20.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.6ms preprocess, 115.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/30.jpg: 384x640 2 persons, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/130.jpg: 384x640 2 persons, 112.8ms\n",
      "Speed: 0.6ms preprocess, 112.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/180.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/80.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/140.jpg: 384x640 2 persons, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/40.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 1.0ms preprocess, 116.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/50.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/150.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/90.jpg: 384x640 1 person, 139.8ms\n",
      "Speed: 0.6ms preprocess, 139.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/0.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.7ms preprocess, 115.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19032022_16.mp4/190.jpg: 384x640 1 person, 113.1ms\n",
      "Speed: 0.6ms preprocess, 113.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/200.jpg: 384x640 1 person, 113.7ms\n",
      "Speed: 0.8ms preprocess, 113.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/60.jpg: 384x640 2 persons, 113.5ms\n",
      "Speed: 0.5ms preprocess, 113.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/160.jpg: 384x640 2 persons, 112.4ms\n",
      "Speed: 0.6ms preprocess, 112.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/170.jpg: 384x640 1 person, 114.1ms\n",
      "Speed: 0.5ms preprocess, 114.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/70.jpg: 384x640 1 person, 114.5ms\n",
      "Speed: 0.5ms preprocess, 114.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/210.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.8ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/100.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/300.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.6ms preprocess, 114.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/260.jpg: 384x640 1 person, 113.6ms\n",
      "Speed: 0.5ms preprocess, 113.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/270.jpg: 384x640 1 person, 131.9ms\n",
      "Speed: 0.7ms preprocess, 131.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/310.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/110.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.6ms preprocess, 114.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/10.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.7ms preprocess, 115.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/120.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.5ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/280.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.6ms preprocess, 114.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/20.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/240.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/320.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/250.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/30.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.6ms preprocess, 116.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/290.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.7ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/130.jpg: 384x640 1 person, 133.0ms\n",
      "Speed: 0.7ms preprocess, 133.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/180.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.7ms preprocess, 118.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/220.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/80.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/140.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.9ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/40.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/50.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/150.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.6ms preprocess, 123.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/90.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/230.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.5ms preprocess, 118.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/0.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_22012022_5.mp4/190.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/360.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.5ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/200.jpg: 384x640 1 person, 134.1ms\n",
      "Speed: 0.6ms preprocess, 134.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/60.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.8ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/160.jpg: 384x640 1 person, 160.1ms\n",
      "Speed: 0.6ms preprocess, 160.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/170.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/70.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/210.jpg: 384x640 1 person, 132.3ms\n",
      "Speed: 0.6ms preprocess, 132.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/370.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/100.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.5ms preprocess, 115.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/300.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.6ms preprocess, 115.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/260.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/270.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/310.jpg: 384x640 1 person, 114.2ms\n",
      "Speed: 0.6ms preprocess, 114.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/110.jpg: 384x640 1 person, 135.1ms\n",
      "Speed: 0.5ms preprocess, 135.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/10.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.6ms preprocess, 115.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/120.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.5ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/280.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/20.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/240.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/320.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/330.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.6ms preprocess, 115.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/250.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/30.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.6ms preprocess, 115.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/290.jpg: 384x640 1 person, 115.0ms\n",
      "Speed: 0.5ms preprocess, 115.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/130.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/180.jpg: 384x640 1 person, 127.0ms\n",
      "Speed: 2.6ms preprocess, 127.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/220.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.5ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/340.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.6ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/80.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/140.jpg: 384x640 1 person, 128.7ms\n",
      "Speed: 2.0ms preprocess, 128.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/380.jpg: 384x640 1 person, 113.5ms\n",
      "Speed: 0.6ms preprocess, 113.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/40.jpg: 384x640 1 person, 113.8ms\n",
      "Speed: 0.6ms preprocess, 113.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/50.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/390.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/150.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/90.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.6ms preprocess, 115.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/350.jpg: 384x640 1 person, 129.7ms\n",
      "Speed: 0.8ms preprocess, 129.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/230.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/0.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.7ms preprocess, 116.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_26.mp4/190.jpg: 384x640 1 person, 114.0ms\n",
      "Speed: 0.6ms preprocess, 114.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/610.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/360.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/200.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/980.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.5ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/770.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/60.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.5ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/820.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/940.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.5ms preprocess, 116.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/570.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.6ms preprocess, 122.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/410.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.5ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/160.jpg: 384x640 1 person, 139.3ms\n",
      "Speed: 0.7ms preprocess, 139.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/170.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/400.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/560.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.7ms preprocess, 120.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/950.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/830.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.5ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/70.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/990.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.5ms preprocess, 121.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/760.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/210.jpg: 384x640 1 person, 124.1ms\n",
      "Speed: 0.5ms preprocess, 124.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/370.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.5ms preprocess, 118.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/600.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.5ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/840.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/920.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/510.jpg: 384x640 1 person, 134.8ms\n",
      "Speed: 0.5ms preprocess, 134.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/470.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.6ms preprocess, 122.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/100.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/880.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/670.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/300.jpg: 384x640 2 persons, 124.1ms\n",
      "Speed: 0.6ms preprocess, 124.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/260.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/710.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/700.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.6ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/270.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/310.jpg: 384x640 3 persons, 115.5ms\n",
      "Speed: 0.5ms preprocess, 115.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/890.jpg: 384x640 1 person, 138.3ms\n",
      "Speed: 0.6ms preprocess, 138.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/660.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/110.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/460.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.7ms preprocess, 117.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/500.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.6ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/930.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.5ms preprocess, 116.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/850.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/10.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/120.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/450.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/530.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/900.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.7ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/280.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/690.jpg: 384x640 1 person, 137.4ms\n",
      "Speed: 0.7ms preprocess, 137.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/860.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.6ms preprocess, 127.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/20.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.7ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/490.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/730.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/240.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/320.jpg: 384x640 2 persons, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/650.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.5ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/640.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.6ms preprocess, 127.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/330.jpg: 384x640 1 person, 126.5ms\n",
      "Speed: 0.6ms preprocess, 126.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/250.jpg: 384x640 1 person, 136.7ms\n",
      "Speed: 0.8ms preprocess, 136.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/720.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/480.jpg: 384x640 1 person, 138.1ms\n",
      "Speed: 0.6ms preprocess, 138.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/680.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/30.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.5ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/870.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/290.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.7ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/910.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.6ms preprocess, 115.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/520.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/440.jpg: 384x640 1 person, 136.3ms\n",
      "Speed: 0.5ms preprocess, 136.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/130.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.6ms preprocess, 127.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/180.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.7ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/590.jpg: 384x640 1 person, 128.6ms\n",
      "Speed: 0.8ms preprocess, 128.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/750.jpg: 384x640 1 person, 128.5ms\n",
      "Speed: 0.6ms preprocess, 128.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/220.jpg: 384x640 1 person, 126.8ms\n",
      "Speed: 0.6ms preprocess, 126.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/340.jpg: 384x640 2 persons, 144.4ms\n",
      "Speed: 0.6ms preprocess, 144.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/630.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/80.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/140.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.5ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/430.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.5ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/550.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.5ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/790.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/960.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.7ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/380.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.6ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/800.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/40.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.8ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/50.jpg: 384x640 1 person, 133.8ms\n",
      "Speed: 0.6ms preprocess, 133.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/810.jpg: 384x640 1 person, 129.4ms\n",
      "Speed: 0.5ms preprocess, 129.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/390.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.8ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/780.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/970.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.5ms preprocess, 116.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/540.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.5ms preprocess, 119.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/420.jpg: 384x640 2 persons, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/150.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.5ms preprocess, 115.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/620.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/90.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.5ms preprocess, 116.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/350.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.6ms preprocess, 127.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/230.jpg: 384x640 1 person, 136.2ms\n",
      "Speed: 0.6ms preprocess, 136.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/740.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.7ms preprocess, 116.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/580.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/1000.jpg: 384x640 1 person, 114.2ms\n",
      "Speed: 0.5ms preprocess, 114.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/0.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_19122021_3.mp4/190.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.7ms preprocess, 116.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/60.jpg: 384x640 2 persons, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/160.jpg: 384x640 2 persons, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/170.jpg: 384x640 3 persons, 121.7ms\n",
      "Speed: 0.5ms preprocess, 121.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/70.jpg: 384x640 2 persons, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/100.jpg: 384x640 2 persons, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/110.jpg: 384x640 2 persons, 117.9ms\n",
      "Speed: 0.7ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/10.jpg: 384x640 2 persons, 118.7ms\n",
      "Speed: 0.7ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/120.jpg: 384x640 2 persons, 137.4ms\n",
      "Speed: 0.6ms preprocess, 137.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/20.jpg: 384x640 2 persons, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/30.jpg: 384x640 2 persons, 119.8ms\n",
      "Speed: 0.7ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/130.jpg: 384x640 2 persons, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/80.jpg: 384x640 2 persons, 140.4ms\n",
      "Speed: 0.6ms preprocess, 140.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/140.jpg: 384x640 2 persons, 130.2ms\n",
      "Speed: 1.6ms preprocess, 130.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/40.jpg: 384x640 2 persons, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/50.jpg: 384x640 2 persons, 121.4ms\n",
      "Speed: 0.7ms preprocess, 121.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/150.jpg: 384x640 2 persons, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/90.jpg: 384x640 2 persons, 122.0ms\n",
      "Speed: 0.6ms preprocess, 122.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_27.mp4/0.jpg: 384x640 2 persons, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/200.jpg: 384x640 1 person, 132.8ms\n",
      "Speed: 0.6ms preprocess, 132.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/60.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/160.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/170.jpg: 384x640 2 persons, 114.8ms\n",
      "Speed: 0.6ms preprocess, 114.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/70.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.7ms preprocess, 117.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/210.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/100.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.5ms preprocess, 115.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/300.jpg: 384x640 1 person, 114.4ms\n",
      "Speed: 0.5ms preprocess, 114.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/260.jpg: 384x640 (no detections), 113.0ms\n",
      "Speed: 0.6ms preprocess, 113.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/270.jpg: 384x640 1 person, 114.5ms\n",
      "Speed: 0.6ms preprocess, 114.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/310.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.7ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/110.jpg: 384x640 1 person, 138.4ms\n",
      "Speed: 0.5ms preprocess, 138.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/10.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.7ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/120.jpg: 384x640 2 persons, 119.1ms\n",
      "Speed: 0.7ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/280.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.7ms preprocess, 117.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/20.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/240.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/320.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/330.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.7ms preprocess, 116.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/250.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/30.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.6ms preprocess, 116.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/290.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/130.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.5ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/180.jpg: 384x640 2 persons, 112.4ms\n",
      "Speed: 0.8ms preprocess, 112.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/220.jpg: 384x640 1 person, 113.5ms\n",
      "Speed: 0.6ms preprocess, 113.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/340.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.7ms preprocess, 115.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/80.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.6ms preprocess, 122.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/140.jpg: 384x640 1 person, 128.4ms\n",
      "Speed: 0.6ms preprocess, 128.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/40.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/50.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.7ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/150.jpg: 384x640 1 person, 113.3ms\n",
      "Speed: 0.6ms preprocess, 113.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/90.jpg: 384x640 1 person, 131.2ms\n",
      "Speed: 0.5ms preprocess, 131.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/230.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.6ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/0.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_02.mp4/190.jpg: 384x640 2 persons, 116.6ms\n",
      "Speed: 0.5ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/60.jpg: 384x640 2 persons, 123.0ms\n",
      "Speed: 0.5ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/70.jpg: 384x640 2 persons, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/100.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/110.jpg: 384x640 2 persons, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/10.jpg: 384x640 2 persons, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/120.jpg: 384x640 2 persons, 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/20.jpg: 384x640 2 persons, 116.8ms\n",
      "Speed: 0.5ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/30.jpg: 384x640 2 persons, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/130.jpg: 384x640 2 persons, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/80.jpg: 384x640 2 persons, 150.9ms\n",
      "Speed: 0.5ms preprocess, 150.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/140.jpg: 384x640 2 persons, 118.6ms\n",
      "Speed: 0.7ms preprocess, 118.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/40.jpg: 384x640 2 persons, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/50.jpg: 384x640 2 persons, 120.0ms\n",
      "Speed: 0.7ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/90.jpg: 384x640 2 persons, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_17.mp4/0.jpg: 384x640 2 persons, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/200.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/60.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/160.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.8ms preprocess, 123.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/170.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.6ms preprocess, 116.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/70.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.5ms preprocess, 117.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/210.jpg: 384x640 (no detections), 113.6ms\n",
      "Speed: 0.5ms preprocess, 113.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/100.jpg: 384x640 2 persons, 132.5ms\n",
      "Speed: 0.6ms preprocess, 132.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/300.jpg: 384x640 (no detections), 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/260.jpg: 384x640 (no detections), 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/270.jpg: 384x640 (no detections), 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/110.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.6ms preprocess, 123.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/10.jpg: 384x640 (no detections), 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/120.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.6ms preprocess, 116.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/280.jpg: 384x640 (no detections), 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/20.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.5ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/240.jpg: 384x640 1 person, 133.2ms\n",
      "Speed: 0.6ms preprocess, 133.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/250.jpg: 384x640 2 persons, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/30.jpg: 384x640 2 persons, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/290.jpg: 384x640 (no detections), 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/130.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.9ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/180.jpg: 384x640 2 persons, 116.3ms\n",
      "Speed: 0.5ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/220.jpg: 384x640 (no detections), 115.2ms\n",
      "Speed: 0.6ms preprocess, 115.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/80.jpg: 384x640 1 person, 114.7ms\n",
      "Speed: 0.6ms preprocess, 114.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/140.jpg: 384x640 1 person, 114.3ms\n",
      "Speed: 0.5ms preprocess, 114.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/40.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.5ms preprocess, 121.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/50.jpg: 384x640 1 person, 126.4ms\n",
      "Speed: 0.7ms preprocess, 126.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/150.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.5ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/90.jpg: 384x640 1 person, 134.2ms\n",
      "Speed: 0.8ms preprocess, 134.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/230.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.5ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/0.jpg: 384x640 (no detections), 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_03.mp4/190.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/360.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/200.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/60.jpg: 384x640 2 persons, 118.3ms\n",
      "Speed: 0.5ms preprocess, 118.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/160.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.7ms preprocess, 114.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/170.jpg: 384x640 1 person, 144.8ms\n",
      "Speed: 0.7ms preprocess, 144.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/70.jpg: 384x640 2 persons, 114.4ms\n",
      "Speed: 0.6ms preprocess, 114.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/210.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/100.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/300.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.7ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/260.jpg: 384x640 2 persons, 115.0ms\n",
      "Speed: 0.6ms preprocess, 115.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/270.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.9ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/310.jpg: 384x640 (no detections), 114.7ms\n",
      "Speed: 0.5ms preprocess, 114.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/110.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/10.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.5ms preprocess, 116.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/120.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.6ms preprocess, 116.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/280.jpg: 384x640 1 person, 112.9ms\n",
      "Speed: 0.5ms preprocess, 112.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/20.jpg: 384x640 1 person, 135.5ms\n",
      "Speed: 0.6ms preprocess, 135.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/240.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.7ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/320.jpg: 384x640 2 persons, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/330.jpg: 384x640 2 persons, 116.4ms\n",
      "Speed: 0.5ms preprocess, 116.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/250.jpg: 384x640 1 person, 129.1ms\n",
      "Speed: 0.6ms preprocess, 129.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/30.jpg: 384x640 2 persons, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/290.jpg: 384x640 2 persons, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/130.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.5ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/180.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.7ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/220.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/340.jpg: 384x640 2 persons, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/80.jpg: 384x640 1 person, 134.1ms\n",
      "Speed: 0.7ms preprocess, 134.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/140.jpg: 384x640 1 person, 201.6ms\n",
      "Speed: 1.0ms preprocess, 201.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/40.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.6ms preprocess, 122.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/50.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.9ms preprocess, 122.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/150.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/90.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/350.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/230.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.6ms preprocess, 127.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/0.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.8ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_23022022_15.mp4/190.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/200.jpg: 384x640 1 person, 164.0ms\n",
      "Speed: 0.6ms preprocess, 164.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/60.jpg: 384x640 1 person, 154.8ms\n",
      "Speed: 1.0ms preprocess, 154.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/160.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.6ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/170.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.7ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/70.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.6ms preprocess, 123.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/210.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.8ms preprocess, 121.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/100.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.5ms preprocess, 119.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/110.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.5ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/10.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/120.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/20.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.7ms preprocess, 118.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/240.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/250.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.6ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/30.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/130.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.5ms preprocess, 115.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/180.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.6ms preprocess, 116.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/220.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/80.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/140.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.5ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/40.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.7ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/50.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/150.jpg: 384x640 1 person, 131.4ms\n",
      "Speed: 0.6ms preprocess, 131.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/90.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/230.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/0.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.7ms preprocess, 115.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_20012022_4.mp4/190.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.5ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/60.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/160.jpg: 384x640 2 persons, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/70.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.5ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/100.jpg: 384x640 2 persons, 136.4ms\n",
      "Speed: 0.5ms preprocess, 136.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/110.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/10.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/120.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/20.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/30.jpg: 384x640 1 person, 124.6ms\n",
      "Speed: 0.7ms preprocess, 124.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/130.jpg: 384x640 2 persons, 116.7ms\n",
      "Speed: 0.8ms preprocess, 116.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/80.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/140.jpg: 384x640 1 person, 135.3ms\n",
      "Speed: 0.5ms preprocess, 135.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/40.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.7ms preprocess, 118.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/50.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.6ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/150.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.7ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/90.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_2.mp4/0.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.6ms preprocess, 123.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/60.jpg: 384x640 2 persons, 116.9ms\n",
      "Speed: 0.5ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/70.jpg: 384x640 2 persons, 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/100.jpg: 384x640 2 persons, 134.9ms\n",
      "Speed: 0.6ms preprocess, 134.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/110.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/10.jpg: 384x640 3 persons, 115.9ms\n",
      "Speed: 0.7ms preprocess, 115.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/120.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/20.jpg: 384x640 3 persons, 120.4ms\n",
      "Speed: 0.8ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/30.jpg: 384x640 3 persons, 118.9ms\n",
      "Speed: 0.5ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/80.jpg: 384x640 2 persons, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/40.jpg: 384x640 4 persons, 117.2ms\n",
      "Speed: 0.5ms preprocess, 117.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/50.jpg: 384x640 3 persons, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/90.jpg: 384x640 2 persons, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_12122021_1.mp4/0.jpg: 384x640 3 persons, 117.5ms\n",
      "Speed: 0.5ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/200.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.5ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/60.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/160.jpg: 384x640 1 person, 134.5ms\n",
      "Speed: 0.5ms preprocess, 134.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/170.jpg: 384x640 1 person, 123.4ms\n",
      "Speed: 0.7ms preprocess, 123.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/70.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/210.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/100.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.5ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/300.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/260.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.5ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/270.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/110.jpg: 384x640 1 person, 125.2ms\n",
      "Speed: 0.6ms preprocess, 125.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/10.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/120.jpg: 384x640 2 persons, 118.3ms\n",
      "Speed: 0.5ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/280.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/20.jpg: 384x640 1 person, 130.2ms\n",
      "Speed: 0.5ms preprocess, 130.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/240.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/250.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.7ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/30.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.6ms preprocess, 124.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/290.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/130.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.7ms preprocess, 115.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/180.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.5ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/220.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/80.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/140.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.5ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/40.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.6ms preprocess, 125.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/50.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/150.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/90.jpg: 384x640 1 person, 136.7ms\n",
      "Speed: 0.6ms preprocess, 136.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/230.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/0.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_06.mp4/190.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.5ms preprocess, 118.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/360.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.6ms preprocess, 123.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/200.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.6ms preprocess, 116.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/60.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/410.jpg: 384x640 1 person, 114.4ms\n",
      "Speed: 0.6ms preprocess, 114.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/160.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.5ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/170.jpg: 384x640 1 person, 126.8ms\n",
      "Speed: 0.6ms preprocess, 126.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/400.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/70.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/210.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/370.jpg: 384x640 1 person, 133.8ms\n",
      "Speed: 0.6ms preprocess, 133.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/510.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/470.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/100.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.7ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/300.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/260.jpg: 384x640 (no detections), 120.9ms\n",
      "Speed: 0.7ms preprocess, 120.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/270.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/310.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/110.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.5ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/460.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.6ms preprocess, 115.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/500.jpg: 384x640 1 person, 135.7ms\n",
      "Speed: 0.5ms preprocess, 135.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/10.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/120.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/450.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/530.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/280.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.6ms preprocess, 116.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/20.jpg: 384x640 1 person, 113.7ms\n",
      "Speed: 0.6ms preprocess, 113.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/490.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.7ms preprocess, 116.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/240.jpg: 384x640 1 person, 115.0ms\n",
      "Speed: 0.5ms preprocess, 115.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/320.jpg: 384x640 1 person, 129.4ms\n",
      "Speed: 0.5ms preprocess, 129.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/330.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/250.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.7ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/480.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/30.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.5ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/290.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.5ms preprocess, 117.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/520.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.5ms preprocess, 117.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/440.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.5ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/130.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.6ms preprocess, 122.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/180.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.5ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/220.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/340.jpg: 384x640 1 person, 138.9ms\n",
      "Speed: 0.5ms preprocess, 138.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/80.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/140.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/430.jpg: 384x640 1 person, 168.5ms\n",
      "Speed: 0.7ms preprocess, 168.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/550.jpg: 384x640 1 person, 123.4ms\n",
      "Speed: 0.6ms preprocess, 123.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/380.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.6ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/40.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.7ms preprocess, 115.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/50.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/390.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/540.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/420.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/150.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/90.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.5ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/350.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/230.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.7ms preprocess, 137.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/0.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_2.mp4/190.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.5ms preprocess, 118.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/360.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/200.jpg: 384x640 2 persons, 118.2ms\n",
      "Speed: 0.7ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/60.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.6ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/410.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.5ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/160.jpg: 384x640 2 persons, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/170.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/400.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.6ms preprocess, 123.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/70.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/210.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.5ms preprocess, 118.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/370.jpg: 384x640 1 person, 146.3ms\n",
      "Speed: 0.5ms preprocess, 146.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/510.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/470.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/100.jpg: 384x640 2 persons, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/300.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/260.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/270.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.5ms preprocess, 118.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/310.jpg: 384x640 1 person, 125.1ms\n",
      "Speed: 0.5ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/110.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.5ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/460.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/500.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/10.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/120.jpg: 384x640 1 person, 144.6ms\n",
      "Speed: 0.7ms preprocess, 144.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/450.jpg: 384x640 1 person, 148.6ms\n",
      "Speed: 0.7ms preprocess, 148.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/280.jpg: 384x640 1 person, 128.0ms\n",
      "Speed: 0.6ms preprocess, 128.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/20.jpg: 384x640 2 persons, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/490.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/240.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/320.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.5ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/330.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.5ms preprocess, 121.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/250.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.5ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/480.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.5ms preprocess, 123.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/30.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.7ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/290.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/520.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.5ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/440.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/130.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/180.jpg: 384x640 1 person, 152.7ms\n",
      "Speed: 0.6ms preprocess, 152.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/220.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.6ms preprocess, 123.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/340.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/80.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.5ms preprocess, 118.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/140.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/430.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.5ms preprocess, 116.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/380.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/40.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.5ms preprocess, 124.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/50.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.7ms preprocess, 121.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/390.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/420.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/150.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/90.jpg: 384x640 1 person, 139.6ms\n",
      "Speed: 0.6ms preprocess, 139.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/350.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.7ms preprocess, 119.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/230.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.5ms preprocess, 122.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/0.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.5ms preprocess, 122.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_11122021_3.mp4/190.jpg: 384x640 2 persons, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/200.jpg: 384x640 1 person, 129.3ms\n",
      "Speed: 0.7ms preprocess, 129.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/60.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.8ms preprocess, 124.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/160.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/170.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/70.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/210.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.5ms preprocess, 121.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/100.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/260.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/110.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/10.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.6ms preprocess, 137.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/120.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 0.6ms preprocess, 127.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/20.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/240.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/250.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.5ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/30.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/130.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/180.jpg: 384x640 1 person, 140.7ms\n",
      "Speed: 0.5ms preprocess, 140.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/220.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.7ms preprocess, 119.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/80.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/140.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.5ms preprocess, 119.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/40.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/50.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.6ms preprocess, 122.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/150.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.7ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/90.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.6ms preprocess, 123.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/230.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/0.jpg: 384x640 1 person, 131.1ms\n",
      "Speed: 0.7ms preprocess, 131.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_03032022_10.mp4/190.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/360.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.5ms preprocess, 117.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/200.jpg: 384x640 1 person, 146.3ms\n",
      "Speed: 0.6ms preprocess, 146.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/60.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/160.jpg: 384x640 1 person, 137.0ms\n",
      "Speed: 0.6ms preprocess, 137.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/170.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/70.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.7ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/210.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.5ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/370.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.5ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/100.jpg: 384x640 1 person, 170.1ms\n",
      "Speed: 0.6ms preprocess, 170.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/300.jpg: 384x640 1 person, 129.2ms\n",
      "Speed: 1.0ms preprocess, 129.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/260.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/270.jpg: 384x640 1 person, 126.9ms\n",
      "Speed: 0.6ms preprocess, 126.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/310.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/110.jpg: 384x640 1 person, 142.8ms\n",
      "Speed: 2.5ms preprocess, 142.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/10.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/120.jpg: 384x640 1 person, 132.2ms\n",
      "Speed: 0.6ms preprocess, 132.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/280.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/20.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/240.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/320.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/330.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.5ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/250.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.6ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/30.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.5ms preprocess, 116.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/290.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/130.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.5ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/180.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/220.jpg: 384x640 1 person, 139.0ms\n",
      "Speed: 0.6ms preprocess, 139.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/340.jpg: 384x640 1 person, 138.0ms\n",
      "Speed: 0.5ms preprocess, 138.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/80.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/140.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/380.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.5ms preprocess, 115.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/40.jpg: 384x640 1 person, 126.2ms\n",
      "Speed: 0.5ms preprocess, 126.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/50.jpg: 384x640 1 person, 146.5ms\n",
      "Speed: 0.6ms preprocess, 146.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/390.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.7ms preprocess, 125.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/150.jpg: 384x640 1 person, 135.8ms\n",
      "Speed: 0.6ms preprocess, 135.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/90.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/350.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.7ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/230.jpg: 384x640 1 person, 135.4ms\n",
      "Speed: 0.7ms preprocess, 135.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/0.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_4.mp4/190.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/360.jpg: 384x640 1 person, 131.5ms\n",
      "Speed: 0.6ms preprocess, 131.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/200.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 0.6ms preprocess, 133.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/60.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.8ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/160.jpg: 384x640 1 person, 126.8ms\n",
      "Speed: 0.5ms preprocess, 126.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/170.jpg: 384x640 1 person, 127.0ms\n",
      "Speed: 0.6ms preprocess, 127.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/70.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.8ms preprocess, 120.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/210.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.6ms preprocess, 121.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/100.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/300.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.5ms preprocess, 116.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/260.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.5ms preprocess, 122.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/270.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.5ms preprocess, 118.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/310.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.5ms preprocess, 119.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/110.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/10.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/120.jpg: 384x640 1 person, 131.1ms\n",
      "Speed: 0.6ms preprocess, 131.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/280.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.6ms preprocess, 137.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/20.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.8ms preprocess, 123.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/240.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/320.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.5ms preprocess, 118.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/330.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/250.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.5ms preprocess, 117.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/30.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/290.jpg: 384x640 1 person, 144.0ms\n",
      "Speed: 0.8ms preprocess, 144.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/130.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.5ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/180.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.6ms preprocess, 116.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/220.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/340.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.7ms preprocess, 117.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/80.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/140.jpg: 384x640 1 person, 136.4ms\n",
      "Speed: 0.7ms preprocess, 136.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/40.jpg: 384x640 1 person, 142.1ms\n",
      "Speed: 0.5ms preprocess, 142.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/50.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.6ms preprocess, 116.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/150.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.5ms preprocess, 118.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/90.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/350.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/230.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/0.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.6ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MILD/mild_youtube_18122021_5.mp4/190.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.5ms preprocess, 137.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/360.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/200.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/60.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.7ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/410.jpg: 384x640 1 person, 129.4ms\n",
      "Speed: 0.5ms preprocess, 129.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/160.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.7ms preprocess, 116.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/170.jpg: 384x640 1 person, 135.5ms\n",
      "Speed: 0.5ms preprocess, 135.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/400.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.5ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/70.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/210.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.5ms preprocess, 115.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/370.jpg: 384x640 2 persons, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/510.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.8ms preprocess, 117.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/470.jpg: 384x640 1 person, 135.3ms\n",
      "Speed: 0.5ms preprocess, 135.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/100.jpg: 384x640 1 person, 113.4ms\n",
      "Speed: 0.6ms preprocess, 113.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/300.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.5ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/260.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/270.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.7ms preprocess, 121.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/310.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/110.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/460.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/500.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.5ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/10.jpg: 384x640 1 person, 113.5ms\n",
      "Speed: 0.5ms preprocess, 113.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/120.jpg: 384x640 1 person, 132.0ms\n",
      "Speed: 0.5ms preprocess, 132.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/450.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.6ms preprocess, 125.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/280.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/20.jpg: 384x640 1 person, 113.4ms\n",
      "Speed: 0.6ms preprocess, 113.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/490.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.7ms preprocess, 116.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/240.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.6ms preprocess, 117.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/320.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.6ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/330.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.6ms preprocess, 127.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/250.jpg: 384x640 1 person, 150.5ms\n",
      "Speed: 0.6ms preprocess, 150.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/480.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/30.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/290.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/440.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.9ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/130.jpg: 384x640 1 person, 126.2ms\n",
      "Speed: 0.6ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/180.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.6ms preprocess, 115.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/220.jpg: 384x640 1 person, 134.8ms\n",
      "Speed: 0.5ms preprocess, 134.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/340.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.7ms preprocess, 117.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/80.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.7ms preprocess, 117.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/140.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.6ms preprocess, 114.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/430.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/380.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.6ms preprocess, 121.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/40.jpg: 384x640 1 person, 135.9ms\n",
      "Speed: 0.5ms preprocess, 135.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/50.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.6ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/390.jpg: 384x640 1 person, 142.7ms\n",
      "Speed: 0.8ms preprocess, 142.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/420.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.6ms preprocess, 121.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/150.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/90.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/350.jpg: 384x640 2 persons, 131.9ms\n",
      "Speed: 0.5ms preprocess, 131.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/230.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.5ms preprocess, 117.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/0.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_24.mp4/190.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.7ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/360.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.6ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/200.jpg: 384x640 1 person, 135.5ms\n",
      "Speed: 0.7ms preprocess, 135.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/60.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/410.jpg: 384x640 1 person, 127.4ms\n",
      "Speed: 0.6ms preprocess, 127.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/160.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.5ms preprocess, 119.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/170.jpg: 384x640 1 person, 144.5ms\n",
      "Speed: 0.6ms preprocess, 144.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/400.jpg: 384x640 1 person, 128.9ms\n",
      "Speed: 0.8ms preprocess, 128.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/70.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/210.jpg: 384x640 1 person, 133.3ms\n",
      "Speed: 0.7ms preprocess, 133.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/370.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/470.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/100.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/300.jpg: 384x640 1 person, 137.4ms\n",
      "Speed: 0.6ms preprocess, 137.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/260.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.9ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/270.jpg: 384x640 1 person, 145.9ms\n",
      "Speed: 0.8ms preprocess, 145.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/310.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.7ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/110.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/460.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.5ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/10.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.5ms preprocess, 115.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/120.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.5ms preprocess, 120.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/450.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.7ms preprocess, 125.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/280.jpg: 384x640 1 person, 131.3ms\n",
      "Speed: 0.6ms preprocess, 131.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/20.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.7ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/240.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.5ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/320.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/330.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.6ms preprocess, 116.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/250.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/480.jpg: 384x640 1 person, 191.7ms\n",
      "Speed: 0.5ms preprocess, 191.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/30.jpg: 384x640 1 person, 138.7ms\n",
      "Speed: 0.8ms preprocess, 138.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/290.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.5ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/440.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.7ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/130.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/180.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/220.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.6ms preprocess, 123.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/340.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.5ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/80.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.6ms preprocess, 116.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/140.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.7ms preprocess, 116.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/430.jpg: 384x640 1 person, 135.7ms\n",
      "Speed: 0.5ms preprocess, 135.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/380.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.6ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/40.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/50.jpg: 384x640 1 person, 132.1ms\n",
      "Speed: 0.6ms preprocess, 132.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/390.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/420.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/150.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.5ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/90.jpg: 384x640 1 person, 133.6ms\n",
      "Speed: 0.6ms preprocess, 133.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/350.jpg: 384x640 1 person, 129.5ms\n",
      "Speed: 0.6ms preprocess, 129.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/230.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/0.jpg: 384x640 1 person, 131.3ms\n",
      "Speed: 0.6ms preprocess, 131.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_18.mp4/190.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.7ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/200.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/60.jpg: 384x640 1 person, 136.4ms\n",
      "Speed: 0.6ms preprocess, 136.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/160.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.7ms preprocess, 121.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/170.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.8ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/70.jpg: 384x640 1 person, 146.0ms\n",
      "Speed: 0.5ms preprocess, 146.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/210.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.5ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/100.jpg: 384x640 1 person, 129.2ms\n",
      "Speed: 0.6ms preprocess, 129.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/260.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.7ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/270.jpg: 384x640 1 person, 145.6ms\n",
      "Speed: 0.6ms preprocess, 145.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/110.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.6ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/10.jpg: 384x640 1 person, 130.1ms\n",
      "Speed: 0.8ms preprocess, 130.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/120.jpg: 384x640 1 person, 124.1ms\n",
      "Speed: 0.6ms preprocess, 124.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/20.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.6ms preprocess, 123.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/240.jpg: 384x640 1 person, 123.4ms\n",
      "Speed: 0.6ms preprocess, 123.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/250.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.6ms preprocess, 123.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/30.jpg: 384x640 1 person, 136.3ms\n",
      "Speed: 0.6ms preprocess, 136.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/130.jpg: 384x640 1 person, 183.0ms\n",
      "Speed: 1.1ms preprocess, 183.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/180.jpg: 384x640 1 person, 147.3ms\n",
      "Speed: 1.7ms preprocess, 147.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/220.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.6ms preprocess, 128.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/80.jpg: 384x640 1 person, 130.9ms\n",
      "Speed: 0.7ms preprocess, 130.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/140.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.6ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/40.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.6ms preprocess, 125.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/50.jpg: 384x640 1 person, 128.1ms\n",
      "Speed: 0.7ms preprocess, 128.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/150.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.6ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/90.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.5ms preprocess, 119.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/230.jpg: 384x640 1 person, 146.9ms\n",
      "Speed: 0.6ms preprocess, 146.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/0.jpg: 384x640 1 person, 135.1ms\n",
      "Speed: 0.7ms preprocess, 135.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_16.mp4/190.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.7ms preprocess, 125.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/610.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/360.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.5ms preprocess, 119.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/200.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.7ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/60.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 1.2ms preprocess, 126.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/570.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.8ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/410.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.9ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/160.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/170.jpg: 384x640 1 person, 137.3ms\n",
      "Speed: 0.6ms preprocess, 137.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/400.jpg: 384x640 1 person, 126.5ms\n",
      "Speed: 0.7ms preprocess, 126.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/560.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.5ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/70.jpg: 384x640 1 person, 126.8ms\n",
      "Speed: 0.5ms preprocess, 126.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/210.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.6ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/370.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.6ms preprocess, 124.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/600.jpg: 384x640 (no detections), 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/510.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/470.jpg: 384x640 2 persons, 136.3ms\n",
      "Speed: 0.5ms preprocess, 136.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/100.jpg: 384x640 1 person, 134.9ms\n",
      "Speed: 0.7ms preprocess, 134.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/300.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/260.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/270.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.6ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/310.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.5ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/110.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.5ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/460.jpg: 384x640 1 person, 132.8ms\n",
      "Speed: 0.5ms preprocess, 132.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/500.jpg: 384x640 1 person, 137.3ms\n",
      "Speed: 2.1ms preprocess, 137.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/10.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/120.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/450.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.5ms preprocess, 116.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/530.jpg: 384x640 1 person, 129.3ms\n",
      "Speed: 0.6ms preprocess, 129.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/280.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.7ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/20.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.5ms preprocess, 118.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/490.jpg: 384x640 1 person, 133.0ms\n",
      "Speed: 0.6ms preprocess, 133.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/240.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/320.jpg: 384x640 1 person, 126.5ms\n",
      "Speed: 0.5ms preprocess, 126.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/650.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/640.jpg: 384x640 1 person, 132.3ms\n",
      "Speed: 0.6ms preprocess, 132.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/330.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.9ms preprocess, 121.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/250.jpg: 384x640 1 person, 134.3ms\n",
      "Speed: 0.6ms preprocess, 134.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/480.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.6ms preprocess, 126.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/30.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.7ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/290.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/520.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/440.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.7ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/130.jpg: 384x640 1 person, 137.0ms\n",
      "Speed: 0.6ms preprocess, 137.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/180.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.6ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/590.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/220.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.7ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/340.jpg: 384x640 1 person, 126.2ms\n",
      "Speed: 0.5ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/630.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/80.jpg: 384x640 1 person, 142.4ms\n",
      "Speed: 0.6ms preprocess, 142.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/140.jpg: 384x640 1 person, 128.8ms\n",
      "Speed: 0.6ms preprocess, 128.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/430.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.5ms preprocess, 125.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/550.jpg: 384x640 1 person, 128.5ms\n",
      "Speed: 0.8ms preprocess, 128.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/380.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/40.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.5ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/50.jpg: 384x640 1 person, 149.0ms\n",
      "Speed: 0.6ms preprocess, 149.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/390.jpg: 384x640 1 person, 130.7ms\n",
      "Speed: 0.5ms preprocess, 130.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/540.jpg: 384x640 1 person, 140.1ms\n",
      "Speed: 0.7ms preprocess, 140.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/420.jpg: 384x640 1 person, 130.5ms\n",
      "Speed: 0.7ms preprocess, 130.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/150.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/620.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 0.6ms preprocess, 127.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/90.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.6ms preprocess, 137.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/350.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/230.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/580.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.7ms preprocess, 122.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/0.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_4.mp4/190.jpg: 384x640 1 person, 136.3ms\n",
      "Speed: 0.6ms preprocess, 136.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/610.jpg: 384x640 1 person, 113.8ms\n",
      "Speed: 0.6ms preprocess, 113.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/360.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.6ms preprocess, 127.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/200.jpg: 384x640 3 persons, 118.1ms\n",
      "Speed: 0.7ms preprocess, 118.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/60.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/570.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.6ms preprocess, 115.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/410.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.5ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/160.jpg: 384x640 2 persons, 165.2ms\n",
      "Speed: 0.6ms preprocess, 165.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/170.jpg: 384x640 2 persons, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/400.jpg: 384x640 1 person, 114.2ms\n",
      "Speed: 0.7ms preprocess, 114.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/560.jpg: 384x640 (no detections), 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/70.jpg: 384x640 1 person, 138.6ms\n",
      "Speed: 0.6ms preprocess, 138.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/210.jpg: 384x640 2 persons, 127.9ms\n",
      "Speed: 1.1ms preprocess, 127.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/370.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.6ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/600.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.5ms preprocess, 118.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/510.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/470.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/100.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.5ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/670.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.7ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/300.jpg: 384x640 2 persons, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/260.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.7ms preprocess, 116.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/700.jpg: 384x640 1 person, 155.4ms\n",
      "Speed: 0.6ms preprocess, 155.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/270.jpg: 384x640 1 person, 124.1ms\n",
      "Speed: 0.6ms preprocess, 124.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/310.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/660.jpg: 384x640 (no detections), 114.3ms\n",
      "Speed: 0.6ms preprocess, 114.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/110.jpg: 384x640 1 person, 113.3ms\n",
      "Speed: 0.5ms preprocess, 113.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/460.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.6ms preprocess, 115.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/500.jpg: 384x640 1 person, 136.1ms\n",
      "Speed: 0.6ms preprocess, 136.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/10.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/120.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.7ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/450.jpg: 384x640 1 person, 114.5ms\n",
      "Speed: 0.7ms preprocess, 114.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/530.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.7ms preprocess, 115.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/280.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.7ms preprocess, 119.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/690.jpg: 384x640 (no detections), 148.9ms\n",
      "Speed: 0.7ms preprocess, 148.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/20.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.7ms preprocess, 115.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/490.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.5ms preprocess, 114.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/240.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.7ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/320.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/650.jpg: 384x640 (no detections), 113.8ms\n",
      "Speed: 0.6ms preprocess, 113.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/640.jpg: 384x640 (no detections), 114.4ms\n",
      "Speed: 0.5ms preprocess, 114.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/330.jpg: 384x640 1 person, 130.1ms\n",
      "Speed: 0.6ms preprocess, 130.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/250.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.6ms preprocess, 114.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/480.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.7ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/680.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.6ms preprocess, 123.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/30.jpg: 384x640 1 person, 114.1ms\n",
      "Speed: 0.6ms preprocess, 114.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/290.jpg: 384x640 2 persons, 125.0ms\n",
      "Speed: 0.8ms preprocess, 125.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/520.jpg: 384x640 1 person, 114.8ms\n",
      "Speed: 0.5ms preprocess, 114.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/440.jpg: 384x640 1 person, 131.4ms\n",
      "Speed: 0.7ms preprocess, 131.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/130.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/180.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.7ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/590.jpg: 384x640 (no detections), 113.8ms\n",
      "Speed: 0.8ms preprocess, 113.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/220.jpg: 384x640 2 persons, 114.8ms\n",
      "Speed: 0.6ms preprocess, 114.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/340.jpg: 384x640 1 person, 114.0ms\n",
      "Speed: 0.6ms preprocess, 114.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/630.jpg: 384x640 (no detections), 133.9ms\n",
      "Speed: 0.6ms preprocess, 133.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/80.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/140.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.7ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/430.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.5ms preprocess, 122.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/550.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.7ms preprocess, 115.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/380.jpg: 384x640 1 person, 112.1ms\n",
      "Speed: 0.7ms preprocess, 112.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/40.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/50.jpg: 384x640 1 person, 112.6ms\n",
      "Speed: 0.7ms preprocess, 112.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/390.jpg: 384x640 1 person, 129.5ms\n",
      "Speed: 0.6ms preprocess, 129.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/540.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.7ms preprocess, 117.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/420.jpg: 384x640 1 person, 113.8ms\n",
      "Speed: 0.7ms preprocess, 113.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/150.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/620.jpg: 384x640 1 person, 113.7ms\n",
      "Speed: 0.6ms preprocess, 113.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/90.jpg: 384x640 1 person, 113.3ms\n",
      "Speed: 0.6ms preprocess, 113.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/350.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.6ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/230.jpg: 384x640 2 persons, 117.0ms\n",
      "Speed: 0.7ms preprocess, 117.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/580.jpg: 384x640 (no detections), 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/0.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.7ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_2.mp4/190.jpg: 384x640 2 persons, 113.4ms\n",
      "Speed: 0.5ms preprocess, 113.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/360.jpg: 384x640 1 person, 135.2ms\n",
      "Speed: 0.5ms preprocess, 135.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/200.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.6ms preprocess, 123.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/60.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/410.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/160.jpg: 384x640 2 persons, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/170.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.7ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/400.jpg: 384x640 1 person, 147.2ms\n",
      "Speed: 0.6ms preprocess, 147.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/70.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/210.jpg: 384x640 2 persons, 132.4ms\n",
      "Speed: 0.6ms preprocess, 132.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/370.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/510.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/470.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/100.jpg: 384x640 1 person, 126.8ms\n",
      "Speed: 0.6ms preprocess, 126.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/300.jpg: 384x640 1 person, 128.1ms\n",
      "Speed: 0.6ms preprocess, 128.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/260.jpg: 384x640 1 person, 140.1ms\n",
      "Speed: 0.6ms preprocess, 140.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/270.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/310.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.5ms preprocess, 121.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/110.jpg: 384x640 1 person, 126.8ms\n",
      "Speed: 0.5ms preprocess, 126.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/460.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.6ms preprocess, 122.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/500.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/10.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.5ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/120.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.5ms preprocess, 115.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/450.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/280.jpg: 384x640 1 person, 144.0ms\n",
      "Speed: 0.5ms preprocess, 144.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/20.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/490.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.8ms preprocess, 123.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/240.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.5ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/320.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.7ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/330.jpg: 384x640 1 person, 134.7ms\n",
      "Speed: 0.6ms preprocess, 134.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/250.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.5ms preprocess, 118.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/480.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/30.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/290.jpg: 384x640 1 person, 135.6ms\n",
      "Speed: 0.6ms preprocess, 135.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/440.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.6ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/130.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/180.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/220.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/340.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/80.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/140.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.7ms preprocess, 123.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/430.jpg: 384x640 1 person, 144.8ms\n",
      "Speed: 0.6ms preprocess, 144.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/380.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/40.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.7ms preprocess, 118.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/50.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.7ms preprocess, 117.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/390.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/420.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/150.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/90.jpg: 384x640 1 person, 137.8ms\n",
      "Speed: 0.6ms preprocess, 137.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/350.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/230.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.7ms preprocess, 117.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/0.jpg: 384x640 1 person, 132.3ms\n",
      "Speed: 0.6ms preprocess, 132.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_19.mp4/190.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.7ms preprocess, 117.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/200.jpg: 384x640 1 person, 114.8ms\n",
      "Speed: 0.6ms preprocess, 114.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/60.jpg: 384x640 1 person, 131.9ms\n",
      "Speed: 0.5ms preprocess, 131.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/160.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.7ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/170.jpg: 384x640 1 person, 126.2ms\n",
      "Speed: 0.6ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/70.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.6ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/210.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.5ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/100.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/110.jpg: 384x640 (no detections), 129.8ms\n",
      "Speed: 0.6ms preprocess, 129.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/10.jpg: 384x640 1 person, 157.8ms\n",
      "Speed: 0.8ms preprocess, 157.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/120.jpg: 384x640 (no detections), 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/20.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/30.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/130.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.5ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/180.jpg: 384x640 1 person, 135.7ms\n",
      "Speed: 0.6ms preprocess, 135.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/220.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.6ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/80.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.5ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/140.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.5ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/40.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.5ms preprocess, 116.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/50.jpg: 384x640 1 person, 114.8ms\n",
      "Speed: 0.5ms preprocess, 114.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/150.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.6ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/90.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/230.jpg: 384x640 1 person, 144.2ms\n",
      "Speed: 0.5ms preprocess, 144.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/0.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.7ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_29.mp4/190.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.6ms preprocess, 115.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/610.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.8ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/360.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.6ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/200.jpg: 384x640 1 person, 140.5ms\n",
      "Speed: 0.6ms preprocess, 140.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/770.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/60.jpg: 384x640 1 person, 128.0ms\n",
      "Speed: 0.6ms preprocess, 128.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/820.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.5ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/940.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.5ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/570.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/410.jpg: 384x640 1 person, 141.4ms\n",
      "Speed: 0.6ms preprocess, 141.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/160.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/170.jpg: 384x640 1 person, 126.3ms\n",
      "Speed: 0.6ms preprocess, 126.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/400.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/560.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/950.jpg: 384x640 1 person, 146.1ms\n",
      "Speed: 0.5ms preprocess, 146.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/830.jpg: 384x640 1 person, 131.3ms\n",
      "Speed: 0.6ms preprocess, 131.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/70.jpg: 384x640 1 person, 129.5ms\n",
      "Speed: 0.8ms preprocess, 129.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/760.jpg: 384x640 1 person, 136.3ms\n",
      "Speed: 0.6ms preprocess, 136.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/210.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/370.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.5ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/600.jpg: 384x640 1 person, 136.2ms\n",
      "Speed: 0.6ms preprocess, 136.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/840.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/920.jpg: 384x640 1 person, 124.6ms\n",
      "Speed: 0.6ms preprocess, 124.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/510.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.5ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/470.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/100.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.5ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/880.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/670.jpg: 384x640 1 person, 150.9ms\n",
      "Speed: 0.6ms preprocess, 150.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/300.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.5ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/260.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.7ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/710.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/700.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/270.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.6ms preprocess, 123.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/310.jpg: 384x640 1 person, 137.0ms\n",
      "Speed: 1.8ms preprocess, 137.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/890.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/660.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/110.jpg: 384x640 1 person, 128.5ms\n",
      "Speed: 0.6ms preprocess, 128.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/460.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.6ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/500.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.7ms preprocess, 119.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/930.jpg: 384x640 1 person, 138.1ms\n",
      "Speed: 0.6ms preprocess, 138.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/850.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/10.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/120.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.5ms preprocess, 125.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/450.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.5ms preprocess, 120.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/530.jpg: 384x640 1 person, 131.5ms\n",
      "Speed: 0.6ms preprocess, 131.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/900.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.6ms preprocess, 127.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/280.jpg: 384x640 1 person, 127.0ms\n",
      "Speed: 0.5ms preprocess, 127.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/690.jpg: 384x640 1 person, 136.6ms\n",
      "Speed: 0.6ms preprocess, 136.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/860.jpg: 384x640 1 person, 129.6ms\n",
      "Speed: 0.6ms preprocess, 129.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/20.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/490.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/730.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.7ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/240.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/320.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/650.jpg: 384x640 1 person, 126.2ms\n",
      "Speed: 0.6ms preprocess, 126.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/640.jpg: 384x640 1 person, 136.1ms\n",
      "Speed: 0.7ms preprocess, 136.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/330.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.7ms preprocess, 122.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/250.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/720.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.5ms preprocess, 121.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/480.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.6ms preprocess, 124.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/680.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/30.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.5ms preprocess, 121.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/870.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 0.7ms preprocess, 133.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/290.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.7ms preprocess, 123.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/910.jpg: 384x640 1 person, 127.1ms\n",
      "Speed: 0.6ms preprocess, 127.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/520.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.5ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/440.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.5ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/130.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/180.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/590.jpg: 384x640 1 person, 160.3ms\n",
      "Speed: 0.6ms preprocess, 160.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/750.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.8ms preprocess, 121.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/220.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/340.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.5ms preprocess, 121.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/630.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/80.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.5ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/140.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.6ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/430.jpg: 384x640 1 person, 150.5ms\n",
      "Speed: 0.6ms preprocess, 150.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/550.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/790.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.5ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/960.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/380.jpg: 384x640 1 person, 124.6ms\n",
      "Speed: 0.5ms preprocess, 124.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/800.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/40.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.7ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/50.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/810.jpg: 384x640 1 person, 136.6ms\n",
      "Speed: 0.7ms preprocess, 136.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/390.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.7ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/780.jpg: 384x640 1 person, 141.5ms\n",
      "Speed: 0.7ms preprocess, 141.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/540.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.7ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/420.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.5ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/150.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/620.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.5ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/90.jpg: 384x640 1 person, 136.6ms\n",
      "Speed: 0.6ms preprocess, 136.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/350.jpg: 384x640 1 person, 128.6ms\n",
      "Speed: 0.6ms preprocess, 128.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/230.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.6ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/740.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/580.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/0.jpg: 384x640 1 person, 131.6ms\n",
      "Speed: 0.5ms preprocess, 131.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_5.mp4/190.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/610.jpg: 384x640 1 person, 131.8ms\n",
      "Speed: 0.6ms preprocess, 131.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/360.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/200.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/60.jpg: 384x640 1 person, 133.7ms\n",
      "Speed: 0.7ms preprocess, 133.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/570.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.7ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/410.jpg: 384x640 (no detections), 144.4ms\n",
      "Speed: 0.8ms preprocess, 144.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/160.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/170.jpg: 384x640 1 person, 151.9ms\n",
      "Speed: 1.7ms preprocess, 151.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/400.jpg: 384x640 (no detections), 127.8ms\n",
      "Speed: 0.6ms preprocess, 127.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/560.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.7ms preprocess, 125.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/70.jpg: 384x640 1 person, 138.3ms\n",
      "Speed: 0.6ms preprocess, 138.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/210.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/370.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.5ms preprocess, 116.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/600.jpg: 384x640 1 person, 112.7ms\n",
      "Speed: 0.5ms preprocess, 112.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/510.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/470.jpg: 384x640 (no detections), 114.7ms\n",
      "Speed: 0.7ms preprocess, 114.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/100.jpg: 384x640 1 person, 114.7ms\n",
      "Speed: 0.6ms preprocess, 114.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/670.jpg: 384x640 (no detections), 115.4ms\n",
      "Speed: 0.5ms preprocess, 115.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/300.jpg: 384x640 1 person, 153.8ms\n",
      "Speed: 0.6ms preprocess, 153.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/260.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.6ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/700.jpg: 384x640 (no detections), 112.1ms\n",
      "Speed: 0.7ms preprocess, 112.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/270.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.5ms preprocess, 115.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/310.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.5ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/660.jpg: 384x640 (no detections), 123.1ms\n",
      "Speed: 0.5ms preprocess, 123.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/110.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.8ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/460.jpg: 384x640 (no detections), 122.4ms\n",
      "Speed: 0.5ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/500.jpg: 384x640 (no detections), 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/10.jpg: 384x640 1 person, 125.1ms\n",
      "Speed: 0.6ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/120.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/450.jpg: 384x640 (no detections), 122.5ms\n",
      "Speed: 0.7ms preprocess, 122.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/530.jpg: 384x640 1 person, 143.6ms\n",
      "Speed: 0.8ms preprocess, 143.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/280.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/690.jpg: 384x640 (no detections), 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/20.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/490.jpg: 384x640 (no detections), 131.0ms\n",
      "Speed: 0.5ms preprocess, 131.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/240.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/320.jpg: 384x640 1 person, 132.2ms\n",
      "Speed: 0.5ms preprocess, 132.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/650.jpg: 384x640 (no detections), 116.0ms\n",
      "Speed: 0.5ms preprocess, 116.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/640.jpg: 384x640 (no detections), 121.0ms\n",
      "Speed: 0.7ms preprocess, 121.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/330.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/250.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.6ms preprocess, 115.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/480.jpg: 384x640 (no detections), 117.2ms\n",
      "Speed: 0.5ms preprocess, 117.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/680.jpg: 384x640 (no detections), 139.4ms\n",
      "Speed: 0.6ms preprocess, 139.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/30.jpg: 384x640 1 person, 113.9ms\n",
      "Speed: 0.7ms preprocess, 113.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/290.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.5ms preprocess, 124.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/520.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.6ms preprocess, 120.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/440.jpg: 384x640 (no detections), 133.5ms\n",
      "Speed: 0.6ms preprocess, 133.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/130.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.8ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/180.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 1.0ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/590.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/220.jpg: 384x640 1 person, 155.7ms\n",
      "Speed: 0.7ms preprocess, 155.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/340.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/630.jpg: 384x640 (no detections), 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/80.jpg: 384x640 1 person, 134.8ms\n",
      "Speed: 0.5ms preprocess, 134.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/140.jpg: 384x640 1 person, 126.3ms\n",
      "Speed: 0.6ms preprocess, 126.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/430.jpg: 384x640 (no detections), 121.9ms\n",
      "Speed: 0.7ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/550.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/380.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 2.0ms preprocess, 127.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/40.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.7ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/50.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.5ms preprocess, 118.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/390.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/540.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.7ms preprocess, 124.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/420.jpg: 384x640 (no detections), 122.9ms\n",
      "Speed: 0.5ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/150.jpg: 384x640 1 person, 137.8ms\n",
      "Speed: 0.6ms preprocess, 137.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/620.jpg: 384x640 1 person, 128.6ms\n",
      "Speed: 1.6ms preprocess, 128.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/90.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/350.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/230.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.7ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/580.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.7ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/0.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.7ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_1.mp4/190.jpg: 384x640 1 person, 134.1ms\n",
      "Speed: 0.6ms preprocess, 134.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/610.jpg: 384x640 1 person, 123.4ms\n",
      "Speed: 0.6ms preprocess, 123.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/360.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/200.jpg: 384x640 1 person, 130.6ms\n",
      "Speed: 0.6ms preprocess, 130.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/980.jpg: 384x640 1 person, 125.2ms\n",
      "Speed: 0.7ms preprocess, 125.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/770.jpg: 384x640 1 person, 145.6ms\n",
      "Speed: 0.6ms preprocess, 145.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1030.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.6ms preprocess, 123.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/60.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.7ms preprocess, 123.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/820.jpg: 384x640 1 person, 126.9ms\n",
      "Speed: 0.5ms preprocess, 126.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/940.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/570.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/410.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.5ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/160.jpg: 384x640 1 person, 159.8ms\n",
      "Speed: 0.6ms preprocess, 159.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/170.jpg: 384x640 1 person, 131.6ms\n",
      "Speed: 0.6ms preprocess, 131.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/400.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.7ms preprocess, 121.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/560.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.5ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/950.jpg: 384x640 1 person, 129.3ms\n",
      "Speed: 0.6ms preprocess, 129.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/830.jpg: 384x640 1 person, 149.8ms\n",
      "Speed: 0.6ms preprocess, 149.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/70.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.7ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1020.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/990.jpg: 384x640 2 persons, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/760.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/210.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.5ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/370.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.5ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/600.jpg: 384x640 1 person, 149.3ms\n",
      "Speed: 0.6ms preprocess, 149.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/840.jpg: 384x640 1 person, 133.9ms\n",
      "Speed: 0.7ms preprocess, 133.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/920.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1090.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.5ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/510.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.5ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/470.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.6ms preprocess, 124.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/100.jpg: 384x640 1 person, 141.2ms\n",
      "Speed: 0.6ms preprocess, 141.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/880.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/670.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.5ms preprocess, 121.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/300.jpg: 384x640 1 person, 133.7ms\n",
      "Speed: 0.5ms preprocess, 133.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/260.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/710.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1050.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1040.jpg: 384x640 1 person, 139.0ms\n",
      "Speed: 0.5ms preprocess, 139.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/700.jpg: 384x640 1 person, 152.5ms\n",
      "Speed: 0.9ms preprocess, 152.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/270.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/310.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.7ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/890.jpg: 384x640 1 person, 130.7ms\n",
      "Speed: 0.6ms preprocess, 130.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/660.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.9ms preprocess, 121.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/110.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/460.jpg: 384x640 1 person, 139.2ms\n",
      "Speed: 0.6ms preprocess, 139.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1080.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.8ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/500.jpg: 384x640 1 person, 127.4ms\n",
      "Speed: 0.6ms preprocess, 127.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/930.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/850.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.5ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/10.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.6ms preprocess, 120.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/120.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/450.jpg: 384x640 1 person, 136.5ms\n",
      "Speed: 0.5ms preprocess, 136.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/530.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/900.jpg: 384x640 1 person, 157.7ms\n",
      "Speed: 0.6ms preprocess, 157.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/280.jpg: 384x640 1 person, 128.0ms\n",
      "Speed: 0.6ms preprocess, 128.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/690.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.7ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/860.jpg: 384x640 1 person, 132.1ms\n",
      "Speed: 0.6ms preprocess, 132.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/20.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/490.jpg: 384x640 1 person, 144.0ms\n",
      "Speed: 0.6ms preprocess, 144.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1110.jpg: 384x640 1 person, 127.0ms\n",
      "Speed: 0.7ms preprocess, 127.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1070.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.6ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/730.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/240.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/320.jpg: 384x640 1 person, 131.7ms\n",
      "Speed: 0.6ms preprocess, 131.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/650.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/640.jpg: 384x640 1 person, 138.2ms\n",
      "Speed: 0.6ms preprocess, 138.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/330.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.8ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/250.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.7ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/720.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.6ms preprocess, 123.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1060.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.7ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/480.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1100.jpg: 384x640 1 person, 164.9ms\n",
      "Speed: 0.7ms preprocess, 164.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/680.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.5ms preprocess, 121.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/30.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/870.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/290.jpg: 384x640 1 person, 126.4ms\n",
      "Speed: 0.5ms preprocess, 126.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/910.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.5ms preprocess, 120.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/520.jpg: 384x640 1 person, 137.0ms\n",
      "Speed: 0.5ms preprocess, 137.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/440.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/130.jpg: 384x640 1 person, 131.6ms\n",
      "Speed: 0.6ms preprocess, 131.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/180.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.7ms preprocess, 126.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/590.jpg: 384x640 1 person, 129.6ms\n",
      "Speed: 0.6ms preprocess, 129.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1010.jpg: 384x640 1 person, 130.6ms\n",
      "Speed: 0.7ms preprocess, 130.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/750.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.6ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/220.jpg: 384x640 1 person, 152.8ms\n",
      "Speed: 0.6ms preprocess, 152.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/340.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.6ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/630.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/80.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/140.jpg: 384x640 1 person, 132.7ms\n",
      "Speed: 0.5ms preprocess, 132.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/430.jpg: 384x640 1 person, 130.1ms\n",
      "Speed: 0.7ms preprocess, 130.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/550.jpg: 384x640 1 person, 138.6ms\n",
      "Speed: 0.6ms preprocess, 138.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/790.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/960.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/380.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/800.jpg: 384x640 1 person, 135.9ms\n",
      "Speed: 0.5ms preprocess, 135.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/40.jpg: 384x640 2 persons, 142.4ms\n",
      "Speed: 0.5ms preprocess, 142.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/50.jpg: 384x640 2 persons, 135.5ms\n",
      "Speed: 0.6ms preprocess, 135.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/810.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/390.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.6ms preprocess, 125.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/780.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/970.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.6ms preprocess, 122.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/540.jpg: 384x640 2 persons, 137.1ms\n",
      "Speed: 0.6ms preprocess, 137.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/420.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.6ms preprocess, 125.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/150.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 1.0ms preprocess, 124.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/620.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.8ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/90.jpg: 384x640 1 person, 130.8ms\n",
      "Speed: 0.6ms preprocess, 130.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/350.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.7ms preprocess, 127.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/230.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/740.jpg: 384x640 1 person, 138.5ms\n",
      "Speed: 0.8ms preprocess, 138.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/580.jpg: 384x640 2 persons, 123.2ms\n",
      "Speed: 0.7ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/1000.jpg: 384x640 1 person, 124.6ms\n",
      "Speed: 0.6ms preprocess, 124.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/0.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.6ms preprocess, 123.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_4.mp4/190.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/200.jpg: 384x640 1 person, 139.2ms\n",
      "Speed: 0.5ms preprocess, 139.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/60.jpg: 384x640 1 person, 137.2ms\n",
      "Speed: 0.7ms preprocess, 137.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/160.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/170.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/70.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.8ms preprocess, 122.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/210.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/100.jpg: 384x640 1 person, 135.9ms\n",
      "Speed: 0.6ms preprocess, 135.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/110.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.7ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/10.jpg: 384x640 3 persons, 121.7ms\n",
      "Speed: 0.5ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/120.jpg: 384x640 1 person, 136.1ms\n",
      "Speed: 0.6ms preprocess, 136.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/20.jpg: 384x640 1 person, 132.7ms\n",
      "Speed: 0.6ms preprocess, 132.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/240.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/250.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.5ms preprocess, 123.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/30.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/130.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.6ms preprocess, 123.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/180.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.7ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/220.jpg: 384x640 1 person, 135.2ms\n",
      "Speed: 0.5ms preprocess, 135.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/80.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.7ms preprocess, 127.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/140.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/40.jpg: 384x640 1 person, 137.1ms\n",
      "Speed: 0.9ms preprocess, 137.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/50.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.8ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/150.jpg: 384x640 (no detections), 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/90.jpg: 384x640 1 person, 135.4ms\n",
      "Speed: 0.7ms preprocess, 135.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/230.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.6ms preprocess, 125.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/0.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_28.mp4/190.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.7ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/360.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/200.jpg: 384x640 2 persons, 128.2ms\n",
      "Speed: 0.6ms preprocess, 128.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/60.jpg: 384x640 2 persons, 167.6ms\n",
      "Speed: 0.6ms preprocess, 167.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/410.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/160.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.7ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/170.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.6ms preprocess, 124.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/400.jpg: 384x640 2 persons, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/560.jpg: 384x640 (no detections), 134.9ms\n",
      "Speed: 0.6ms preprocess, 134.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/70.jpg: 384x640 2 persons, 123.5ms\n",
      "Speed: 0.7ms preprocess, 123.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/210.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/370.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/510.jpg: 384x640 1 person, 128.1ms\n",
      "Speed: 0.8ms preprocess, 128.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/470.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/100.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.5ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/300.jpg: 384x640 1 person, 148.5ms\n",
      "Speed: 0.5ms preprocess, 148.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/260.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/270.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.6ms preprocess, 123.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/310.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/110.jpg: 384x640 1 person, 131.5ms\n",
      "Speed: 0.6ms preprocess, 131.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/460.jpg: 384x640 1 person, 148.3ms\n",
      "Speed: 0.6ms preprocess, 148.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/500.jpg: 384x640 1 person, 133.4ms\n",
      "Speed: 0.6ms preprocess, 133.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/10.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.7ms preprocess, 120.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/120.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.5ms preprocess, 124.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/450.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/530.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.5ms preprocess, 118.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/280.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/20.jpg: 384x640 1 person, 131.8ms\n",
      "Speed: 0.5ms preprocess, 131.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/490.jpg: 384x640 1 person, 147.0ms\n",
      "Speed: 0.7ms preprocess, 147.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/240.jpg: 384x640 2 persons, 121.6ms\n",
      "Speed: 0.7ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/320.jpg: 384x640 1 person, 151.4ms\n",
      "Speed: 0.6ms preprocess, 151.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/330.jpg: 384x640 2 persons, 139.1ms\n",
      "Speed: 0.6ms preprocess, 139.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/250.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.5ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/480.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/30.jpg: 384x640 1 person, 114.4ms\n",
      "Speed: 0.6ms preprocess, 114.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/290.jpg: 384x640 1 person, 133.9ms\n",
      "Speed: 0.7ms preprocess, 133.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/520.jpg: 384x640 1 person, 114.8ms\n",
      "Speed: 0.8ms preprocess, 114.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/440.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/130.jpg: 384x640 2 persons, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/180.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 0.7ms preprocess, 133.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/220.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/340.jpg: 384x640 1 person, 112.6ms\n",
      "Speed: 0.6ms preprocess, 112.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/80.jpg: 384x640 1 person, 137.4ms\n",
      "Speed: 0.6ms preprocess, 137.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/140.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.7ms preprocess, 125.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/430.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/550.jpg: 384x640 2 persons, 116.4ms\n",
      "Speed: 0.5ms preprocess, 116.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/380.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/40.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/50.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.5ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/390.jpg: 384x640 1 person, 128.8ms\n",
      "Speed: 1.5ms preprocess, 128.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/540.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.6ms preprocess, 127.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/420.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/150.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/90.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/350.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.6ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/230.jpg: 384x640 1 person, 137.1ms\n",
      "Speed: 3.0ms preprocess, 137.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/0.jpg: 384x640 (no detections), 115.3ms\n",
      "Speed: 0.6ms preprocess, 115.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_22.mp4/190.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.6ms preprocess, 126.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/360.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/200.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/60.jpg: 384x640 1 person, 114.5ms\n",
      "Speed: 0.7ms preprocess, 114.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/410.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/160.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.7ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/170.jpg: 384x640 1 person, 126.3ms\n",
      "Speed: 0.7ms preprocess, 126.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/400.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/70.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/210.jpg: 384x640 2 persons, 129.7ms\n",
      "Speed: 0.7ms preprocess, 129.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/370.jpg: 384x640 1 person, 139.8ms\n",
      "Speed: 0.6ms preprocess, 139.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/100.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.8ms preprocess, 126.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/300.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.6ms preprocess, 122.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/260.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/270.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/310.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/110.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.8ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/460.jpg: 384x640 1 person, 137.9ms\n",
      "Speed: 0.6ms preprocess, 137.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/10.jpg: 384x640 1 person, 130.6ms\n",
      "Speed: 0.6ms preprocess, 130.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/120.jpg: 384x640 1 person, 130.5ms\n",
      "Speed: 0.5ms preprocess, 130.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/450.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.5ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/280.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.8ms preprocess, 124.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/20.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/240.jpg: 384x640 1 person, 126.2ms\n",
      "Speed: 0.6ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/320.jpg: 384x640 1 person, 167.4ms\n",
      "Speed: 0.5ms preprocess, 167.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/330.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.7ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/250.jpg: 384x640 1 person, 131.1ms\n",
      "Speed: 0.8ms preprocess, 131.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/30.jpg: 384x640 1 person, 142.6ms\n",
      "Speed: 0.7ms preprocess, 142.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/290.jpg: 384x640 1 person, 133.3ms\n",
      "Speed: 0.8ms preprocess, 133.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/440.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.7ms preprocess, 123.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/130.jpg: 384x640 1 person, 140.2ms\n",
      "Speed: 0.8ms preprocess, 140.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/180.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.7ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/220.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.8ms preprocess, 126.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/340.jpg: 384x640 1 person, 129.5ms\n",
      "Speed: 0.7ms preprocess, 129.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/80.jpg: 384x640 1 person, 131.6ms\n",
      "Speed: 0.8ms preprocess, 131.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/140.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.7ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/430.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.5ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/380.jpg: 384x640 1 person, 147.2ms\n",
      "Speed: 0.6ms preprocess, 147.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/40.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/50.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.5ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/390.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/420.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.6ms preprocess, 125.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/150.jpg: 384x640 1 person, 126.4ms\n",
      "Speed: 1.0ms preprocess, 126.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/90.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/350.jpg: 384x640 1 person, 138.0ms\n",
      "Speed: 0.6ms preprocess, 138.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/230.jpg: 384x640 1 person, 127.1ms\n",
      "Speed: 0.6ms preprocess, 127.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/0.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_04.mp4/190.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.5ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/610.jpg: 384x640 1 person, 140.2ms\n",
      "Speed: 0.6ms preprocess, 140.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/360.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/200.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/770.jpg: 384x640 1 person, 140.0ms\n",
      "Speed: 0.7ms preprocess, 140.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/60.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/820.jpg: 384x640 1 person, 135.3ms\n",
      "Speed: 0.6ms preprocess, 135.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/570.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.5ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/410.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.6ms preprocess, 115.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/160.jpg: 384x640 1 person, 125.2ms\n",
      "Speed: 0.6ms preprocess, 125.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/170.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.7ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/400.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/560.jpg: 384x640 1 person, 134.3ms\n",
      "Speed: 0.5ms preprocess, 134.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/830.jpg: 384x640 1 person, 137.3ms\n",
      "Speed: 0.7ms preprocess, 137.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/70.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.7ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/760.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.5ms preprocess, 118.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/210.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.6ms preprocess, 121.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/370.jpg: 384x640 1 person, 127.1ms\n",
      "Speed: 0.7ms preprocess, 127.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/600.jpg: 384x640 1 person, 133.6ms\n",
      "Speed: 0.7ms preprocess, 133.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/840.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/510.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.5ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/470.jpg: 384x640 1 person, 131.7ms\n",
      "Speed: 0.6ms preprocess, 131.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/100.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.7ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/670.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/300.jpg: 384x640 1 person, 134.6ms\n",
      "Speed: 1.2ms preprocess, 134.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/260.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.7ms preprocess, 122.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/710.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.5ms preprocess, 118.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/700.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/270.jpg: 384x640 1 person, 114.4ms\n",
      "Speed: 0.6ms preprocess, 114.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/310.jpg: 384x640 1 person, 131.6ms\n",
      "Speed: 0.6ms preprocess, 131.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/660.jpg: 384x640 1 person, 136.4ms\n",
      "Speed: 0.6ms preprocess, 136.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/110.jpg: 384x640 1 person, 123.4ms\n",
      "Speed: 0.7ms preprocess, 123.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/460.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/500.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/850.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/10.jpg: 384x640 1 person, 136.4ms\n",
      "Speed: 0.6ms preprocess, 136.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/120.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/450.jpg: 384x640 1 person, 131.3ms\n",
      "Speed: 0.5ms preprocess, 131.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/530.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/280.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.6ms preprocess, 118.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/690.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/860.jpg: 384x640 1 person, 139.0ms\n",
      "Speed: 0.5ms preprocess, 139.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/20.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.6ms preprocess, 117.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/490.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.5ms preprocess, 117.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/730.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/240.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.6ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/320.jpg: 384x640 1 person, 127.1ms\n",
      "Speed: 0.6ms preprocess, 127.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/650.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/640.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.7ms preprocess, 116.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/330.jpg: 384x640 1 person, 135.1ms\n",
      "Speed: 0.6ms preprocess, 135.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/250.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.8ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/720.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.5ms preprocess, 115.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/480.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/680.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.5ms preprocess, 123.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/30.jpg: 384x640 1 person, 128.2ms\n",
      "Speed: 0.5ms preprocess, 128.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/870.jpg: 384x640 1 person, 135.2ms\n",
      "Speed: 0.6ms preprocess, 135.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/290.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.7ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/520.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/440.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/130.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/180.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/590.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.6ms preprocess, 126.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/750.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.7ms preprocess, 118.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/220.jpg: 384x640 1 person, 139.1ms\n",
      "Speed: 1.1ms preprocess, 139.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/340.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/630.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/80.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.5ms preprocess, 115.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/140.jpg: 384x640 1 person, 141.2ms\n",
      "Speed: 0.5ms preprocess, 141.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/430.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.5ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/550.jpg: 384x640 1 person, 127.4ms\n",
      "Speed: 0.6ms preprocess, 127.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/790.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.7ms preprocess, 118.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/380.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/800.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/40.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.5ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/50.jpg: 384x640 1 person, 136.8ms\n",
      "Speed: 0.6ms preprocess, 136.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/810.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/390.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/780.jpg: 384x640 1 person, 129.1ms\n",
      "Speed: 0.7ms preprocess, 129.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/540.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/420.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.5ms preprocess, 119.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/150.jpg: 384x640 1 person, 136.4ms\n",
      "Speed: 0.5ms preprocess, 136.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/620.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.5ms preprocess, 115.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/90.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.5ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/350.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/230.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.5ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/740.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.6ms preprocess, 127.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/580.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.7ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/0.jpg: 384x640 1 person, 135.5ms\n",
      "Speed: 0.5ms preprocess, 135.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13122021_2.mp4/190.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/610.jpg: 384x640 1 person, 114.3ms\n",
      "Speed: 0.5ms preprocess, 114.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/360.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.5ms preprocess, 115.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/200.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.5ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/980.jpg: 384x640 1 person, 158.4ms\n",
      "Speed: 0.6ms preprocess, 158.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/770.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.8ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1030.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1150.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.6ms preprocess, 116.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/60.jpg: 384x640 1 person, 138.9ms\n",
      "Speed: 0.5ms preprocess, 138.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/820.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/940.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.5ms preprocess, 116.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1230.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.5ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/570.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.5ms preprocess, 115.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1190.jpg: 384x640 1 person, 131.7ms\n",
      "Speed: 0.5ms preprocess, 131.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/410.jpg: 384x640 1 person, 132.2ms\n",
      "Speed: 0.6ms preprocess, 132.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/160.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/170.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.6ms preprocess, 117.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1180.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.6ms preprocess, 115.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/400.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.5ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/560.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/950.jpg: 384x640 1 person, 145.0ms\n",
      "Speed: 0.7ms preprocess, 145.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1220.jpg: 384x640 1 person, 130.2ms\n",
      "Speed: 0.7ms preprocess, 130.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/830.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.6ms preprocess, 124.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/70.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.5ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1140.jpg: 384x640 1 person, 115.0ms\n",
      "Speed: 0.6ms preprocess, 115.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1020.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.5ms preprocess, 115.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/990.jpg: 384x640 1 person, 144.5ms\n",
      "Speed: 0.6ms preprocess, 144.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/760.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.6ms preprocess, 116.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/210.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.5ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/370.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.5ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/600.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.8ms preprocess, 118.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/840.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.5ms preprocess, 120.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/920.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.5ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1090.jpg: 384x640 1 person, 132.1ms\n",
      "Speed: 0.6ms preprocess, 132.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/510.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.5ms preprocess, 119.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/470.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/100.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.7ms preprocess, 114.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/880.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.6ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/670.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.7ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/300.jpg: 384x640 1 person, 142.2ms\n",
      "Speed: 0.5ms preprocess, 142.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/260.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/710.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.5ms preprocess, 119.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1050.jpg: 384x640 1 person, 118.2ms\n",
      "Speed: 0.6ms preprocess, 118.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1130.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1120.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.6ms preprocess, 123.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1040.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/700.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/270.jpg: 384x640 1 person, 144.6ms\n",
      "Speed: 0.6ms preprocess, 144.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/310.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/890.jpg: 384x640 1 person, 131.0ms\n",
      "Speed: 0.6ms preprocess, 131.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/660.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/110.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.6ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/460.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1080.jpg: 384x640 1 person, 134.4ms\n",
      "Speed: 0.6ms preprocess, 134.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/500.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/930.jpg: 384x640 1 person, 114.2ms\n",
      "Speed: 0.6ms preprocess, 114.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1240.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/850.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.7ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/10.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.6ms preprocess, 115.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/120.jpg: 384x640 1 person, 148.5ms\n",
      "Speed: 0.7ms preprocess, 148.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/450.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/530.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.6ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/900.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/280.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.7ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/690.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/860.jpg: 384x640 (no detections), 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/20.jpg: 384x640 1 person, 133.1ms\n",
      "Speed: 0.7ms preprocess, 133.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/490.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.6ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1110.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.5ms preprocess, 116.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1070.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/730.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/240.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.5ms preprocess, 116.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/320.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.5ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/650.jpg: 384x640 1 person, 133.6ms\n",
      "Speed: 0.6ms preprocess, 133.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/640.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/330.jpg: 384x640 1 person, 124.1ms\n",
      "Speed: 0.5ms preprocess, 124.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/250.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/720.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.5ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1060.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.6ms preprocess, 115.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/480.jpg: 384x640 1 person, 133.7ms\n",
      "Speed: 0.6ms preprocess, 133.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1100.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.9ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/680.jpg: 384x640 1 person, 112.8ms\n",
      "Speed: 0.6ms preprocess, 112.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/30.jpg: 384x640 1 person, 111.9ms\n",
      "Speed: 0.5ms preprocess, 111.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/870.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/290.jpg: 384x640 1 person, 141.0ms\n",
      "Speed: 0.7ms preprocess, 141.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/910.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.7ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/520.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.5ms preprocess, 115.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/440.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/130.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.6ms preprocess, 116.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/180.jpg: 384x640 1 person, 141.3ms\n",
      "Speed: 0.5ms preprocess, 141.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1170.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.5ms preprocess, 116.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/590.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.6ms preprocess, 125.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1010.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/750.jpg: 384x640 1 person, 113.9ms\n",
      "Speed: 0.6ms preprocess, 113.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/220.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/340.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/630.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.6ms preprocess, 117.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/80.jpg: 384x640 1 person, 133.6ms\n",
      "Speed: 0.6ms preprocess, 133.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/140.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/430.jpg: 384x640 1 person, 114.0ms\n",
      "Speed: 0.5ms preprocess, 114.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/550.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/790.jpg: 384x640 1 person, 134.0ms\n",
      "Speed: 0.5ms preprocess, 134.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1210.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/960.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.5ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/380.jpg: 384x640 1 person, 114.3ms\n",
      "Speed: 0.6ms preprocess, 114.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/800.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.5ms preprocess, 116.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/40.jpg: 384x640 1 person, 131.4ms\n",
      "Speed: 0.6ms preprocess, 131.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/50.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.7ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/810.jpg: 384x640 1 person, 130.5ms\n",
      "Speed: 0.5ms preprocess, 130.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/390.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/780.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1200.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.6ms preprocess, 124.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/970.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/540.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/420.jpg: 384x640 1 person, 138.1ms\n",
      "Speed: 0.5ms preprocess, 138.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/150.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/620.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.8ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/90.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.6ms preprocess, 116.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/350.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.5ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/230.jpg: 384x640 1 person, 138.7ms\n",
      "Speed: 0.6ms preprocess, 138.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/740.jpg: 384x640 1 person, 114.8ms\n",
      "Speed: 0.6ms preprocess, 114.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/580.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.6ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1000.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.6ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/1160.jpg: 384x640 1 person, 133.7ms\n",
      "Speed: 0.6ms preprocess, 133.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/0.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.9ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_4.mp4/190.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/610.jpg: 384x640 2 persons, 138.4ms\n",
      "Speed: 0.7ms preprocess, 138.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/360.jpg: 384x640 3 persons, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/200.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/980.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.5ms preprocess, 117.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/770.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/1030.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.5ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/60.jpg: 384x640 1 person, 141.9ms\n",
      "Speed: 0.6ms preprocess, 141.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/820.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.6ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/940.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/570.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/410.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/160.jpg: 384x640 1 person, 113.4ms\n",
      "Speed: 0.6ms preprocess, 113.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/170.jpg: 384x640 1 person, 132.7ms\n",
      "Speed: 0.6ms preprocess, 132.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/400.jpg: 384x640 (no detections), 117.4ms\n",
      "Speed: 0.5ms preprocess, 117.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/560.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.6ms preprocess, 114.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/950.jpg: 384x640 1 person, 128.2ms\n",
      "Speed: 0.6ms preprocess, 128.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/830.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/70.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.6ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/1020.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.6ms preprocess, 115.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/990.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.5ms preprocess, 118.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/760.jpg: 384x640 1 person, 133.7ms\n",
      "Speed: 0.5ms preprocess, 133.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/210.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.6ms preprocess, 115.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/370.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.6ms preprocess, 114.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/600.jpg: 384x640 1 person, 150.7ms\n",
      "Speed: 0.6ms preprocess, 150.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/840.jpg: 384x640 1 person, 113.1ms\n",
      "Speed: 0.7ms preprocess, 113.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/920.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.7ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/510.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/470.jpg: 384x640 1 person, 146.7ms\n",
      "Speed: 1.5ms preprocess, 146.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/100.jpg: 384x640 1 person, 113.2ms\n",
      "Speed: 0.6ms preprocess, 113.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/880.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.5ms preprocess, 116.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/670.jpg: 384x640 1 person, 139.3ms\n",
      "Speed: 0.6ms preprocess, 139.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/300.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.6ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/260.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.5ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/710.jpg: 384x640 1 person, 134.2ms\n",
      "Speed: 0.5ms preprocess, 134.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/1050.jpg: 384x640 1 person, 114.2ms\n",
      "Speed: 0.6ms preprocess, 114.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/1040.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/700.jpg: 384x640 2 persons, 114.3ms\n",
      "Speed: 0.6ms preprocess, 114.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/270.jpg: 384x640 1 person, 113.5ms\n",
      "Speed: 0.5ms preprocess, 113.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/310.jpg: 384x640 2 persons, 118.9ms\n",
      "Speed: 0.5ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/890.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.5ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/660.jpg: 384x640 1 person, 149.7ms\n",
      "Speed: 0.6ms preprocess, 149.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/110.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/460.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.7ms preprocess, 118.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/500.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/930.jpg: 384x640 1 person, 114.0ms\n",
      "Speed: 0.5ms preprocess, 114.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/850.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.7ms preprocess, 116.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/10.jpg: 384x640 1 person, 132.0ms\n",
      "Speed: 0.5ms preprocess, 132.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/120.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.7ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/450.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.6ms preprocess, 120.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/530.jpg: 384x640 1 person, 113.2ms\n",
      "Speed: 0.6ms preprocess, 113.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/900.jpg: 384x640 1 person, 114.1ms\n",
      "Speed: 0.6ms preprocess, 114.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/280.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/690.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/860.jpg: 384x640 1 person, 151.6ms\n",
      "Speed: 0.6ms preprocess, 151.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/20.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/490.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/1070.jpg: 384x640 3 persons, 127.8ms\n",
      "Speed: 0.6ms preprocess, 127.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/730.jpg: 384x640 1 person, 114.8ms\n",
      "Speed: 0.6ms preprocess, 114.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/240.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.6ms preprocess, 115.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/320.jpg: 384x640 2 persons, 119.5ms\n",
      "Speed: 0.5ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/650.jpg: 384x640 1 person, 148.2ms\n",
      "Speed: 0.6ms preprocess, 148.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/640.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.7ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/330.jpg: 384x640 1 person, 116.5ms\n",
      "Speed: 0.6ms preprocess, 116.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/250.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/720.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.5ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/1060.jpg: 384x640 1 person, 114.5ms\n",
      "Speed: 0.6ms preprocess, 114.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/480.jpg: 384x640 1 person, 115.2ms\n",
      "Speed: 0.6ms preprocess, 115.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/680.jpg: 384x640 1 person, 134.2ms\n",
      "Speed: 0.6ms preprocess, 134.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/30.jpg: 384x640 1 person, 126.1ms\n",
      "Speed: 0.6ms preprocess, 126.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/870.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/290.jpg: 384x640 2 persons, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/910.jpg: 384x640 1 person, 114.6ms\n",
      "Speed: 0.5ms preprocess, 114.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/520.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.5ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/440.jpg: 384x640 1 person, 129.6ms\n",
      "Speed: 0.8ms preprocess, 129.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/130.jpg: 384x640 1 person, 112.0ms\n",
      "Speed: 0.7ms preprocess, 112.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/180.jpg: 384x640 1 person, 111.8ms\n",
      "Speed: 0.6ms preprocess, 111.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/590.jpg: 384x640 1 person, 112.5ms\n",
      "Speed: 0.6ms preprocess, 112.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/1010.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.7ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/750.jpg: 384x640 1 person, 108.9ms\n",
      "Speed: 0.6ms preprocess, 108.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/220.jpg: 384x640 1 person, 112.9ms\n",
      "Speed: 0.5ms preprocess, 112.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/340.jpg: 384x640 2 persons, 140.3ms\n",
      "Speed: 0.5ms preprocess, 140.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/630.jpg: 384x640 2 persons, 111.7ms\n",
      "Speed: 0.6ms preprocess, 111.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/80.jpg: 384x640 1 person, 109.8ms\n",
      "Speed: 0.7ms preprocess, 109.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/140.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.5ms preprocess, 116.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/430.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.6ms preprocess, 115.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/550.jpg: 384x640 1 person, 131.6ms\n",
      "Speed: 0.6ms preprocess, 131.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/790.jpg: 384x640 1 person, 142.4ms\n",
      "Speed: 0.6ms preprocess, 142.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/960.jpg: 384x640 1 person, 112.1ms\n",
      "Speed: 0.6ms preprocess, 112.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/380.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.7ms preprocess, 122.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/800.jpg: 384x640 1 person, 111.9ms\n",
      "Speed: 0.6ms preprocess, 111.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/40.jpg: 384x640 1 person, 138.9ms\n",
      "Speed: 0.6ms preprocess, 138.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/50.jpg: 384x640 1 person, 134.2ms\n",
      "Speed: 0.7ms preprocess, 134.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/810.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.5ms preprocess, 115.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/390.jpg: 384x640 1 person, 114.0ms\n",
      "Speed: 0.6ms preprocess, 114.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/780.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/970.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.5ms preprocess, 119.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/540.jpg: 384x640 1 person, 112.1ms\n",
      "Speed: 0.7ms preprocess, 112.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/420.jpg: 384x640 1 person, 134.1ms\n",
      "Speed: 0.6ms preprocess, 134.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/150.jpg: 384x640 1 person, 110.6ms\n",
      "Speed: 0.6ms preprocess, 110.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/620.jpg: 384x640 1 person, 112.3ms\n",
      "Speed: 0.5ms preprocess, 112.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/90.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/350.jpg: 384x640 2 persons, 111.4ms\n",
      "Speed: 0.6ms preprocess, 111.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/230.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.5ms preprocess, 121.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/740.jpg: 384x640 1 person, 111.5ms\n",
      "Speed: 0.6ms preprocess, 111.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/580.jpg: 384x640 1 person, 133.1ms\n",
      "Speed: 0.6ms preprocess, 133.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/1000.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/0.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_5.mp4/190.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.7ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/200.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/60.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/160.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.5ms preprocess, 115.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/170.jpg: 384x640 1 person, 131.2ms\n",
      "Speed: 0.5ms preprocess, 131.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/70.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/210.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/100.jpg: 384x640 2 persons, 115.3ms\n",
      "Speed: 0.5ms preprocess, 115.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/260.jpg: 384x640 1 person, 129.6ms\n",
      "Speed: 0.7ms preprocess, 129.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/270.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.8ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/110.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.7ms preprocess, 121.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/10.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.5ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/120.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/280.jpg: 384x640 1 person, 114.0ms\n",
      "Speed: 0.5ms preprocess, 114.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/20.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/240.jpg: 384x640 1 person, 133.0ms\n",
      "Speed: 0.5ms preprocess, 133.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/250.jpg: 384x640 1 person, 130.1ms\n",
      "Speed: 0.7ms preprocess, 130.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/30.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.5ms preprocess, 119.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/130.jpg: 384x640 1 person, 114.3ms\n",
      "Speed: 0.5ms preprocess, 114.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/180.jpg: 384x640 1 person, 112.9ms\n",
      "Speed: 0.5ms preprocess, 112.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/220.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/80.jpg: 384x640 1 person, 134.1ms\n",
      "Speed: 0.6ms preprocess, 134.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/140.jpg: 384x640 1 person, 115.4ms\n",
      "Speed: 0.6ms preprocess, 115.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/40.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.5ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/50.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.6ms preprocess, 123.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/150.jpg: 384x640 1 person, 112.9ms\n",
      "Speed: 0.5ms preprocess, 112.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/90.jpg: 384x640 2 persons, 116.1ms\n",
      "Speed: 0.5ms preprocess, 116.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/230.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/0.jpg: 384x640 1 person, 133.2ms\n",
      "Speed: 0.5ms preprocess, 133.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_1.mp4/190.jpg: 384x640 1 person, 114.2ms\n",
      "Speed: 0.5ms preprocess, 114.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/360.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/200.jpg: 384x640 1 person, 126.2ms\n",
      "Speed: 0.6ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/60.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.5ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/410.jpg: 384x640 1 person, 140.4ms\n",
      "Speed: 0.7ms preprocess, 140.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/160.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.7ms preprocess, 125.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/170.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.5ms preprocess, 118.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/400.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/70.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 0.5ms preprocess, 133.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/210.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/370.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/100.jpg: 384x640 1 person, 149.8ms\n",
      "Speed: 0.6ms preprocess, 149.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/300.jpg: 384x640 1 person, 131.2ms\n",
      "Speed: 0.6ms preprocess, 131.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/260.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.6ms preprocess, 120.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/270.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/310.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.6ms preprocess, 127.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/110.jpg: 384x640 1 person, 145.6ms\n",
      "Speed: 0.6ms preprocess, 145.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/10.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.5ms preprocess, 122.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/120.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/280.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.6ms preprocess, 124.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/20.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.5ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/240.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.7ms preprocess, 128.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/320.jpg: 384x640 1 person, 157.5ms\n",
      "Speed: 0.9ms preprocess, 157.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/330.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.7ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/250.jpg: 384x640 1 person, 130.9ms\n",
      "Speed: 0.6ms preprocess, 130.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/30.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.6ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/290.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/130.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.5ms preprocess, 118.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/180.jpg: 384x640 1 person, 149.1ms\n",
      "Speed: 0.7ms preprocess, 149.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/220.jpg: 384x640 1 person, 185.7ms\n",
      "Speed: 0.6ms preprocess, 185.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/340.jpg: 384x640 1 person, 134.9ms\n",
      "Speed: 0.7ms preprocess, 134.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/80.jpg: 384x640 1 person, 136.2ms\n",
      "Speed: 1.3ms preprocess, 136.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/140.jpg: 384x640 1 person, 132.2ms\n",
      "Speed: 0.6ms preprocess, 132.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/430.jpg: 384x640 1 person, 143.5ms\n",
      "Speed: 0.6ms preprocess, 143.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/380.jpg: 384x640 1 person, 193.1ms\n",
      "Speed: 0.9ms preprocess, 193.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/40.jpg: 384x640 1 person, 138.5ms\n",
      "Speed: 0.6ms preprocess, 138.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/50.jpg: 384x640 1 person, 131.5ms\n",
      "Speed: 0.8ms preprocess, 131.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/390.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.6ms preprocess, 127.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/420.jpg: 384x640 1 person, 179.1ms\n",
      "Speed: 0.6ms preprocess, 179.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/150.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.6ms preprocess, 137.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/90.jpg: 384x640 1 person, 131.3ms\n",
      "Speed: 0.6ms preprocess, 131.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/350.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.6ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/230.jpg: 384x640 1 person, 130.8ms\n",
      "Speed: 0.6ms preprocess, 130.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/0.jpg: 384x640 1 person, 165.8ms\n",
      "Speed: 0.6ms preprocess, 165.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_23022022_05.mp4/190.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.7ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/60.jpg: 384x640 1 person, 143.5ms\n",
      "Speed: 0.7ms preprocess, 143.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/160.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.8ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/170.jpg: 384x640 1 person, 142.9ms\n",
      "Speed: 0.6ms preprocess, 142.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/70.jpg: 384x640 1 person, 136.2ms\n",
      "Speed: 0.8ms preprocess, 136.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/100.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.6ms preprocess, 126.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/110.jpg: 384x640 1 person, 135.6ms\n",
      "Speed: 0.6ms preprocess, 135.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/10.jpg: 384x640 1 person, 134.5ms\n",
      "Speed: 0.6ms preprocess, 134.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/120.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/20.jpg: 384x640 1 person, 140.8ms\n",
      "Speed: 0.6ms preprocess, 140.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/30.jpg: 384x640 1 person, 128.2ms\n",
      "Speed: 0.8ms preprocess, 128.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/130.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/180.jpg: 384x640 1 person, 133.0ms\n",
      "Speed: 0.7ms preprocess, 133.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/80.jpg: 384x640 1 person, 148.1ms\n",
      "Speed: 0.6ms preprocess, 148.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/140.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.7ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/40.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.7ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/50.jpg: 384x640 1 person, 129.3ms\n",
      "Speed: 0.6ms preprocess, 129.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/150.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/90.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.6ms preprocess, 124.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/0.jpg: 384x640 1 person, 160.9ms\n",
      "Speed: 0.6ms preprocess, 160.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_21.mp4/190.jpg: 384x640 1 person, 136.3ms\n",
      "Speed: 0.8ms preprocess, 136.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/610.jpg: 384x640 1 person, 128.2ms\n",
      "Speed: 0.6ms preprocess, 128.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/360.jpg: 384x640 1 person, 128.2ms\n",
      "Speed: 0.8ms preprocess, 128.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/200.jpg: 384x640 1 person, 139.8ms\n",
      "Speed: 0.6ms preprocess, 139.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/980.jpg: 384x640 1 person, 129.6ms\n",
      "Speed: 0.6ms preprocess, 129.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/770.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.7ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1030.jpg: 384x640 1 person, 135.0ms\n",
      "Speed: 0.6ms preprocess, 135.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/60.jpg: 384x640 1 person, 158.2ms\n",
      "Speed: 0.7ms preprocess, 158.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/820.jpg: 384x640 1 person, 124.1ms\n",
      "Speed: 0.6ms preprocess, 124.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/940.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/570.jpg: 384x640 1 person, 126.2ms\n",
      "Speed: 0.7ms preprocess, 126.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/410.jpg: 384x640 1 person, 125.1ms\n",
      "Speed: 0.8ms preprocess, 125.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/160.jpg: 384x640 1 person, 153.5ms\n",
      "Speed: 0.6ms preprocess, 153.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/170.jpg: 384x640 1 person, 132.4ms\n",
      "Speed: 0.6ms preprocess, 132.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/400.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.7ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/560.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/950.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.6ms preprocess, 123.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/830.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.6ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/70.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.6ms preprocess, 127.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1020.jpg: 384x640 1 person, 148.2ms\n",
      "Speed: 0.7ms preprocess, 148.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/990.jpg: 384x640 1 person, 149.6ms\n",
      "Speed: 0.6ms preprocess, 149.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/760.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.7ms preprocess, 125.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/210.jpg: 384x640 1 person, 129.6ms\n",
      "Speed: 0.6ms preprocess, 129.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/370.jpg: 384x640 1 person, 142.2ms\n",
      "Speed: 0.6ms preprocess, 142.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/600.jpg: 384x640 1 person, 147.9ms\n",
      "Speed: 0.6ms preprocess, 147.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/840.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 0.6ms preprocess, 127.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/920.jpg: 384x640 1 person, 133.0ms\n",
      "Speed: 0.8ms preprocess, 133.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1090.jpg: 384x640 1 person, 133.3ms\n",
      "Speed: 0.5ms preprocess, 133.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/510.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 0.7ms preprocess, 127.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/470.jpg: 384x640 1 person, 132.0ms\n",
      "Speed: 0.6ms preprocess, 132.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/100.jpg: 384x640 1 person, 149.7ms\n",
      "Speed: 0.8ms preprocess, 149.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/880.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.6ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/670.jpg: 384x640 1 person, 185.5ms\n",
      "Speed: 0.6ms preprocess, 185.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/300.jpg: 384x640 1 person, 142.1ms\n",
      "Speed: 0.9ms preprocess, 142.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/260.jpg: 384x640 1 person, 133.6ms\n",
      "Speed: 0.6ms preprocess, 133.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/710.jpg: 384x640 1 person, 159.3ms\n",
      "Speed: 0.7ms preprocess, 159.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1050.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.7ms preprocess, 124.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1040.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/700.jpg: 384x640 1 person, 129.4ms\n",
      "Speed: 0.7ms preprocess, 129.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/270.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.7ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/310.jpg: 384x640 1 person, 126.1ms\n",
      "Speed: 0.6ms preprocess, 126.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/890.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.7ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/660.jpg: 384x640 1 person, 154.3ms\n",
      "Speed: 0.7ms preprocess, 154.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/110.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.6ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/460.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.7ms preprocess, 123.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1080.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.6ms preprocess, 125.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/500.jpg: 384x640 1 person, 131.5ms\n",
      "Speed: 0.6ms preprocess, 131.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/930.jpg: 384x640 1 person, 145.9ms\n",
      "Speed: 0.6ms preprocess, 145.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/850.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/10.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.6ms preprocess, 127.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/120.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.6ms preprocess, 123.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/450.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/530.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/900.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/280.jpg: 384x640 1 person, 155.5ms\n",
      "Speed: 0.6ms preprocess, 155.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/690.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/860.jpg: 384x640 1 person, 141.7ms\n",
      "Speed: 0.8ms preprocess, 141.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/20.jpg: 384x640 1 person, 134.2ms\n",
      "Speed: 0.8ms preprocess, 134.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/490.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.6ms preprocess, 127.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1070.jpg: 384x640 1 person, 147.5ms\n",
      "Speed: 0.7ms preprocess, 147.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/730.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.7ms preprocess, 127.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/240.jpg: 384x640 1 person, 135.3ms\n",
      "Speed: 0.7ms preprocess, 135.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/320.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.6ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/650.jpg: 384x640 1 person, 139.7ms\n",
      "Speed: 0.5ms preprocess, 139.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/640.jpg: 384x640 1 person, 128.6ms\n",
      "Speed: 0.8ms preprocess, 128.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/330.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/250.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.7ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/720.jpg: 384x640 1 person, 155.8ms\n",
      "Speed: 0.8ms preprocess, 155.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1060.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.7ms preprocess, 119.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/480.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1100.jpg: 384x640 1 person, 150.3ms\n",
      "Speed: 0.6ms preprocess, 150.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/680.jpg: 384x640 1 person, 139.3ms\n",
      "Speed: 0.8ms preprocess, 139.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/30.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/870.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/290.jpg: 384x640 1 person, 132.8ms\n",
      "Speed: 0.5ms preprocess, 132.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/910.jpg: 384x640 1 person, 138.4ms\n",
      "Speed: 0.6ms preprocess, 138.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/520.jpg: 384x640 1 person, 127.4ms\n",
      "Speed: 0.7ms preprocess, 127.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/440.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/130.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/180.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/590.jpg: 384x640 1 person, 138.9ms\n",
      "Speed: 0.6ms preprocess, 138.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1010.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.5ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/750.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/220.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.6ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/340.jpg: 384x640 1 person, 140.4ms\n",
      "Speed: 0.6ms preprocess, 140.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/630.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.7ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/80.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/140.jpg: 384x640 1 person, 136.5ms\n",
      "Speed: 0.5ms preprocess, 136.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/430.jpg: 384x640 1 person, 141.6ms\n",
      "Speed: 0.8ms preprocess, 141.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/550.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/790.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.5ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/960.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.6ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/380.jpg: 384x640 1 person, 152.0ms\n",
      "Speed: 0.6ms preprocess, 152.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/800.jpg: 384x640 1 person, 138.9ms\n",
      "Speed: 0.6ms preprocess, 138.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/40.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/50.jpg: 384x640 1 person, 126.5ms\n",
      "Speed: 0.5ms preprocess, 126.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/810.jpg: 384x640 1 person, 136.6ms\n",
      "Speed: 0.7ms preprocess, 136.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/390.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/780.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.5ms preprocess, 119.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/970.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.6ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/540.jpg: 384x640 1 person, 160.4ms\n",
      "Speed: 0.6ms preprocess, 160.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/420.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/150.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.5ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/620.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.6ms preprocess, 125.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/90.jpg: 384x640 1 person, 139.9ms\n",
      "Speed: 0.6ms preprocess, 139.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/350.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.8ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/230.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.5ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/740.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/580.jpg: 384x640 1 person, 135.0ms\n",
      "Speed: 1.3ms preprocess, 135.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/1000.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/0.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.7ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_3.mp4/190.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.5ms preprocess, 118.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/610.jpg: 384x640 1 person, 138.3ms\n",
      "Speed: 0.5ms preprocess, 138.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/360.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.6ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/200.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.8ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/770.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.7ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/60.jpg: 384x640 1 person, 139.8ms\n",
      "Speed: 0.7ms preprocess, 139.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/570.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/410.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.6ms preprocess, 115.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/160.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.6ms preprocess, 115.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/170.jpg: 384x640 1 person, 139.3ms\n",
      "Speed: 0.5ms preprocess, 139.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/400.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.8ms preprocess, 121.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/560.jpg: 384x640 1 person, 119.3ms\n",
      "Speed: 0.6ms preprocess, 119.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/70.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/760.jpg: 384x640 1 person, 149.8ms\n",
      "Speed: 0.6ms preprocess, 149.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/210.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.5ms preprocess, 117.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/370.jpg: 384x640 1 person, 126.1ms\n",
      "Speed: 0.6ms preprocess, 126.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/600.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.6ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/510.jpg: 384x640 1 person, 128.4ms\n",
      "Speed: 2.3ms preprocess, 128.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/470.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/100.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/670.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/300.jpg: 384x640 1 person, 134.4ms\n",
      "Speed: 0.6ms preprocess, 134.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/260.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/710.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/700.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.5ms preprocess, 115.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/270.jpg: 384x640 1 person, 148.6ms\n",
      "Speed: 0.6ms preprocess, 148.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/310.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.5ms preprocess, 119.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/660.jpg: 384x640 1 person, 115.6ms\n",
      "Speed: 0.5ms preprocess, 115.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/110.jpg: 384x640 1 person, 137.5ms\n",
      "Speed: 0.5ms preprocess, 137.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/460.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 2.6ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/500.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.6ms preprocess, 116.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/10.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.6ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/120.jpg: 384x640 1 person, 145.7ms\n",
      "Speed: 0.6ms preprocess, 145.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/450.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.6ms preprocess, 121.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/530.jpg: 384x640 1 person, 131.0ms\n",
      "Speed: 0.7ms preprocess, 131.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/280.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.6ms preprocess, 123.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/690.jpg: 384x640 1 person, 137.6ms\n",
      "Speed: 0.7ms preprocess, 137.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/20.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.7ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/490.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/730.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.5ms preprocess, 120.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/240.jpg: 384x640 1 person, 140.0ms\n",
      "Speed: 0.6ms preprocess, 140.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/320.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.8ms preprocess, 121.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/650.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.6ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/640.jpg: 384x640 1 person, 148.6ms\n",
      "Speed: 0.7ms preprocess, 148.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/330.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.5ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/250.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.6ms preprocess, 126.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/720.jpg: 384x640 1 person, 139.2ms\n",
      "Speed: 0.7ms preprocess, 139.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/480.jpg: 384x640 1 person, 156.3ms\n",
      "Speed: 5.2ms preprocess, 156.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/680.jpg: 384x640 2 persons, 152.1ms\n",
      "Speed: 0.6ms preprocess, 152.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/30.jpg: 384x640 2 persons, 138.4ms\n",
      "Speed: 0.8ms preprocess, 138.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/290.jpg: 384x640 1 person, 159.2ms\n",
      "Speed: 1.0ms preprocess, 159.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/520.jpg: 384x640 1 person, 129.2ms\n",
      "Speed: 0.6ms preprocess, 129.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/440.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.6ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/130.jpg: 384x640 1 person, 144.2ms\n",
      "Speed: 0.6ms preprocess, 144.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/180.jpg: 384x640 1 person, 131.7ms\n",
      "Speed: 0.6ms preprocess, 131.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/590.jpg: 384x640 1 person, 117.9ms\n",
      "Speed: 0.7ms preprocess, 117.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/750.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.7ms preprocess, 116.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/220.jpg: 384x640 1 person, 129.2ms\n",
      "Speed: 0.7ms preprocess, 129.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/340.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 0.8ms preprocess, 127.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/630.jpg: 384x640 1 person, 143.8ms\n",
      "Speed: 0.7ms preprocess, 143.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/80.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/140.jpg: 384x640 1 person, 142.6ms\n",
      "Speed: 0.6ms preprocess, 142.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/430.jpg: 384x640 2 persons, 126.5ms\n",
      "Speed: 0.6ms preprocess, 126.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/550.jpg: 384x640 1 person, 129.8ms\n",
      "Speed: 0.6ms preprocess, 129.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/790.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/380.jpg: 384x640 1 person, 134.3ms\n",
      "Speed: 0.6ms preprocess, 134.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/800.jpg: 384x640 1 person, 118.6ms\n",
      "Speed: 0.6ms preprocess, 118.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/40.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.5ms preprocess, 122.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/50.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.5ms preprocess, 122.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/810.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/390.jpg: 384x640 1 person, 135.4ms\n",
      "Speed: 0.6ms preprocess, 135.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/780.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.7ms preprocess, 123.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/540.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.7ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/420.jpg: 384x640 1 person, 141.4ms\n",
      "Speed: 0.7ms preprocess, 141.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/150.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.9ms preprocess, 124.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/620.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/90.jpg: 384x640 1 person, 135.2ms\n",
      "Speed: 0.6ms preprocess, 135.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/350.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.7ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/230.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/740.jpg: 384x640 1 person, 141.2ms\n",
      "Speed: 0.8ms preprocess, 141.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/580.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.8ms preprocess, 123.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/0.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.6ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_7.mp4/190.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/360.jpg: 384x640 2 persons, 134.2ms\n",
      "Speed: 1.5ms preprocess, 134.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/200.jpg: 384x640 1 person, 134.1ms\n",
      "Speed: 0.6ms preprocess, 134.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/60.jpg: 384x640 2 persons, 143.4ms\n",
      "Speed: 0.6ms preprocess, 143.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/570.jpg: 384x640 2 persons, 125.8ms\n",
      "Speed: 0.9ms preprocess, 125.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/410.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/160.jpg: 384x640 2 persons, 136.4ms\n",
      "Speed: 0.6ms preprocess, 136.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/170.jpg: 384x640 2 persons, 109.5ms\n",
      "Speed: 0.8ms preprocess, 109.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/400.jpg: 384x640 2 persons, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/560.jpg: 384x640 3 persons, 144.0ms\n",
      "Speed: 0.6ms preprocess, 144.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/70.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.6ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/210.jpg: 384x640 2 persons, 128.6ms\n",
      "Speed: 0.6ms preprocess, 128.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/370.jpg: 384x640 2 persons, 148.4ms\n",
      "Speed: 0.8ms preprocess, 148.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/510.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/470.jpg: 384x640 1 person, 130.0ms\n",
      "Speed: 0.6ms preprocess, 130.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/100.jpg: 384x640 1 person, 137.2ms\n",
      "Speed: 0.7ms preprocess, 137.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/300.jpg: 384x640 1 person, 132.9ms\n",
      "Speed: 0.7ms preprocess, 132.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/260.jpg: 384x640 1 person, 127.4ms\n",
      "Speed: 0.6ms preprocess, 127.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/270.jpg: 384x640 1 person, 150.2ms\n",
      "Speed: 0.6ms preprocess, 150.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/310.jpg: 384x640 1 person, 128.2ms\n",
      "Speed: 0.7ms preprocess, 128.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/110.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.8ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/460.jpg: 384x640 1 person, 154.9ms\n",
      "Speed: 0.6ms preprocess, 154.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/500.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.7ms preprocess, 125.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/10.jpg: 384x640 1 person, 114.7ms\n",
      "Speed: 0.5ms preprocess, 114.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/120.jpg: 384x640 2 persons, 115.6ms\n",
      "Speed: 0.5ms preprocess, 115.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/450.jpg: 384x640 1 person, 150.0ms\n",
      "Speed: 0.7ms preprocess, 150.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/530.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.6ms preprocess, 121.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/280.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.6ms preprocess, 115.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/20.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.6ms preprocess, 116.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/490.jpg: 384x640 1 person, 137.3ms\n",
      "Speed: 2.4ms preprocess, 137.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/240.jpg: 384x640 1 person, 131.0ms\n",
      "Speed: 0.6ms preprocess, 131.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/320.jpg: 384x640 2 persons, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/330.jpg: 384x640 2 persons, 143.8ms\n",
      "Speed: 0.6ms preprocess, 143.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/250.jpg: 384x640 2 persons, 126.4ms\n",
      "Speed: 0.8ms preprocess, 126.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/480.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/30.jpg: 384x640 2 persons, 146.1ms\n",
      "Speed: 0.7ms preprocess, 146.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/290.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/520.jpg: 384x640 2 persons, 128.5ms\n",
      "Speed: 0.6ms preprocess, 128.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/440.jpg: 384x640 1 person, 147.2ms\n",
      "Speed: 0.6ms preprocess, 147.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/130.jpg: 384x640 2 persons, 123.9ms\n",
      "Speed: 0.8ms preprocess, 123.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/180.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.7ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/590.jpg: 384x640 2 persons, 144.2ms\n",
      "Speed: 0.7ms preprocess, 144.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/220.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.6ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/340.jpg: 384x640 2 persons, 125.1ms\n",
      "Speed: 0.6ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/80.jpg: 384x640 2 persons, 131.1ms\n",
      "Speed: 0.8ms preprocess, 131.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/140.jpg: 384x640 1 person, 130.4ms\n",
      "Speed: 2.1ms preprocess, 130.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/430.jpg: 384x640 2 persons, 141.5ms\n",
      "Speed: 0.6ms preprocess, 141.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/550.jpg: 384x640 2 persons, 135.2ms\n",
      "Speed: 0.6ms preprocess, 135.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/380.jpg: 384x640 2 persons, 124.3ms\n",
      "Speed: 0.7ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/40.jpg: 384x640 2 persons, 144.8ms\n",
      "Speed: 0.7ms preprocess, 144.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/50.jpg: 384x640 2 persons, 131.5ms\n",
      "Speed: 0.7ms preprocess, 131.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/390.jpg: 384x640 2 persons, 127.2ms\n",
      "Speed: 0.7ms preprocess, 127.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/540.jpg: 384x640 2 persons, 143.5ms\n",
      "Speed: 0.8ms preprocess, 143.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/420.jpg: 384x640 2 persons, 125.6ms\n",
      "Speed: 0.8ms preprocess, 125.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/150.jpg: 384x640 1 person, 145.9ms\n",
      "Speed: 0.8ms preprocess, 145.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/90.jpg: 384x640 2 persons, 148.8ms\n",
      "Speed: 0.7ms preprocess, 148.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/350.jpg: 384x640 2 persons, 132.3ms\n",
      "Speed: 0.7ms preprocess, 132.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/230.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 0.6ms preprocess, 127.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/580.jpg: 384x640 2 persons, 120.2ms\n",
      "Speed: 0.5ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/0.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.5ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_13012022_6.mp4/190.jpg: 384x640 1 person, 134.9ms\n",
      "Speed: 0.5ms preprocess, 134.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/610.jpg: 384x640 1 person, 130.5ms\n",
      "Speed: 0.6ms preprocess, 130.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/360.jpg: 384x640 1 person, 130.1ms\n",
      "Speed: 0.6ms preprocess, 130.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/200.jpg: 384x640 1 person, 145.3ms\n",
      "Speed: 0.6ms preprocess, 145.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/770.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.6ms preprocess, 125.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/60.jpg: 384x640 1 person, 138.4ms\n",
      "Speed: 0.8ms preprocess, 138.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/820.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.6ms preprocess, 125.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/940.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.6ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/570.jpg: 384x640 1 person, 189.6ms\n",
      "Speed: 0.6ms preprocess, 189.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/410.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 0.8ms preprocess, 127.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/160.jpg: 384x640 1 person, 132.1ms\n",
      "Speed: 0.6ms preprocess, 132.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/170.jpg: 384x640 1 person, 163.5ms\n",
      "Speed: 0.6ms preprocess, 163.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/400.jpg: 384x640 1 person, 156.9ms\n",
      "Speed: 0.8ms preprocess, 156.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/560.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.6ms preprocess, 127.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/950.jpg: 384x640 1 person, 129.6ms\n",
      "Speed: 0.6ms preprocess, 129.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/830.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.6ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/70.jpg: 384x640 1 person, 142.4ms\n",
      "Speed: 0.5ms preprocess, 142.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/760.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/210.jpg: 384x640 1 person, 120.1ms\n",
      "Speed: 0.6ms preprocess, 120.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/370.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.5ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/600.jpg: 384x640 1 person, 152.5ms\n",
      "Speed: 0.6ms preprocess, 152.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/840.jpg: 384x640 1 person, 130.3ms\n",
      "Speed: 1.2ms preprocess, 130.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/920.jpg: 384x640 1 person, 135.3ms\n",
      "Speed: 0.6ms preprocess, 135.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/510.jpg: 384x640 1 person, 126.4ms\n",
      "Speed: 0.8ms preprocess, 126.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/470.jpg: 384x640 1 person, 151.9ms\n",
      "Speed: 0.6ms preprocess, 151.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/100.jpg: 384x640 1 person, 133.4ms\n",
      "Speed: 0.6ms preprocess, 133.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/880.jpg: 384x640 1 person, 134.3ms\n",
      "Speed: 0.7ms preprocess, 134.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/670.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/300.jpg: 384x640 1 person, 142.6ms\n",
      "Speed: 0.8ms preprocess, 142.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/260.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.6ms preprocess, 125.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/710.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 0.6ms preprocess, 133.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/700.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.6ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/270.jpg: 384x640 1 person, 146.4ms\n",
      "Speed: 0.8ms preprocess, 146.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/310.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.8ms preprocess, 132.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/890.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.7ms preprocess, 123.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/660.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.8ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/110.jpg: 384x640 1 person, 135.1ms\n",
      "Speed: 0.6ms preprocess, 135.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/460.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.8ms preprocess, 137.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/500.jpg: 384x640 1 person, 139.0ms\n",
      "Speed: 0.6ms preprocess, 139.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/930.jpg: 384x640 1 person, 141.8ms\n",
      "Speed: 0.6ms preprocess, 141.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/850.jpg: 384x640 1 person, 139.9ms\n",
      "Speed: 0.6ms preprocess, 139.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/10.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.9ms preprocess, 123.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/120.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.5ms preprocess, 121.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/450.jpg: 384x640 1 person, 145.9ms\n",
      "Speed: 0.7ms preprocess, 145.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/530.jpg: 384x640 1 person, 176.2ms\n",
      "Speed: 0.6ms preprocess, 176.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/900.jpg: 384x640 1 person, 141.7ms\n",
      "Speed: 0.7ms preprocess, 141.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/280.jpg: 384x640 1 person, 133.0ms\n",
      "Speed: 0.6ms preprocess, 133.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/690.jpg: 384x640 1 person, 144.6ms\n",
      "Speed: 0.6ms preprocess, 144.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/860.jpg: 384x640 1 person, 149.9ms\n",
      "Speed: 0.5ms preprocess, 149.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/20.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/490.jpg: 384x640 1 person, 141.4ms\n",
      "Speed: 0.5ms preprocess, 141.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/730.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.6ms preprocess, 123.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/240.jpg: 384x640 1 person, 149.7ms\n",
      "Speed: 0.6ms preprocess, 149.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/320.jpg: 384x640 1 person, 135.3ms\n",
      "Speed: 0.6ms preprocess, 135.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/650.jpg: 384x640 1 person, 128.1ms\n",
      "Speed: 0.7ms preprocess, 128.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/640.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/330.jpg: 384x640 1 person, 170.5ms\n",
      "Speed: 0.5ms preprocess, 170.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/250.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/720.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/480.jpg: 384x640 1 person, 137.1ms\n",
      "Speed: 0.6ms preprocess, 137.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/680.jpg: 384x640 1 person, 158.9ms\n",
      "Speed: 0.6ms preprocess, 158.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/30.jpg: 384x640 1 person, 128.9ms\n",
      "Speed: 0.8ms preprocess, 128.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/870.jpg: 384x640 1 person, 140.3ms\n",
      "Speed: 0.6ms preprocess, 140.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/290.jpg: 384x640 1 person, 145.2ms\n",
      "Speed: 0.6ms preprocess, 145.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/910.jpg: 384x640 1 person, 125.1ms\n",
      "Speed: 0.6ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/520.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.5ms preprocess, 127.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/440.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.7ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/130.jpg: 384x640 1 person, 136.6ms\n",
      "Speed: 0.6ms preprocess, 136.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/180.jpg: 384x640 1 person, 177.0ms\n",
      "Speed: 0.6ms preprocess, 177.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/590.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.7ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/750.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/220.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/340.jpg: 384x640 1 person, 222.9ms\n",
      "Speed: 0.6ms preprocess, 222.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/630.jpg: 384x640 1 person, 130.5ms\n",
      "Speed: 0.7ms preprocess, 130.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/80.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/140.jpg: 384x640 1 person, 130.7ms\n",
      "Speed: 0.6ms preprocess, 130.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/430.jpg: 384x640 1 person, 152.8ms\n",
      "Speed: 0.7ms preprocess, 152.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/550.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.8ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/790.jpg: 384x640 1 person, 132.2ms\n",
      "Speed: 0.6ms preprocess, 132.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/380.jpg: 384x640 1 person, 144.2ms\n",
      "Speed: 0.8ms preprocess, 144.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/800.jpg: 384x640 1 person, 136.8ms\n",
      "Speed: 0.9ms preprocess, 136.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/40.jpg: 384x640 1 person, 143.2ms\n",
      "Speed: 0.7ms preprocess, 143.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/50.jpg: 384x640 1 person, 133.1ms\n",
      "Speed: 0.6ms preprocess, 133.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/810.jpg: 384x640 1 person, 136.7ms\n",
      "Speed: 0.6ms preprocess, 136.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/390.jpg: 384x640 1 person, 149.5ms\n",
      "Speed: 0.8ms preprocess, 149.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/780.jpg: 384x640 1 person, 134.4ms\n",
      "Speed: 0.6ms preprocess, 134.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/540.jpg: 384x640 1 person, 130.3ms\n",
      "Speed: 0.5ms preprocess, 130.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/420.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/150.jpg: 384x640 1 person, 152.4ms\n",
      "Speed: 0.5ms preprocess, 152.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/620.jpg: 384x640 1 person, 129.2ms\n",
      "Speed: 0.6ms preprocess, 129.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/90.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/350.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.5ms preprocess, 125.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/230.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.5ms preprocess, 121.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/740.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.7ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/580.jpg: 384x640 1 person, 171.1ms\n",
      "Speed: 0.7ms preprocess, 171.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/0.jpg: 384x640 1 person, 137.1ms\n",
      "Speed: 0.6ms preprocess, 137.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_24012022_2.mp4/190.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.6ms preprocess, 128.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/200.jpg: 384x640 1 person, 136.5ms\n",
      "Speed: 0.6ms preprocess, 136.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/60.jpg: 384x640 1 person, 161.2ms\n",
      "Speed: 0.6ms preprocess, 161.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/160.jpg: 384x640 1 person, 140.8ms\n",
      "Speed: 0.6ms preprocess, 140.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/170.jpg: 384x640 1 person, 199.6ms\n",
      "Speed: 0.8ms preprocess, 199.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/70.jpg: 384x640 1 person, 226.3ms\n",
      "Speed: 0.7ms preprocess, 226.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/210.jpg: 384x640 1 person, 128.8ms\n",
      "Speed: 1.1ms preprocess, 128.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/100.jpg: 384x640 1 person, 131.3ms\n",
      "Speed: 0.7ms preprocess, 131.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/110.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/10.jpg: 384x640 1 person, 145.4ms\n",
      "Speed: 0.6ms preprocess, 145.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/120.jpg: 384x640 1 person, 150.2ms\n",
      "Speed: 0.7ms preprocess, 150.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/20.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.6ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/30.jpg: 384x640 1 person, 146.3ms\n",
      "Speed: 0.5ms preprocess, 146.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/130.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/180.jpg: 384x640 1 person, 127.9ms\n",
      "Speed: 0.6ms preprocess, 127.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/80.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/140.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/40.jpg: 384x640 1 person, 153.8ms\n",
      "Speed: 0.6ms preprocess, 153.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/50.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/150.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.5ms preprocess, 117.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/90.jpg: 384x640 1 person, 141.2ms\n",
      "Speed: 0.6ms preprocess, 141.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/0.jpg: 384x640 1 person, 125.1ms\n",
      "Speed: 0.7ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19032022_9.mp4/190.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.8ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/610.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.5ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/360.jpg: 384x640 1 person, 136.0ms\n",
      "Speed: 0.5ms preprocess, 136.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/200.jpg: 384x640 1 person, 141.2ms\n",
      "Speed: 1.2ms preprocess, 141.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/770.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/60.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/570.jpg: 384x640 1 person, 151.8ms\n",
      "Speed: 0.5ms preprocess, 151.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/410.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.6ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/160.jpg: 384x640 1 person, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/170.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/400.jpg: 384x640 1 person, 140.5ms\n",
      "Speed: 0.6ms preprocess, 140.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/560.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.9ms preprocess, 122.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/70.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/760.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.8ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/210.jpg: 384x640 1 person, 137.4ms\n",
      "Speed: 0.8ms preprocess, 137.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/370.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.8ms preprocess, 122.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/600.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/510.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.5ms preprocess, 127.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/470.jpg: 384x640 1 person, 140.0ms\n",
      "Speed: 0.7ms preprocess, 140.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/100.jpg: 384x640 1 person, 136.2ms\n",
      "Speed: 0.9ms preprocess, 136.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/670.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.6ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/300.jpg: 384x640 1 person, 137.5ms\n",
      "Speed: 0.5ms preprocess, 137.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/260.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.7ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/710.jpg: 384x640 1 person, 146.8ms\n",
      "Speed: 0.9ms preprocess, 146.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/700.jpg: 384x640 1 person, 164.7ms\n",
      "Speed: 0.6ms preprocess, 164.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/270.jpg: 384x640 1 person, 129.7ms\n",
      "Speed: 0.6ms preprocess, 129.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/310.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.8ms preprocess, 125.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/660.jpg: 384x640 1 person, 142.5ms\n",
      "Speed: 0.9ms preprocess, 142.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/110.jpg: 384x640 1 person, 127.0ms\n",
      "Speed: 0.7ms preprocess, 127.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/460.jpg: 384x640 1 person, 127.9ms\n",
      "Speed: 0.5ms preprocess, 127.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/500.jpg: 384x640 1 person, 170.5ms\n",
      "Speed: 0.6ms preprocess, 170.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/10.jpg: 384x640 1 person, 138.9ms\n",
      "Speed: 0.6ms preprocess, 138.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/120.jpg: 384x640 1 person, 121.1ms\n",
      "Speed: 0.7ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/450.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/530.jpg: 384x640 1 person, 161.7ms\n",
      "Speed: 0.6ms preprocess, 161.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/280.jpg: 384x640 1 person, 146.9ms\n",
      "Speed: 0.7ms preprocess, 146.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/690.jpg: 384x640 1 person, 134.7ms\n",
      "Speed: 0.8ms preprocess, 134.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/20.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.6ms preprocess, 122.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/490.jpg: 384x640 1 person, 161.6ms\n",
      "Speed: 0.7ms preprocess, 161.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/730.jpg: 384x640 1 person, 129.0ms\n",
      "Speed: 0.6ms preprocess, 129.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/240.jpg: 384x640 1 person, 127.1ms\n",
      "Speed: 0.6ms preprocess, 127.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/320.jpg: 384x640 1 person, 142.1ms\n",
      "Speed: 0.6ms preprocess, 142.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/650.jpg: 384x640 1 person, 194.2ms\n",
      "Speed: 0.9ms preprocess, 194.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/640.jpg: 384x640 1 person, 135.0ms\n",
      "Speed: 0.6ms preprocess, 135.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/330.jpg: 384x640 1 person, 134.1ms\n",
      "Speed: 0.7ms preprocess, 134.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/250.jpg: 384x640 1 person, 128.2ms\n",
      "Speed: 0.7ms preprocess, 128.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/720.jpg: 384x640 1 person, 145.8ms\n",
      "Speed: 0.6ms preprocess, 145.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/480.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/680.jpg: 384x640 1 person, 129.7ms\n",
      "Speed: 0.8ms preprocess, 129.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/30.jpg: 384x640 1 person, 159.8ms\n",
      "Speed: 0.8ms preprocess, 159.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/290.jpg: 384x640 1 person, 148.5ms\n",
      "Speed: 0.7ms preprocess, 148.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/520.jpg: 384x640 1 person, 149.6ms\n",
      "Speed: 0.8ms preprocess, 149.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/440.jpg: 384x640 1 person, 160.1ms\n",
      "Speed: 0.6ms preprocess, 160.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/130.jpg: 384x640 1 person, 133.3ms\n",
      "Speed: 0.6ms preprocess, 133.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/180.jpg: 384x640 1 person, 136.6ms\n",
      "Speed: 0.8ms preprocess, 136.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/590.jpg: 384x640 1 person, 130.2ms\n",
      "Speed: 0.8ms preprocess, 130.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/750.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.7ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/220.jpg: 384x640 1 person, 142.6ms\n",
      "Speed: 0.6ms preprocess, 142.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/340.jpg: 384x640 1 person, 134.1ms\n",
      "Speed: 0.8ms preprocess, 134.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/630.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/80.jpg: 384x640 1 person, 155.9ms\n",
      "Speed: 0.5ms preprocess, 155.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/140.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.7ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/430.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.6ms preprocess, 126.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/550.jpg: 384x640 1 person, 133.2ms\n",
      "Speed: 0.6ms preprocess, 133.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/790.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.8ms preprocess, 128.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/380.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.7ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/800.jpg: 384x640 1 person, 192.0ms\n",
      "Speed: 0.7ms preprocess, 192.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/40.jpg: 384x640 1 person, 158.0ms\n",
      "Speed: 0.8ms preprocess, 158.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/50.jpg: 384x640 1 person, 132.3ms\n",
      "Speed: 0.6ms preprocess, 132.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/390.jpg: 384x640 1 person, 201.8ms\n",
      "Speed: 0.8ms preprocess, 201.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/780.jpg: 384x640 1 person, 140.9ms\n",
      "Speed: 0.5ms preprocess, 140.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/540.jpg: 384x640 1 person, 120.2ms\n",
      "Speed: 0.6ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/420.jpg: 384x640 1 person, 146.0ms\n",
      "Speed: 0.6ms preprocess, 146.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/150.jpg: 384x640 1 person, 144.5ms\n",
      "Speed: 0.6ms preprocess, 144.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/620.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.8ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/90.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.8ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/350.jpg: 384x640 1 person, 151.8ms\n",
      "Speed: 0.8ms preprocess, 151.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/230.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/740.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.6ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/580.jpg: 384x640 1 person, 143.5ms\n",
      "Speed: 0.6ms preprocess, 143.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/0.jpg: 384x640 1 person, 126.1ms\n",
      "Speed: 0.6ms preprocess, 126.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_1.mp4/190.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.7ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/360.jpg: 384x640 1 person, 138.0ms\n",
      "Speed: 0.6ms preprocess, 138.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/200.jpg: 384x640 1 person, 148.9ms\n",
      "Speed: 0.7ms preprocess, 148.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/60.jpg: 384x640 1 person, 147.2ms\n",
      "Speed: 0.6ms preprocess, 147.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/410.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.7ms preprocess, 121.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/160.jpg: 384x640 1 person, 158.9ms\n",
      "Speed: 0.6ms preprocess, 158.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/170.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.8ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/400.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.6ms preprocess, 123.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/70.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.6ms preprocess, 123.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/210.jpg: 384x640 1 person, 162.9ms\n",
      "Speed: 0.8ms preprocess, 162.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/370.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.8ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/510.jpg: 384x640 1 person, 133.6ms\n",
      "Speed: 0.6ms preprocess, 133.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/470.jpg: 384x640 1 person, 147.1ms\n",
      "Speed: 0.6ms preprocess, 147.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/100.jpg: 384x640 1 person, 241.7ms\n",
      "Speed: 0.8ms preprocess, 241.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/300.jpg: 384x640 1 person, 159.0ms\n",
      "Speed: 0.9ms preprocess, 159.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/260.jpg: 384x640 1 person, 132.1ms\n",
      "Speed: 0.6ms preprocess, 132.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/270.jpg: 384x640 1 person, 146.4ms\n",
      "Speed: 0.6ms preprocess, 146.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/310.jpg: 384x640 1 person, 172.7ms\n",
      "Speed: 0.8ms preprocess, 172.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/110.jpg: 384x640 1 person, 147.0ms\n",
      "Speed: 1.0ms preprocess, 147.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/460.jpg: 384x640 1 person, 179.7ms\n",
      "Speed: 0.8ms preprocess, 179.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/500.jpg: 384x640 1 person, 154.7ms\n",
      "Speed: 0.8ms preprocess, 154.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/10.jpg: 384x640 1 person, 142.4ms\n",
      "Speed: 0.7ms preprocess, 142.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/120.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.7ms preprocess, 122.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/450.jpg: 384x640 1 person, 156.9ms\n",
      "Speed: 0.6ms preprocess, 156.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/530.jpg: 384x640 1 person, 144.6ms\n",
      "Speed: 0.8ms preprocess, 144.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/280.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.8ms preprocess, 123.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/20.jpg: 384x640 1 person, 141.5ms\n",
      "Speed: 0.6ms preprocess, 141.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/490.jpg: 384x640 1 person, 131.6ms\n",
      "Speed: 0.6ms preprocess, 131.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/240.jpg: 384x640 1 person, 135.0ms\n",
      "Speed: 0.6ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/320.jpg: 384x640 1 person, 158.4ms\n",
      "Speed: 0.9ms preprocess, 158.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/330.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.8ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/250.jpg: 384x640 1 person, 135.2ms\n",
      "Speed: 0.6ms preprocess, 135.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/480.jpg: 384x640 1 person, 139.8ms\n",
      "Speed: 0.6ms preprocess, 139.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/30.jpg: 384x640 1 person, 132.9ms\n",
      "Speed: 0.8ms preprocess, 132.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/290.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/520.jpg: 384x640 1 person, 147.2ms\n",
      "Speed: 0.6ms preprocess, 147.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/440.jpg: 384x640 1 person, 126.3ms\n",
      "Speed: 0.8ms preprocess, 126.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/130.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.8ms preprocess, 119.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/180.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/220.jpg: 384x640 1 person, 136.5ms\n",
      "Speed: 0.6ms preprocess, 136.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/340.jpg: 384x640 1 person, 149.4ms\n",
      "Speed: 0.6ms preprocess, 149.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/80.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.8ms preprocess, 126.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/140.jpg: 384x640 1 person, 126.3ms\n",
      "Speed: 0.6ms preprocess, 126.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/430.jpg: 384x640 1 person, 155.5ms\n",
      "Speed: 0.8ms preprocess, 155.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/380.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/40.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.5ms preprocess, 126.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/50.jpg: 384x640 1 person, 126.9ms\n",
      "Speed: 0.7ms preprocess, 126.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/390.jpg: 384x640 1 person, 132.5ms\n",
      "Speed: 0.6ms preprocess, 132.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/420.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.7ms preprocess, 123.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/150.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.5ms preprocess, 127.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/90.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.7ms preprocess, 120.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/350.jpg: 384x640 1 person, 128.9ms\n",
      "Speed: 0.6ms preprocess, 128.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/230.jpg: 384x640 1 person, 145.6ms\n",
      "Speed: 0.8ms preprocess, 145.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/0.jpg: 384x640 1 person, 129.9ms\n",
      "Speed: 0.7ms preprocess, 129.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_19122021_2.mp4/190.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.8ms preprocess, 118.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/200.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/60.jpg: 384x640 1 person, 148.4ms\n",
      "Speed: 0.6ms preprocess, 148.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/160.jpg: 384x640 1 person, 131.1ms\n",
      "Speed: 0.7ms preprocess, 131.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/170.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/70.jpg: 384x640 1 person, 123.4ms\n",
      "Speed: 0.8ms preprocess, 123.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/210.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.6ms preprocess, 116.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/100.jpg: 384x640 1 person, 143.5ms\n",
      "Speed: 0.6ms preprocess, 143.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/300.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.7ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/260.jpg: 384x640 1 person, 126.8ms\n",
      "Speed: 0.6ms preprocess, 126.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/270.jpg: 384x640 1 person, 148.0ms\n",
      "Speed: 0.7ms preprocess, 148.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/110.jpg: 384x640 1 person, 128.0ms\n",
      "Speed: 0.6ms preprocess, 128.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/10.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/120.jpg: 384x640 1 person, 116.4ms\n",
      "Speed: 0.7ms preprocess, 116.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/280.jpg: 384x640 1 person, 138.1ms\n",
      "Speed: 0.6ms preprocess, 138.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/20.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.7ms preprocess, 127.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/240.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.7ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/250.jpg: 384x640 1 person, 113.8ms\n",
      "Speed: 0.7ms preprocess, 113.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/30.jpg: 384x640 1 person, 149.6ms\n",
      "Speed: 2.6ms preprocess, 149.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/290.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.7ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/130.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/180.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/220.jpg: 384x640 1 person, 159.7ms\n",
      "Speed: 0.6ms preprocess, 159.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/80.jpg: 384x640 1 person, 139.4ms\n",
      "Speed: 0.6ms preprocess, 139.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/140.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/40.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.6ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/50.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/150.jpg: 384x640 1 person, 168.0ms\n",
      "Speed: 0.6ms preprocess, 168.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/90.jpg: 384x640 1 person, 136.5ms\n",
      "Speed: 2.5ms preprocess, 136.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/230.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.8ms preprocess, 117.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/0.jpg: 384x640 1 person, 134.3ms\n",
      "Speed: 0.6ms preprocess, 134.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_11.mp4/190.jpg: 384x640 1 person, 126.1ms\n",
      "Speed: 0.6ms preprocess, 126.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/60.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.6ms preprocess, 127.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/160.jpg: 384x640 1 person, 132.4ms\n",
      "Speed: 0.7ms preprocess, 132.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/70.jpg: 384x640 1 person, 132.7ms\n",
      "Speed: 0.6ms preprocess, 132.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/100.jpg: 384x640 1 person, 144.8ms\n",
      "Speed: 0.6ms preprocess, 144.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/110.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.6ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/10.jpg: 384x640 1 person, 122.7ms\n",
      "Speed: 0.6ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/120.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.5ms preprocess, 132.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/20.jpg: 384x640 1 person, 141.6ms\n",
      "Speed: 0.9ms preprocess, 141.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/30.jpg: 384x640 1 person, 129.5ms\n",
      "Speed: 0.6ms preprocess, 129.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/130.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.6ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/80.jpg: 384x640 1 person, 152.9ms\n",
      "Speed: 0.6ms preprocess, 152.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/140.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.6ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/40.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.6ms preprocess, 124.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/50.jpg: 384x640 1 person, 134.5ms\n",
      "Speed: 0.6ms preprocess, 134.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/150.jpg: 384x640 1 person, 143.6ms\n",
      "Speed: 0.6ms preprocess, 143.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/90.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.7ms preprocess, 122.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10012022_5.mp4/0.jpg: 384x640 1 person, 128.0ms\n",
      "Speed: 0.6ms preprocess, 128.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/610.jpg: 384x640 1 person, 118.1ms\n",
      "Speed: 0.6ms preprocess, 118.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/360.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.6ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/200.jpg: 384x640 1 person, 168.0ms\n",
      "Speed: 0.6ms preprocess, 168.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/60.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.7ms preprocess, 124.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/570.jpg: 384x640 1 person, 136.2ms\n",
      "Speed: 0.8ms preprocess, 136.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/410.jpg: 384x640 1 person, 134.4ms\n",
      "Speed: 0.8ms preprocess, 134.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/160.jpg: 384x640 1 person, 141.4ms\n",
      "Speed: 1.5ms preprocess, 141.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/170.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.9ms preprocess, 122.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/400.jpg: 384x640 1 person, 130.0ms\n",
      "Speed: 0.6ms preprocess, 130.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/560.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.8ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/70.jpg: 384x640 1 person, 140.7ms\n",
      "Speed: 0.6ms preprocess, 140.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/210.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/370.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/600.jpg: 384x640 1 person, 151.6ms\n",
      "Speed: 0.7ms preprocess, 151.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/510.jpg: 384x640 1 person, 134.3ms\n",
      "Speed: 0.6ms preprocess, 134.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/470.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.7ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/100.jpg: 384x640 1 person, 145.4ms\n",
      "Speed: 0.6ms preprocess, 145.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/670.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/300.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/260.jpg: 384x640 1 person, 174.8ms\n",
      "Speed: 0.7ms preprocess, 174.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/710.jpg: 384x640 1 person, 134.9ms\n",
      "Speed: 0.6ms preprocess, 134.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/700.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/270.jpg: 384x640 1 person, 147.4ms\n",
      "Speed: 0.5ms preprocess, 147.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/310.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.7ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/660.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/110.jpg: 384x640 1 person, 132.1ms\n",
      "Speed: 0.5ms preprocess, 132.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/460.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.6ms preprocess, 127.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/500.jpg: 384x640 1 person, 146.5ms\n",
      "Speed: 0.6ms preprocess, 146.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/10.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/120.jpg: 384x640 1 person, 128.6ms\n",
      "Speed: 0.6ms preprocess, 128.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/450.jpg: 384x640 1 person, 136.3ms\n",
      "Speed: 0.6ms preprocess, 136.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/530.jpg: 384x640 1 person, 145.3ms\n",
      "Speed: 0.6ms preprocess, 145.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/280.jpg: 384x640 1 person, 159.1ms\n",
      "Speed: 0.8ms preprocess, 159.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/690.jpg: 384x640 1 person, 136.2ms\n",
      "Speed: 0.9ms preprocess, 136.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/20.jpg: 384x640 1 person, 138.1ms\n",
      "Speed: 0.6ms preprocess, 138.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/490.jpg: 384x640 1 person, 125.7ms\n",
      "Speed: 0.6ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/730.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 0.6ms preprocess, 133.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/240.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.9ms preprocess, 121.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/320.jpg: 384x640 1 person, 173.9ms\n",
      "Speed: 0.5ms preprocess, 173.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/650.jpg: 384x640 1 person, 133.3ms\n",
      "Speed: 0.7ms preprocess, 133.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/640.jpg: 384x640 1 person, 120.3ms\n",
      "Speed: 0.7ms preprocess, 120.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/330.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.5ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/250.jpg: 384x640 1 person, 135.0ms\n",
      "Speed: 0.5ms preprocess, 135.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/720.jpg: 384x640 1 person, 129.5ms\n",
      "Speed: 0.8ms preprocess, 129.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/480.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.6ms preprocess, 127.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/680.jpg: 384x640 1 person, 140.3ms\n",
      "Speed: 0.6ms preprocess, 140.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/30.jpg: 384x640 1 person, 219.8ms\n",
      "Speed: 0.7ms preprocess, 219.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/290.jpg: 384x640 1 person, 149.9ms\n",
      "Speed: 0.9ms preprocess, 149.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/520.jpg: 384x640 1 person, 136.2ms\n",
      "Speed: 0.6ms preprocess, 136.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/440.jpg: 384x640 1 person, 140.3ms\n",
      "Speed: 0.7ms preprocess, 140.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/130.jpg: 384x640 1 person, 169.6ms\n",
      "Speed: 0.6ms preprocess, 169.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/180.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 0.7ms preprocess, 127.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/590.jpg: 384x640 1 person, 139.6ms\n",
      "Speed: 0.8ms preprocess, 139.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/220.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/340.jpg: 384x640 1 person, 143.7ms\n",
      "Speed: 0.5ms preprocess, 143.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/630.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/80.jpg: 384x640 1 person, 145.4ms\n",
      "Speed: 0.5ms preprocess, 145.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/140.jpg: 384x640 1 person, 139.0ms\n",
      "Speed: 0.8ms preprocess, 139.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/430.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/550.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.7ms preprocess, 124.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/380.jpg: 384x640 1 person, 148.0ms\n",
      "Speed: 0.7ms preprocess, 148.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/40.jpg: 384x640 1 person, 131.3ms\n",
      "Speed: 0.5ms preprocess, 131.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/50.jpg: 384x640 1 person, 131.9ms\n",
      "Speed: 0.5ms preprocess, 131.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/390.jpg: 384x640 1 person, 136.8ms\n",
      "Speed: 0.8ms preprocess, 136.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/540.jpg: 384x640 1 person, 129.3ms\n",
      "Speed: 0.9ms preprocess, 129.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/420.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/150.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.6ms preprocess, 126.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/620.jpg: 384x640 1 person, 152.6ms\n",
      "Speed: 0.6ms preprocess, 152.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/90.jpg: 384x640 1 person, 132.6ms\n",
      "Speed: 0.6ms preprocess, 132.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/350.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.7ms preprocess, 123.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/230.jpg: 384x640 1 person, 146.7ms\n",
      "Speed: 0.6ms preprocess, 146.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/580.jpg: 384x640 1 person, 132.7ms\n",
      "Speed: 0.6ms preprocess, 132.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/0.jpg: 384x640 1 person, 121.8ms\n",
      "Speed: 0.8ms preprocess, 121.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_10122021_2.mp4/190.jpg: 384x640 1 person, 148.3ms\n",
      "Speed: 0.6ms preprocess, 148.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/60.jpg: 384x640 1 person, 146.7ms\n",
      "Speed: 0.6ms preprocess, 146.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/70.jpg: 384x640 2 persons, 127.6ms\n",
      "Speed: 0.6ms preprocess, 127.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/100.jpg: 384x640 1 person, 137.5ms\n",
      "Speed: 0.7ms preprocess, 137.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/110.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.9ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/10.jpg: 384x640 1 person, 137.0ms\n",
      "Speed: 0.5ms preprocess, 137.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/20.jpg: 384x640 1 person, 165.2ms\n",
      "Speed: 0.9ms preprocess, 165.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/30.jpg: 384x640 1 person, 122.2ms\n",
      "Speed: 0.6ms preprocess, 122.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/80.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/40.jpg: 384x640 1 person, 148.9ms\n",
      "Speed: 1.4ms preprocess, 148.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/50.jpg: 384x640 1 person, 135.8ms\n",
      "Speed: 0.7ms preprocess, 135.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/90.jpg: 384x640 1 person, 139.1ms\n",
      "Speed: 0.6ms preprocess, 139.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_04.mp4/0.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.6ms preprocess, 126.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/360.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.6ms preprocess, 128.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/200.jpg: 384x640 1 person, 166.5ms\n",
      "Speed: 2.4ms preprocess, 166.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/60.jpg: 384x640 1 person, 154.8ms\n",
      "Speed: 0.8ms preprocess, 154.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/410.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/160.jpg: 384x640 1 person, 157.8ms\n",
      "Speed: 0.6ms preprocess, 157.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/170.jpg: 384x640 1 person, 135.0ms\n",
      "Speed: 0.8ms preprocess, 135.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/400.jpg: 384x640 1 person, 131.9ms\n",
      "Speed: 0.9ms preprocess, 131.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/70.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/210.jpg: 384x640 1 person, 146.6ms\n",
      "Speed: 0.6ms preprocess, 146.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/370.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.5ms preprocess, 123.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/470.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/100.jpg: 384x640 1 person, 170.8ms\n",
      "Speed: 0.5ms preprocess, 170.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/300.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 1.0ms preprocess, 124.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/260.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.6ms preprocess, 123.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/270.jpg: 384x640 1 person, 145.9ms\n",
      "Speed: 0.5ms preprocess, 145.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/310.jpg: 384x640 1 person, 134.2ms\n",
      "Speed: 0.5ms preprocess, 134.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/110.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.6ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/460.jpg: 384x640 1 person, 169.4ms\n",
      "Speed: 0.7ms preprocess, 169.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/10.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/120.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/450.jpg: 384x640 1 person, 126.3ms\n",
      "Speed: 0.5ms preprocess, 126.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/280.jpg: 384x640 2 persons, 144.8ms\n",
      "Speed: 0.7ms preprocess, 144.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/20.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.6ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/240.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.8ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/320.jpg: 384x640 1 person, 157.8ms\n",
      "Speed: 0.6ms preprocess, 157.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/330.jpg: 384x640 1 person, 130.0ms\n",
      "Speed: 0.9ms preprocess, 130.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/250.jpg: 384x640 1 person, 127.9ms\n",
      "Speed: 0.7ms preprocess, 127.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/480.jpg: 384x640 1 person, 140.9ms\n",
      "Speed: 0.8ms preprocess, 140.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/30.jpg: 384x640 1 person, 194.6ms\n",
      "Speed: 0.9ms preprocess, 194.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/290.jpg: 384x640 1 person, 145.4ms\n",
      "Speed: 0.7ms preprocess, 145.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/440.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.8ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/130.jpg: 384x640 1 person, 129.0ms\n",
      "Speed: 0.6ms preprocess, 129.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/180.jpg: 384x640 1 person, 152.0ms\n",
      "Speed: 0.6ms preprocess, 152.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/220.jpg: 384x640 1 person, 124.3ms\n",
      "Speed: 0.6ms preprocess, 124.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/340.jpg: 384x640 2 persons, 166.6ms\n",
      "Speed: 0.6ms preprocess, 166.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/80.jpg: 384x640 1 person, 215.6ms\n",
      "Speed: 1.3ms preprocess, 215.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/140.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.7ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/430.jpg: 384x640 1 person, 135.7ms\n",
      "Speed: 0.6ms preprocess, 135.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/380.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.7ms preprocess, 121.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/40.jpg: 384x640 1 person, 139.9ms\n",
      "Speed: 0.6ms preprocess, 139.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/50.jpg: 384x640 1 person, 129.8ms\n",
      "Speed: 0.6ms preprocess, 129.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/390.jpg: 384x640 1 person, 136.9ms\n",
      "Speed: 0.6ms preprocess, 136.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/420.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.6ms preprocess, 123.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/150.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/90.jpg: 384x640 1 person, 143.1ms\n",
      "Speed: 0.6ms preprocess, 143.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/350.jpg: 384x640 1 person, 133.7ms\n",
      "Speed: 0.9ms preprocess, 133.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/230.jpg: 384x640 1 person, 126.1ms\n",
      "Speed: 0.6ms preprocess, 126.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/0.jpg: 384x640 1 person, 139.8ms\n",
      "Speed: 0.6ms preprocess, 139.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_2.mp4/190.jpg: 384x640 1 person, 146.1ms\n",
      "Speed: 0.9ms preprocess, 146.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/360.jpg: 384x640 1 person, 129.2ms\n",
      "Speed: 0.6ms preprocess, 129.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/200.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.6ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/60.jpg: 384x640 1 person, 115.8ms\n",
      "Speed: 0.6ms preprocess, 115.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/410.jpg: 384x640 1 person, 135.8ms\n",
      "Speed: 0.6ms preprocess, 135.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/160.jpg: 384x640 1 person, 146.0ms\n",
      "Speed: 0.8ms preprocess, 146.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/170.jpg: 384x640 1 person, 124.4ms\n",
      "Speed: 0.8ms preprocess, 124.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/400.jpg: 384x640 2 persons, 130.7ms\n",
      "Speed: 0.6ms preprocess, 130.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/70.jpg: 384x640 1 person, 139.0ms\n",
      "Speed: 0.6ms preprocess, 139.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/210.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 0.7ms preprocess, 133.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/370.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.7ms preprocess, 122.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/100.jpg: 384x640 1 person, 126.9ms\n",
      "Speed: 0.6ms preprocess, 126.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/300.jpg: 384x640 2 persons, 138.0ms\n",
      "Speed: 0.6ms preprocess, 138.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/260.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.6ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/270.jpg: 384x640 1 person, 132.7ms\n",
      "Speed: 0.5ms preprocess, 132.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/310.jpg: 384x640 1 person, 158.9ms\n",
      "Speed: 0.6ms preprocess, 158.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/110.jpg: 384x640 1 person, 161.2ms\n",
      "Speed: 0.7ms preprocess, 161.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/460.jpg: 384x640 2 persons, 131.7ms\n",
      "Speed: 0.6ms preprocess, 131.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/10.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.5ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/120.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.5ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/450.jpg: 384x640 2 persons, 158.7ms\n",
      "Speed: 0.6ms preprocess, 158.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/280.jpg: 384x640 1 person, 132.7ms\n",
      "Speed: 0.8ms preprocess, 132.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/20.jpg: 384x640 1 person, 120.0ms\n",
      "Speed: 0.6ms preprocess, 120.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/240.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.6ms preprocess, 123.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/320.jpg: 384x640 1 person, 135.2ms\n",
      "Speed: 0.6ms preprocess, 135.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/330.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.7ms preprocess, 124.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/250.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.7ms preprocess, 126.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/30.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.8ms preprocess, 127.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/290.jpg: 384x640 1 person, 139.6ms\n",
      "Speed: 0.6ms preprocess, 139.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/440.jpg: 384x640 2 persons, 140.8ms\n",
      "Speed: 0.7ms preprocess, 140.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/130.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/180.jpg: 384x640 1 person, 137.5ms\n",
      "Speed: 0.7ms preprocess, 137.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/220.jpg: 384x640 1 person, 150.2ms\n",
      "Speed: 0.6ms preprocess, 150.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/340.jpg: 384x640 1 person, 140.5ms\n",
      "Speed: 0.6ms preprocess, 140.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/80.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.6ms preprocess, 126.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/140.jpg: 384x640 1 person, 139.9ms\n",
      "Speed: 0.6ms preprocess, 139.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/430.jpg: 384x640 1 person, 128.1ms\n",
      "Speed: 0.5ms preprocess, 128.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/380.jpg: 384x640 2 persons, 127.2ms\n",
      "Speed: 0.7ms preprocess, 127.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/40.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.6ms preprocess, 128.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/50.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.6ms preprocess, 124.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/390.jpg: 384x640 2 persons, 159.9ms\n",
      "Speed: 0.5ms preprocess, 159.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/420.jpg: 384x640 2 persons, 125.7ms\n",
      "Speed: 0.8ms preprocess, 125.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/150.jpg: 384x640 1 person, 124.8ms\n",
      "Speed: 0.7ms preprocess, 124.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/90.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/350.jpg: 384x640 2 persons, 201.9ms\n",
      "Speed: 2.1ms preprocess, 201.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/230.jpg: 384x640 1 person, 129.8ms\n",
      "Speed: 0.7ms preprocess, 129.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/0.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.6ms preprocess, 124.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_09122021_3.mp4/190.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.7ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/360.jpg: 384x640 1 person, 227.7ms\n",
      "Speed: 0.6ms preprocess, 227.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/200.jpg: 384x640 1 person, 164.2ms\n",
      "Speed: 0.6ms preprocess, 164.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/60.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.6ms preprocess, 125.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/160.jpg: 384x640 1 person, 120.8ms\n",
      "Speed: 0.6ms preprocess, 120.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/170.jpg: 384x640 1 person, 157.2ms\n",
      "Speed: 0.6ms preprocess, 157.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/70.jpg: 384x640 1 person, 131.0ms\n",
      "Speed: 0.8ms preprocess, 131.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/210.jpg: 384x640 1 person, 128.5ms\n",
      "Speed: 0.7ms preprocess, 128.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/100.jpg: 384x640 1 person, 137.2ms\n",
      "Speed: 0.7ms preprocess, 137.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/300.jpg: 384x640 1 person, 165.6ms\n",
      "Speed: 0.6ms preprocess, 165.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/260.jpg: 384x640 1 person, 135.7ms\n",
      "Speed: 0.8ms preprocess, 135.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/270.jpg: 384x640 1 person, 128.1ms\n",
      "Speed: 0.6ms preprocess, 128.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/310.jpg: 384x640 1 person, 146.3ms\n",
      "Speed: 0.6ms preprocess, 146.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/110.jpg: 384x640 1 person, 139.7ms\n",
      "Speed: 0.6ms preprocess, 139.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/10.jpg: 384x640 1 person, 145.8ms\n",
      "Speed: 0.6ms preprocess, 145.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/120.jpg: 384x640 1 person, 129.0ms\n",
      "Speed: 1.0ms preprocess, 129.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/280.jpg: 384x640 1 person, 138.4ms\n",
      "Speed: 0.7ms preprocess, 138.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/20.jpg: 384x640 1 person, 154.1ms\n",
      "Speed: 0.9ms preprocess, 154.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/240.jpg: 384x640 1 person, 130.9ms\n",
      "Speed: 0.7ms preprocess, 130.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/320.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.8ms preprocess, 126.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/330.jpg: 384x640 1 person, 136.5ms\n",
      "Speed: 0.7ms preprocess, 136.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/250.jpg: 384x640 1 person, 158.3ms\n",
      "Speed: 0.8ms preprocess, 158.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/30.jpg: 384x640 1 person, 130.2ms\n",
      "Speed: 0.8ms preprocess, 130.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/290.jpg: 384x640 1 person, 128.0ms\n",
      "Speed: 0.7ms preprocess, 128.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/130.jpg: 384x640 1 person, 173.8ms\n",
      "Speed: 0.9ms preprocess, 173.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/180.jpg: 384x640 1 person, 189.8ms\n",
      "Speed: 0.9ms preprocess, 189.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/220.jpg: 384x640 1 person, 130.1ms\n",
      "Speed: 0.8ms preprocess, 130.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/340.jpg: 384x640 1 person, 151.7ms\n",
      "Speed: 0.7ms preprocess, 151.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/80.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.6ms preprocess, 137.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/140.jpg: 384x640 1 person, 168.9ms\n",
      "Speed: 0.8ms preprocess, 168.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/40.jpg: 384x640 1 person, 134.3ms\n",
      "Speed: 0.6ms preprocess, 134.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/50.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.6ms preprocess, 128.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/150.jpg: 384x640 1 person, 131.3ms\n",
      "Speed: 0.6ms preprocess, 131.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/90.jpg: 384x640 1 person, 177.1ms\n",
      "Speed: 0.6ms preprocess, 177.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/350.jpg: 384x640 1 person, 183.5ms\n",
      "Speed: 11.0ms preprocess, 183.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/230.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 0.7ms preprocess, 133.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/0.jpg: 384x640 1 person, 139.3ms\n",
      "Speed: 0.6ms preprocess, 139.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_03.mp4/190.jpg: 384x640 1 person, 155.6ms\n",
      "Speed: 2.7ms preprocess, 155.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/360.jpg: 384x640 1 person, 151.0ms\n",
      "Speed: 0.6ms preprocess, 151.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/200.jpg: 384x640 1 person, 139.6ms\n",
      "Speed: 0.7ms preprocess, 139.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/60.jpg: 384x640 1 person, 172.8ms\n",
      "Speed: 3.3ms preprocess, 172.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/160.jpg: 384x640 1 person, 136.9ms\n",
      "Speed: 0.8ms preprocess, 136.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/170.jpg: 384x640 1 person, 126.2ms\n",
      "Speed: 0.7ms preprocess, 126.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/70.jpg: 384x640 1 person, 154.1ms\n",
      "Speed: 0.6ms preprocess, 154.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/210.jpg: 384x640 1 person, 218.3ms\n",
      "Speed: 0.8ms preprocess, 218.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/100.jpg: 384x640 1 person, 171.4ms\n",
      "Speed: 1.0ms preprocess, 171.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/300.jpg: 384x640 1 person, 166.8ms\n",
      "Speed: 0.8ms preprocess, 166.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/260.jpg: 384x640 1 person, 132.4ms\n",
      "Speed: 0.7ms preprocess, 132.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/270.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.7ms preprocess, 125.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/310.jpg: 384x640 1 person, 145.8ms\n",
      "Speed: 0.8ms preprocess, 145.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/110.jpg: 384x640 1 person, 209.3ms\n",
      "Speed: 0.7ms preprocess, 209.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/10.jpg: 384x640 1 person, 169.2ms\n",
      "Speed: 0.6ms preprocess, 169.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/120.jpg: 384x640 1 person, 123.1ms\n",
      "Speed: 0.7ms preprocess, 123.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/280.jpg: 384x640 1 person, 152.0ms\n",
      "Speed: 0.7ms preprocess, 152.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/20.jpg: 384x640 1 person, 183.9ms\n",
      "Speed: 0.8ms preprocess, 183.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/240.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.8ms preprocess, 124.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/320.jpg: 384x640 1 person, 131.5ms\n",
      "Speed: 0.6ms preprocess, 131.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/330.jpg: 384x640 1 person, 163.5ms\n",
      "Speed: 0.8ms preprocess, 163.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/250.jpg: 384x640 1 person, 140.0ms\n",
      "Speed: 0.5ms preprocess, 140.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/30.jpg: 384x640 1 person, 159.5ms\n",
      "Speed: 0.8ms preprocess, 159.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/290.jpg: 384x640 1 person, 155.8ms\n",
      "Speed: 0.6ms preprocess, 155.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/130.jpg: 384x640 1 person, 129.7ms\n",
      "Speed: 0.7ms preprocess, 129.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/180.jpg: 384x640 1 person, 140.8ms\n",
      "Speed: 0.6ms preprocess, 140.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/220.jpg: 384x640 1 person, 196.1ms\n",
      "Speed: 0.8ms preprocess, 196.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/340.jpg: 384x640 1 person, 204.3ms\n",
      "Speed: 0.8ms preprocess, 204.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/80.jpg: 384x640 1 person, 177.3ms\n",
      "Speed: 1.3ms preprocess, 177.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/140.jpg: 384x640 1 person, 143.9ms\n",
      "Speed: 1.0ms preprocess, 143.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/40.jpg: 384x640 1 person, 175.3ms\n",
      "Speed: 0.6ms preprocess, 175.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/50.jpg: 384x640 1 person, 132.5ms\n",
      "Speed: 0.6ms preprocess, 132.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/150.jpg: 384x640 1 person, 181.9ms\n",
      "Speed: 0.8ms preprocess, 181.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/90.jpg: 384x640 1 person, 137.5ms\n",
      "Speed: 0.6ms preprocess, 137.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/350.jpg: 384x640 1 person, 171.9ms\n",
      "Speed: 0.7ms preprocess, 171.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/230.jpg: 384x640 1 person, 143.3ms\n",
      "Speed: 0.7ms preprocess, 143.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/0.jpg: 384x640 1 person, 148.9ms\n",
      "Speed: 0.8ms preprocess, 148.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_02.mp4/190.jpg: 384x640 1 person, 281.8ms\n",
      "Speed: 0.8ms preprocess, 281.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/200.jpg: 384x640 2 persons, 153.7ms\n",
      "Speed: 0.8ms preprocess, 153.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/60.jpg: 384x640 2 persons, 164.8ms\n",
      "Speed: 0.8ms preprocess, 164.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/160.jpg: 384x640 2 persons, 169.7ms\n",
      "Speed: 0.7ms preprocess, 169.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/170.jpg: 384x640 1 person, 153.4ms\n",
      "Speed: 0.8ms preprocess, 153.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/70.jpg: 384x640 2 persons, 149.6ms\n",
      "Speed: 1.0ms preprocess, 149.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/210.jpg: 384x640 2 persons, 131.4ms\n",
      "Speed: 0.8ms preprocess, 131.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/100.jpg: 384x640 2 persons, 141.5ms\n",
      "Speed: 0.7ms preprocess, 141.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/260.jpg: 384x640 2 persons, 168.8ms\n",
      "Speed: 0.8ms preprocess, 168.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/270.jpg: 384x640 2 persons, 138.0ms\n",
      "Speed: 0.6ms preprocess, 138.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/110.jpg: 384x640 2 persons, 197.8ms\n",
      "Speed: 0.8ms preprocess, 197.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/10.jpg: 384x640 2 persons, 172.3ms\n",
      "Speed: 1.1ms preprocess, 172.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/120.jpg: 384x640 2 persons, 136.1ms\n",
      "Speed: 0.8ms preprocess, 136.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/20.jpg: 384x640 2 persons, 140.6ms\n",
      "Speed: 0.8ms preprocess, 140.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/240.jpg: 384x640 2 persons, 127.0ms\n",
      "Speed: 0.8ms preprocess, 127.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/250.jpg: 384x640 2 persons, 192.9ms\n",
      "Speed: 0.6ms preprocess, 192.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/30.jpg: 384x640 1 person, 151.9ms\n",
      "Speed: 0.7ms preprocess, 151.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/130.jpg: 384x640 1 person, 131.7ms\n",
      "Speed: 0.6ms preprocess, 131.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/180.jpg: 384x640 2 persons, 132.4ms\n",
      "Speed: 0.6ms preprocess, 132.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/220.jpg: 384x640 2 persons, 187.2ms\n",
      "Speed: 0.6ms preprocess, 187.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/80.jpg: 384x640 2 persons, 186.8ms\n",
      "Speed: 0.8ms preprocess, 186.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/140.jpg: 384x640 1 person, 140.6ms\n",
      "Speed: 0.7ms preprocess, 140.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/40.jpg: 384x640 1 person, 151.7ms\n",
      "Speed: 0.6ms preprocess, 151.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/50.jpg: 384x640 2 persons, 163.1ms\n",
      "Speed: 0.8ms preprocess, 163.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/150.jpg: 384x640 1 person, 156.9ms\n",
      "Speed: 0.7ms preprocess, 156.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/90.jpg: 384x640 2 persons, 149.3ms\n",
      "Speed: 0.6ms preprocess, 149.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/230.jpg: 384x640 2 persons, 177.4ms\n",
      "Speed: 1.2ms preprocess, 177.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/0.jpg: 384x640 2 persons, 129.4ms\n",
      "Speed: 0.6ms preprocess, 129.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_5.mp4/190.jpg: 384x640 2 persons, 147.2ms\n",
      "Speed: 0.8ms preprocess, 147.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/610.jpg: 384x640 1 person, 161.8ms\n",
      "Speed: 0.6ms preprocess, 161.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/360.jpg: 384x640 1 person, 174.6ms\n",
      "Speed: 0.8ms preprocess, 174.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/200.jpg: 384x640 1 person, 124.5ms\n",
      "Speed: 0.8ms preprocess, 124.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/60.jpg: 384x640 1 person, 149.2ms\n",
      "Speed: 2.2ms preprocess, 149.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/570.jpg: 384x640 1 person, 174.3ms\n",
      "Speed: 0.6ms preprocess, 174.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/410.jpg: 384x640 1 person, 152.7ms\n",
      "Speed: 0.8ms preprocess, 152.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/160.jpg: 384x640 1 person, 399.1ms\n",
      "Speed: 0.9ms preprocess, 399.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/170.jpg: 384x640 1 person, 177.4ms\n",
      "Speed: 1.1ms preprocess, 177.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/400.jpg: 384x640 1 person, 146.0ms\n",
      "Speed: 0.8ms preprocess, 146.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/560.jpg: 384x640 1 person, 142.1ms\n",
      "Speed: 0.8ms preprocess, 142.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/70.jpg: 384x640 1 person, 157.6ms\n",
      "Speed: 0.8ms preprocess, 157.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/210.jpg: 384x640 1 person, 164.3ms\n",
      "Speed: 0.7ms preprocess, 164.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/370.jpg: 384x640 1 person, 136.8ms\n",
      "Speed: 1.0ms preprocess, 136.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/600.jpg: 384x640 1 person, 133.1ms\n",
      "Speed: 0.7ms preprocess, 133.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/510.jpg: 384x640 1 person, 159.8ms\n",
      "Speed: 0.8ms preprocess, 159.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/470.jpg: 384x640 1 person, 130.1ms\n",
      "Speed: 1.0ms preprocess, 130.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/100.jpg: 384x640 1 person, 153.3ms\n",
      "Speed: 0.8ms preprocess, 153.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/300.jpg: 384x640 1 person, 171.4ms\n",
      "Speed: 1.1ms preprocess, 171.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/260.jpg: 384x640 1 person, 132.3ms\n",
      "Speed: 0.7ms preprocess, 132.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/270.jpg: 384x640 1 person, 158.3ms\n",
      "Speed: 0.7ms preprocess, 158.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/310.jpg: 384x640 1 person, 148.4ms\n",
      "Speed: 0.8ms preprocess, 148.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/110.jpg: 384x640 1 person, 190.8ms\n",
      "Speed: 0.8ms preprocess, 190.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/460.jpg: 384x640 1 person, 132.8ms\n",
      "Speed: 0.8ms preprocess, 132.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/500.jpg: 384x640 1 person, 144.9ms\n",
      "Speed: 0.9ms preprocess, 144.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/10.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/120.jpg: 384x640 1 person, 152.3ms\n",
      "Speed: 0.5ms preprocess, 152.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/450.jpg: 384x640 1 person, 145.9ms\n",
      "Speed: 0.7ms preprocess, 145.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/530.jpg: 384x640 1 person, 127.3ms\n",
      "Speed: 0.8ms preprocess, 127.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/280.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.6ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/20.jpg: 384x640 1 person, 140.0ms\n",
      "Speed: 0.6ms preprocess, 140.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/490.jpg: 384x640 1 person, 116.1ms\n",
      "Speed: 0.6ms preprocess, 116.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/240.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 0.6ms preprocess, 123.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/320.jpg: 384x640 1 person, 126.9ms\n",
      "Speed: 0.7ms preprocess, 126.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/640.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 3.2ms preprocess, 133.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/330.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.8ms preprocess, 119.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/250.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.7ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/480.jpg: 384x640 1 person, 158.6ms\n",
      "Speed: 0.7ms preprocess, 158.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/30.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/290.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.5ms preprocess, 123.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/520.jpg: 384x640 1 person, 115.5ms\n",
      "Speed: 0.6ms preprocess, 115.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/440.jpg: 384x640 1 person, 137.7ms\n",
      "Speed: 0.6ms preprocess, 137.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/130.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.7ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/180.jpg: 384x640 1 person, 126.0ms\n",
      "Speed: 0.8ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/590.jpg: 384x640 1 person, 132.5ms\n",
      "Speed: 0.6ms preprocess, 132.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/220.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.8ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/340.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.6ms preprocess, 127.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/630.jpg: 384x640 1 person, 151.5ms\n",
      "Speed: 0.7ms preprocess, 151.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/80.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.7ms preprocess, 115.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/140.jpg: 384x640 2 persons, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/430.jpg: 384x640 1 person, 115.1ms\n",
      "Speed: 0.6ms preprocess, 115.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/550.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/380.jpg: 384x640 1 person, 151.8ms\n",
      "Speed: 0.6ms preprocess, 151.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/40.jpg: 384x640 1 person, 177.4ms\n",
      "Speed: 0.8ms preprocess, 177.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/50.jpg: 384x640 1 person, 159.8ms\n",
      "Speed: 0.7ms preprocess, 159.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/390.jpg: 384x640 1 person, 134.4ms\n",
      "Speed: 0.7ms preprocess, 134.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/540.jpg: 384x640 1 person, 260.5ms\n",
      "Speed: 0.7ms preprocess, 260.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/420.jpg: 384x640 1 person, 189.3ms\n",
      "Speed: 0.7ms preprocess, 189.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/150.jpg: 384x640 1 person, 226.4ms\n",
      "Speed: 0.8ms preprocess, 226.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/620.jpg: 384x640 1 person, 163.1ms\n",
      "Speed: 0.6ms preprocess, 163.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/90.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.8ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/350.jpg: 384x640 1 person, 120.7ms\n",
      "Speed: 0.6ms preprocess, 120.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/230.jpg: 384x640 1 person, 133.0ms\n",
      "Speed: 0.7ms preprocess, 133.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/580.jpg: 384x640 1 person, 136.0ms\n",
      "Speed: 0.6ms preprocess, 136.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/0.jpg: 384x640 1 person, 119.5ms\n",
      "Speed: 0.7ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_03032022_09.mp4/190.jpg: 384x640 1 person, 121.3ms\n",
      "Speed: 0.6ms preprocess, 121.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/610.jpg: 384x640 1 person, 146.9ms\n",
      "Speed: 0.6ms preprocess, 146.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/360.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/200.jpg: 384x640 2 persons, 115.5ms\n",
      "Speed: 0.8ms preprocess, 115.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/980.jpg: 384x640 1 person, 135.8ms\n",
      "Speed: 0.6ms preprocess, 135.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/770.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.6ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1030.jpg: 384x640 1 person, 115.3ms\n",
      "Speed: 0.6ms preprocess, 115.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1150.jpg: 384x640 (no detections), 128.2ms\n",
      "Speed: 0.7ms preprocess, 128.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/60.jpg: 384x640 1 person, 144.4ms\n",
      "Speed: 0.7ms preprocess, 144.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/820.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/940.jpg: 384x640 2 persons, 120.8ms\n",
      "Speed: 0.8ms preprocess, 120.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/570.jpg: 384x640 1 person, 137.0ms\n",
      "Speed: 0.6ms preprocess, 137.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/410.jpg: 384x640 1 person, 130.3ms\n",
      "Speed: 0.8ms preprocess, 130.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/160.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.8ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/170.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.8ms preprocess, 117.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/400.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.5ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/560.jpg: 384x640 1 person, 133.9ms\n",
      "Speed: 0.6ms preprocess, 133.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/950.jpg: 384x640 1 person, 135.9ms\n",
      "Speed: 0.6ms preprocess, 135.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/830.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.8ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/70.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1140.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.6ms preprocess, 127.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1020.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 1.2ms preprocess, 125.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/990.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.6ms preprocess, 123.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/760.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.6ms preprocess, 123.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/210.jpg: 384x640 1 person, 114.8ms\n",
      "Speed: 0.6ms preprocess, 114.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/370.jpg: 384x640 2 persons, 140.3ms\n",
      "Speed: 0.6ms preprocess, 140.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/600.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/840.jpg: 384x640 2 persons, 136.4ms\n",
      "Speed: 0.6ms preprocess, 136.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/920.jpg: 384x640 1 person, 135.4ms\n",
      "Speed: 0.6ms preprocess, 135.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1090.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.6ms preprocess, 118.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/510.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.5ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/470.jpg: 384x640 1 person, 122.5ms\n",
      "Speed: 0.6ms preprocess, 122.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/100.jpg: 384x640 1 person, 128.5ms\n",
      "Speed: 0.6ms preprocess, 128.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/880.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 2.4ms preprocess, 124.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/670.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/300.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/260.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.6ms preprocess, 116.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/710.jpg: 384x640 1 person, 153.3ms\n",
      "Speed: 0.5ms preprocess, 153.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1050.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.7ms preprocess, 123.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1130.jpg: 384x640 (no detections), 116.6ms\n",
      "Speed: 0.5ms preprocess, 116.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1120.jpg: 384x640 (no detections), 129.6ms\n",
      "Speed: 0.6ms preprocess, 129.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1040.jpg: 384x640 1 person, 127.9ms\n",
      "Speed: 0.6ms preprocess, 127.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/700.jpg: 384x640 1 person, 129.5ms\n",
      "Speed: 0.6ms preprocess, 129.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/270.jpg: 384x640 1 person, 133.4ms\n",
      "Speed: 0.6ms preprocess, 133.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/310.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.6ms preprocess, 123.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/890.jpg: 384x640 1 person, 121.4ms\n",
      "Speed: 0.6ms preprocess, 121.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/660.jpg: 384x640 1 person, 133.5ms\n",
      "Speed: 0.5ms preprocess, 133.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/110.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.7ms preprocess, 126.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/460.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.6ms preprocess, 125.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1080.jpg: 384x640 1 person, 139.1ms\n",
      "Speed: 0.6ms preprocess, 139.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/500.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.8ms preprocess, 116.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/930.jpg: 384x640 1 person, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/850.jpg: 384x640 1 person, 139.5ms\n",
      "Speed: 0.5ms preprocess, 139.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/10.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 1.3ms preprocess, 124.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/120.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 0.5ms preprocess, 116.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/450.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.5ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/530.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/900.jpg: 384x640 1 person, 141.4ms\n",
      "Speed: 1.0ms preprocess, 141.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/280.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.8ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/690.jpg: 384x640 1 person, 117.8ms\n",
      "Speed: 0.6ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/860.jpg: 384x640 1 person, 135.5ms\n",
      "Speed: 0.5ms preprocess, 135.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/20.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.7ms preprocess, 120.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/490.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.6ms preprocess, 127.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1110.jpg: 384x640 (no detections), 134.5ms\n",
      "Speed: 0.8ms preprocess, 134.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1070.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/730.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/240.jpg: 384x640 1 person, 138.1ms\n",
      "Speed: 0.6ms preprocess, 138.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/320.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.6ms preprocess, 125.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/650.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.6ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/640.jpg: 384x640 2 persons, 117.3ms\n",
      "Speed: 0.5ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/330.jpg: 384x640 1 person, 135.3ms\n",
      "Speed: 0.6ms preprocess, 135.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/250.jpg: 384x640 1 person, 114.3ms\n",
      "Speed: 0.6ms preprocess, 114.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/720.jpg: 384x640 1 person, 123.9ms\n",
      "Speed: 1.8ms preprocess, 123.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1060.jpg: 384x640 1 person, 133.1ms\n",
      "Speed: 0.6ms preprocess, 133.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/480.jpg: 384x640 1 person, 122.0ms\n",
      "Speed: 0.6ms preprocess, 122.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1100.jpg: 384x640 1 person, 113.5ms\n",
      "Speed: 0.6ms preprocess, 113.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/680.jpg: 384x640 1 person, 112.5ms\n",
      "Speed: 0.5ms preprocess, 112.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/30.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.6ms preprocess, 120.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/870.jpg: 384x640 1 person, 151.6ms\n",
      "Speed: 0.8ms preprocess, 151.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/290.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.7ms preprocess, 118.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/910.jpg: 384x640 2 persons, 130.2ms\n",
      "Speed: 0.6ms preprocess, 130.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/520.jpg: 384x640 1 person, 173.9ms\n",
      "Speed: 0.8ms preprocess, 173.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/440.jpg: 384x640 2 persons, 149.2ms\n",
      "Speed: 0.7ms preprocess, 149.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/130.jpg: 384x640 1 person, 125.8ms\n",
      "Speed: 0.8ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/180.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.7ms preprocess, 125.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/590.jpg: 384x640 1 person, 173.7ms\n",
      "Speed: 0.6ms preprocess, 173.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1010.jpg: 384x640 1 person, 136.4ms\n",
      "Speed: 0.7ms preprocess, 136.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/750.jpg: 384x640 1 person, 146.9ms\n",
      "Speed: 0.8ms preprocess, 146.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/220.jpg: 384x640 1 person, 144.6ms\n",
      "Speed: 0.7ms preprocess, 144.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/340.jpg: 384x640 1 person, 181.5ms\n",
      "Speed: 0.8ms preprocess, 181.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/630.jpg: 384x640 1 person, 137.8ms\n",
      "Speed: 0.8ms preprocess, 137.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/80.jpg: 384x640 1 person, 143.2ms\n",
      "Speed: 0.7ms preprocess, 143.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/140.jpg: 384x640 1 person, 207.9ms\n",
      "Speed: 0.6ms preprocess, 207.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/430.jpg: 384x640 1 person, 143.0ms\n",
      "Speed: 0.8ms preprocess, 143.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/550.jpg: 384x640 1 person, 186.8ms\n",
      "Speed: 0.9ms preprocess, 186.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/790.jpg: 384x640 1 person, 135.6ms\n",
      "Speed: 0.8ms preprocess, 135.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/960.jpg: 384x640 1 person, 126.7ms\n",
      "Speed: 0.9ms preprocess, 126.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/380.jpg: 384x640 1 person, 203.2ms\n",
      "Speed: 0.7ms preprocess, 203.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/800.jpg: 384x640 1 person, 127.5ms\n",
      "Speed: 0.8ms preprocess, 127.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/40.jpg: 384x640 1 person, 127.0ms\n",
      "Speed: 0.8ms preprocess, 127.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/50.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.7ms preprocess, 125.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/810.jpg: 384x640 1 person, 155.1ms\n",
      "Speed: 0.6ms preprocess, 155.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/390.jpg: 384x640 1 person, 138.4ms\n",
      "Speed: 0.7ms preprocess, 138.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/780.jpg: 384x640 1 person, 148.6ms\n",
      "Speed: 0.8ms preprocess, 148.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/970.jpg: 384x640 1 person, 143.4ms\n",
      "Speed: 0.8ms preprocess, 143.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/540.jpg: 384x640 1 person, 117.5ms\n",
      "Speed: 0.6ms preprocess, 117.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/420.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.6ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/150.jpg: 384x640 1 person, 134.7ms\n",
      "Speed: 0.5ms preprocess, 134.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/620.jpg: 384x640 1 person, 117.3ms\n",
      "Speed: 0.6ms preprocess, 117.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/90.jpg: 384x640 1 person, 136.9ms\n",
      "Speed: 0.6ms preprocess, 136.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/350.jpg: 384x640 1 person, 129.7ms\n",
      "Speed: 0.6ms preprocess, 129.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/230.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/740.jpg: 384x640 1 person, 133.9ms\n",
      "Speed: 0.5ms preprocess, 133.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/580.jpg: 384x640 1 person, 131.8ms\n",
      "Speed: 0.6ms preprocess, 131.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/1000.jpg: 384x640 1 person, 124.1ms\n",
      "Speed: 0.6ms preprocess, 124.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/0.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.7ms preprocess, 122.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_1.mp4/190.jpg: 384x640 1 person, 128.1ms\n",
      "Speed: 0.5ms preprocess, 128.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/610.jpg: 384x640 1 person, 126.5ms\n",
      "Speed: 0.8ms preprocess, 126.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/360.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.7ms preprocess, 127.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/200.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.8ms preprocess, 119.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/770.jpg: 384x640 2 persons, 145.7ms\n",
      "Speed: 0.6ms preprocess, 145.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/60.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.5ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/570.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.6ms preprocess, 127.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/410.jpg: 384x640 1 person, 120.9ms\n",
      "Speed: 0.7ms preprocess, 120.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/160.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/170.jpg: 384x640 1 person, 142.0ms\n",
      "Speed: 0.6ms preprocess, 142.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/400.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.7ms preprocess, 124.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/560.jpg: 384x640 1 person, 136.0ms\n",
      "Speed: 0.6ms preprocess, 136.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/70.jpg: 384x640 1 person, 138.0ms\n",
      "Speed: 0.6ms preprocess, 138.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/760.jpg: 384x640 1 person, 129.8ms\n",
      "Speed: 0.8ms preprocess, 129.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/210.jpg: 384x640 1 person, 122.8ms\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/370.jpg: 384x640 1 person, 136.0ms\n",
      "Speed: 0.6ms preprocess, 136.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/600.jpg: 384x640 1 person, 127.0ms\n",
      "Speed: 0.6ms preprocess, 127.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/510.jpg: 384x640 1 person, 125.9ms\n",
      "Speed: 0.6ms preprocess, 125.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/470.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.5ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/100.jpg: 384x640 1 person, 149.5ms\n",
      "Speed: 0.7ms preprocess, 149.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/670.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/300.jpg: 384x640 1 person, 127.2ms\n",
      "Speed: 0.6ms preprocess, 127.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/260.jpg: 384x640 2 persons, 144.5ms\n",
      "Speed: 0.7ms preprocess, 144.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/710.jpg: 384x640 1 person, 127.0ms\n",
      "Speed: 0.8ms preprocess, 127.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/700.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/270.jpg: 384x640 2 persons, 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/310.jpg: 384x640 2 persons, 165.2ms\n",
      "Speed: 0.6ms preprocess, 165.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/660.jpg: 384x640 1 person, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/110.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/460.jpg: 384x640 1 person, 121.5ms\n",
      "Speed: 0.6ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/500.jpg: 384x640 1 person, 135.4ms\n",
      "Speed: 0.7ms preprocess, 135.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/10.jpg: 384x640 1 person, 129.4ms\n",
      "Speed: 0.8ms preprocess, 129.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/120.jpg: 384x640 1 person, 124.6ms\n",
      "Speed: 0.6ms preprocess, 124.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/450.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/530.jpg: 384x640 1 person, 137.3ms\n",
      "Speed: 0.5ms preprocess, 137.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/280.jpg: 384x640 1 person, 131.6ms\n",
      "Speed: 0.7ms preprocess, 131.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/690.jpg: 384x640 1 person, 129.7ms\n",
      "Speed: 0.5ms preprocess, 129.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/20.jpg: 384x640 1 person, 137.0ms\n",
      "Speed: 0.6ms preprocess, 137.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/490.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.6ms preprocess, 118.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/730.jpg: 384x640 1 person, 128.8ms\n",
      "Speed: 0.6ms preprocess, 128.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/240.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/320.jpg: 384x640 1 person, 128.4ms\n",
      "Speed: 0.6ms preprocess, 128.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/650.jpg: 384x640 1 person, 154.4ms\n",
      "Speed: 0.8ms preprocess, 154.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/640.jpg: 384x640 1 person, 130.0ms\n",
      "Speed: 0.8ms preprocess, 130.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/330.jpg: 384x640 1 person, 121.7ms\n",
      "Speed: 0.6ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/250.jpg: 384x640 1 person, 147.4ms\n",
      "Speed: 0.7ms preprocess, 147.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/720.jpg: 384x640 1 person, 133.9ms\n",
      "Speed: 0.6ms preprocess, 133.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/480.jpg: 384x640 1 person, 127.8ms\n",
      "Speed: 0.6ms preprocess, 127.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/680.jpg: 384x640 1 person, 146.7ms\n",
      "Speed: 0.7ms preprocess, 146.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/30.jpg: 384x640 1 person, 122.9ms\n",
      "Speed: 0.6ms preprocess, 122.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/290.jpg: 384x640 1 person, 126.6ms\n",
      "Speed: 0.6ms preprocess, 126.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/520.jpg: 384x640 1 person, 131.6ms\n",
      "Speed: 0.7ms preprocess, 131.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/440.jpg: 384x640 1 person, 137.5ms\n",
      "Speed: 0.6ms preprocess, 137.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/130.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.6ms preprocess, 119.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/180.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.5ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/590.jpg: 384x640 1 person, 142.1ms\n",
      "Speed: 0.5ms preprocess, 142.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/750.jpg: 384x640 1 person, 126.5ms\n",
      "Speed: 0.7ms preprocess, 126.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/220.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.6ms preprocess, 125.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/340.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.5ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/630.jpg: 384x640 1 person, 140.9ms\n",
      "Speed: 0.6ms preprocess, 140.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/80.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.8ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/140.jpg: 384x640 1 person, 127.0ms\n",
      "Speed: 0.5ms preprocess, 127.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/430.jpg: 384x640 1 person, 124.6ms\n",
      "Speed: 0.6ms preprocess, 124.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/550.jpg: 384x640 1 person, 130.3ms\n",
      "Speed: 0.9ms preprocess, 130.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/790.jpg: 384x640 1 person, 121.0ms\n",
      "Speed: 0.6ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/380.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.6ms preprocess, 117.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/800.jpg: 384x640 1 person, 147.0ms\n",
      "Speed: 0.6ms preprocess, 147.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/40.jpg: 384x640 1 person, 127.1ms\n",
      "Speed: 0.7ms preprocess, 127.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/50.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/390.jpg: 384x640 1 person, 134.2ms\n",
      "Speed: 0.6ms preprocess, 134.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/780.jpg: 384x640 1 person, 125.6ms\n",
      "Speed: 0.7ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/540.jpg: 384x640 1 person, 131.9ms\n",
      "Speed: 0.6ms preprocess, 131.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/420.jpg: 384x640 1 person, 119.0ms\n",
      "Speed: 0.7ms preprocess, 119.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/150.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/620.jpg: 384x640 1 person, 136.3ms\n",
      "Speed: 0.5ms preprocess, 136.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/90.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.5ms preprocess, 121.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/350.jpg: 384x640 1 person, 127.7ms\n",
      "Speed: 0.6ms preprocess, 127.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/230.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/740.jpg: 384x640 1 person, 133.6ms\n",
      "Speed: 0.6ms preprocess, 133.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/580.jpg: 384x640 1 person, 129.4ms\n",
      "Speed: 0.6ms preprocess, 129.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/0.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.6ms preprocess, 121.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_2.mp4/190.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.6ms preprocess, 116.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/200.jpg: 384x640 1 person, 139.8ms\n",
      "Speed: 0.5ms preprocess, 139.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/60.jpg: 384x640 1 person, 120.6ms\n",
      "Speed: 0.6ms preprocess, 120.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/160.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.5ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/170.jpg: 384x640 1 person, 126.4ms\n",
      "Speed: 0.6ms preprocess, 126.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/70.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.8ms preprocess, 116.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/210.jpg: 384x640 1 person, 130.5ms\n",
      "Speed: 2.0ms preprocess, 130.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/100.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.7ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/300.jpg: 384x640 1 person, 113.6ms\n",
      "Speed: 0.6ms preprocess, 113.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/260.jpg: 384x640 1 person, 123.8ms\n",
      "Speed: 0.6ms preprocess, 123.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/270.jpg: 384x640 1 person, 138.9ms\n",
      "Speed: 0.6ms preprocess, 138.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/310.jpg: 384x640 1 person, 123.0ms\n",
      "Speed: 0.7ms preprocess, 123.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/110.jpg: 384x640 1 person, 118.7ms\n",
      "Speed: 0.5ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/10.jpg: 384x640 1 person, 134.5ms\n",
      "Speed: 0.5ms preprocess, 134.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/120.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 1.5ms preprocess, 128.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/280.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/20.jpg: 384x640 1 person, 123.7ms\n",
      "Speed: 0.6ms preprocess, 123.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/240.jpg: 384x640 1 person, 138.1ms\n",
      "Speed: 0.5ms preprocess, 138.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/250.jpg: 384x640 1 person, 129.7ms\n",
      "Speed: 0.6ms preprocess, 129.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/30.jpg: 384x640 1 person, 119.8ms\n",
      "Speed: 0.6ms preprocess, 119.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/290.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.5ms preprocess, 119.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/130.jpg: 384x640 1 person, 124.0ms\n",
      "Speed: 0.6ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/180.jpg: 384x640 1 person, 145.8ms\n",
      "Speed: 0.6ms preprocess, 145.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/220.jpg: 384x640 1 person, 119.9ms\n",
      "Speed: 0.6ms preprocess, 119.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/80.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/140.jpg: 384x640 1 person, 119.6ms\n",
      "Speed: 0.6ms preprocess, 119.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/40.jpg: 384x640 1 person, 161.7ms\n",
      "Speed: 0.6ms preprocess, 161.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/50.jpg: 384x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/150.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/90.jpg: 384x640 1 person, 140.2ms\n",
      "Speed: 0.8ms preprocess, 140.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/230.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.7ms preprocess, 122.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/0.jpg: 384x640 2 persons, 120.5ms\n",
      "Speed: 0.6ms preprocess, 120.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_20012022_3.mp4/190.jpg: 384x640 1 person, 148.1ms\n",
      "Speed: 0.6ms preprocess, 148.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/610.jpg: 384x640 1 person, 115.7ms\n",
      "Speed: 0.6ms preprocess, 115.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/360.jpg: 384x640 1 person, 119.7ms\n",
      "Speed: 0.6ms preprocess, 119.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/200.jpg: 384x640 1 person, 133.2ms\n",
      "Speed: 0.6ms preprocess, 133.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/770.jpg: 384x640 (no detections), 130.2ms\n",
      "Speed: 0.7ms preprocess, 130.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/60.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.7ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/820.jpg: 384x640 (no detections), 118.0ms\n",
      "Speed: 0.6ms preprocess, 118.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/570.jpg: 384x640 2 persons, 128.6ms\n",
      "Speed: 0.6ms preprocess, 128.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/410.jpg: 384x640 1 person, 120.4ms\n",
      "Speed: 0.8ms preprocess, 120.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/160.jpg: 384x640 1 person, 112.2ms\n",
      "Speed: 0.5ms preprocess, 112.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/170.jpg: 384x640 1 person, 118.3ms\n",
      "Speed: 0.5ms preprocess, 118.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/400.jpg: 384x640 1 person, 136.5ms\n",
      "Speed: 0.6ms preprocess, 136.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/560.jpg: 384x640 2 persons, 136.5ms\n",
      "Speed: 0.6ms preprocess, 136.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/70.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.6ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/760.jpg: 384x640 1 person, 123.2ms\n",
      "Speed: 0.6ms preprocess, 123.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/210.jpg: 384x640 1 person, 136.6ms\n",
      "Speed: 1.2ms preprocess, 136.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/370.jpg: 384x640 1 person, 125.5ms\n",
      "Speed: 0.6ms preprocess, 125.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/600.jpg: 384x640 1 person, 115.9ms\n",
      "Speed: 0.5ms preprocess, 115.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/510.jpg: 384x640 1 person, 121.9ms\n",
      "Speed: 0.5ms preprocess, 121.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/470.jpg: 384x640 1 person, 142.3ms\n",
      "Speed: 0.7ms preprocess, 142.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/100.jpg: 384x640 1 person, 118.5ms\n",
      "Speed: 0.8ms preprocess, 118.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/670.jpg: 384x640 1 person, 133.0ms\n",
      "Speed: 0.6ms preprocess, 133.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/300.jpg: 384x640 1 person, 129.2ms\n",
      "Speed: 0.6ms preprocess, 129.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/260.jpg: 384x640 1 person, 122.4ms\n",
      "Speed: 0.7ms preprocess, 122.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/710.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.7ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/700.jpg: 384x640 1 person, 134.2ms\n",
      "Speed: 0.6ms preprocess, 134.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/270.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.6ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/310.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.6ms preprocess, 123.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/660.jpg: 384x640 1 person, 137.9ms\n",
      "Speed: 0.5ms preprocess, 137.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/110.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 0.6ms preprocess, 123.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/460.jpg: 384x640 1 person, 126.8ms\n",
      "Speed: 0.6ms preprocess, 126.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/500.jpg: 384x640 2 persons, 133.5ms\n",
      "Speed: 0.6ms preprocess, 133.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/10.jpg: 384x640 1 person, 127.6ms\n",
      "Speed: 0.6ms preprocess, 127.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/120.jpg: 384x640 1 person, 117.7ms\n",
      "Speed: 0.6ms preprocess, 117.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/450.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/530.jpg: 384x640 1 person, 125.4ms\n",
      "Speed: 0.6ms preprocess, 125.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/280.jpg: 384x640 1 person, 155.2ms\n",
      "Speed: 0.8ms preprocess, 155.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/690.jpg: 384x640 1 person, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/20.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.7ms preprocess, 116.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/490.jpg: 384x640 1 person, 123.4ms\n",
      "Speed: 0.6ms preprocess, 123.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/730.jpg: 384x640 1 person, 134.7ms\n",
      "Speed: 0.6ms preprocess, 134.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/240.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.6ms preprocess, 128.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/320.jpg: 384x640 1 person, 119.1ms\n",
      "Speed: 0.7ms preprocess, 119.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/650.jpg: 384x640 1 person, 119.2ms\n",
      "Speed: 0.5ms preprocess, 119.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/640.jpg: 384x640 1 person, 138.4ms\n",
      "Speed: 0.6ms preprocess, 138.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/330.jpg: 384x640 1 person, 124.7ms\n",
      "Speed: 0.6ms preprocess, 124.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/250.jpg: 384x640 1 person, 123.6ms\n",
      "Speed: 0.6ms preprocess, 123.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/720.jpg: 384x640 1 person, 116.8ms\n",
      "Speed: 0.7ms preprocess, 116.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/480.jpg: 384x640 1 person, 121.6ms\n",
      "Speed: 0.5ms preprocess, 121.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/680.jpg: 384x640 1 person, 142.7ms\n",
      "Speed: 0.6ms preprocess, 142.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/30.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/290.jpg: 384x640 1 person, 116.2ms\n",
      "Speed: 0.6ms preprocess, 116.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/520.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/440.jpg: 384x640 1 person, 159.9ms\n",
      "Speed: 0.7ms preprocess, 159.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/130.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/180.jpg: 384x640 1 person, 145.9ms\n",
      "Speed: 0.7ms preprocess, 145.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/590.jpg: 384x640 1 person, 117.4ms\n",
      "Speed: 0.7ms preprocess, 117.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/750.jpg: 384x640 1 person, 124.1ms\n",
      "Speed: 0.6ms preprocess, 124.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/220.jpg: 384x640 1 person, 138.6ms\n",
      "Speed: 0.6ms preprocess, 138.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/340.jpg: 384x640 1 person, 111.3ms\n",
      "Speed: 0.6ms preprocess, 111.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/630.jpg: 384x640 1 person, 118.9ms\n",
      "Speed: 0.5ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/80.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/140.jpg: 384x640 1 person, 168.9ms\n",
      "Speed: 0.6ms preprocess, 168.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/430.jpg: 384x640 1 person, 117.2ms\n",
      "Speed: 0.7ms preprocess, 117.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/550.jpg: 384x640 1 person, 114.9ms\n",
      "Speed: 0.5ms preprocess, 114.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/790.jpg: 384x640 (no detections), 134.3ms\n",
      "Speed: 0.6ms preprocess, 134.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/380.jpg: 384x640 1 person, 128.3ms\n",
      "Speed: 0.6ms preprocess, 128.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/800.jpg: 384x640 (no detections), 119.0ms\n",
      "Speed: 0.7ms preprocess, 119.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/40.jpg: 384x640 1 person, 132.9ms\n",
      "Speed: 0.7ms preprocess, 132.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/50.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.7ms preprocess, 117.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/810.jpg: 384x640 (no detections), 126.5ms\n",
      "Speed: 0.5ms preprocess, 126.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/390.jpg: 384x640 1 person, 152.3ms\n",
      "Speed: 0.8ms preprocess, 152.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/780.jpg: 384x640 1 person, 117.1ms\n",
      "Speed: 0.6ms preprocess, 117.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/540.jpg: 384x640 1 person, 122.1ms\n",
      "Speed: 0.6ms preprocess, 122.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/420.jpg: 384x640 1 person, 140.2ms\n",
      "Speed: 0.6ms preprocess, 140.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/150.jpg: 384x640 1 person, 118.8ms\n",
      "Speed: 0.7ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/620.jpg: 384x640 1 person, 116.3ms\n",
      "Speed: 0.6ms preprocess, 116.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/90.jpg: 384x640 1 person, 121.2ms\n",
      "Speed: 0.5ms preprocess, 121.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/350.jpg: 384x640 1 person, 138.8ms\n",
      "Speed: 0.6ms preprocess, 138.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/230.jpg: 384x640 1 person, 116.9ms\n",
      "Speed: 0.7ms preprocess, 116.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/740.jpg: 384x640 1 person, 131.8ms\n",
      "Speed: 0.5ms preprocess, 131.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/580.jpg: 384x640 1 person, 116.6ms\n",
      "Speed: 0.7ms preprocess, 116.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/0.jpg: 384x640 1 person, 143.4ms\n",
      "Speed: 3.4ms preprocess, 143.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_12012022_2.mp4/190.jpg: 384x640 2 persons, 118.5ms\n",
      "Speed: 0.5ms preprocess, 118.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/360.jpg: 384x640 1 person, 123.5ms\n",
      "Speed: 0.5ms preprocess, 123.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/200.jpg: 384x640 1 person, 126.5ms\n",
      "Speed: 0.6ms preprocess, 126.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/60.jpg: 384x640 3 persons, 124.6ms\n",
      "Speed: 0.7ms preprocess, 124.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/570.jpg: 384x640 2 persons, 118.4ms\n",
      "Speed: 0.6ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/410.jpg: 384x640 1 person, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/160.jpg: 384x640 1 person, 150.9ms\n",
      "Speed: 0.5ms preprocess, 150.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/170.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.6ms preprocess, 122.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/400.jpg: 384x640 1 person, 125.3ms\n",
      "Speed: 0.6ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/560.jpg: 384x640 2 persons, 114.7ms\n",
      "Speed: 0.5ms preprocess, 114.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/70.jpg: 384x640 2 persons, 140.5ms\n",
      "Speed: 0.6ms preprocess, 140.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/210.jpg: 384x640 1 person, 122.3ms\n",
      "Speed: 0.7ms preprocess, 122.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/370.jpg: 384x640 1 person, 116.7ms\n",
      "Speed: 0.6ms preprocess, 116.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/510.jpg: 384x640 2 persons, 139.2ms\n",
      "Speed: 0.6ms preprocess, 139.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/470.jpg: 384x640 2 persons, 117.0ms\n",
      "Speed: 0.6ms preprocess, 117.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/100.jpg: 384x640 3 persons, 138.7ms\n",
      "Speed: 0.8ms preprocess, 138.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/300.jpg: 384x640 1 person, 138.0ms\n",
      "Speed: 0.6ms preprocess, 138.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/260.jpg: 384x640 1 person, 117.6ms\n",
      "Speed: 0.6ms preprocess, 117.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/270.jpg: 384x640 1 person, 124.2ms\n",
      "Speed: 0.6ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/310.jpg: 384x640 1 person, 144.0ms\n",
      "Speed: 0.6ms preprocess, 144.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/110.jpg: 384x640 2 persons, 124.9ms\n",
      "Speed: 0.6ms preprocess, 124.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/460.jpg: 384x640 2 persons, 118.7ms\n",
      "Speed: 0.6ms preprocess, 118.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/500.jpg: 384x640 2 persons, 125.2ms\n",
      "Speed: 0.5ms preprocess, 125.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/10.jpg: 384x640 1 person, 146.9ms\n",
      "Speed: 0.6ms preprocess, 146.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/120.jpg: 384x640 2 persons, 140.4ms\n",
      "Speed: 0.6ms preprocess, 140.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/450.jpg: 384x640 1 person, 125.0ms\n",
      "Speed: 0.6ms preprocess, 125.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/530.jpg: 384x640 2 persons, 148.4ms\n",
      "Speed: 0.6ms preprocess, 148.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n",
      "image 1/1 /Users/aravdhoot/Remote-PD-Detection/frames/MODERATE/moderate_youtube_11012022_2.mp4/280.jpg: 384x640 1 person, 122.6ms\n",
      "Speed: 0.6ms preprocess, 122.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/predict4\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m os\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(destination_path, severity, video), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(frame_path, severity, video)):\n\u001b[0;32m----> 7\u001b[0m     results \u001b[39m=\u001b[39m model(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(frame_path, severity, video, image), save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, show_labels\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, show_conf\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, line_width\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m     \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m results:\n\u001b[1;32m      9\u001b[0m         im_array \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mplot(img\u001b[39m=\u001b[39mwhite_bg, labels\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, boxes\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/engine/model.py:96\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, source\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     95\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(source, stream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/engine/model.py:238\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m prompts \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor, \u001b[39m'\u001b[39m\u001b[39mset_prompts\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/engine/predictor.py:194\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream_inference(source, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/torch/autograd/grad_mode.py:43\u001b[0m, in \u001b[0;36m_DecoratorContextManager._wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[39m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 43\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     45\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/engine/predictor.py:253\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 253\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference(im, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    255\u001b[0m \u001b[39m# Postprocess\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m2\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/engine/predictor.py:133\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minference\u001b[39m(\u001b[39mself\u001b[39m, im, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    131\u001b[0m     visualize \u001b[39m=\u001b[39m increment_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir \u001b[39m/\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mstem,\n\u001b[1;32m    132\u001b[0m                                mkdir\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mvisualize \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_type\u001b[39m.\u001b[39mtensor) \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/nn/autobackend.py:333\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize)\u001b[0m\n\u001b[1;32m    330\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_module:  \u001b[39m# PyTorch\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im, augment\u001b[39m=\u001b[39maugment, visualize\u001b[39m=\u001b[39mvisualize) \u001b[39mif\u001b[39;00m augment \u001b[39mor\u001b[39;00m visualize \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im)\n\u001b[1;32m    334\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit:  \u001b[39m# TorchScript\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/nn/tasks.py:45\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 45\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/nn/tasks.py:62\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_augment(x)\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_once(x, profile, visualize)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/nn/tasks.py:82\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[1;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m---> 82\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[1;32m     83\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/ultralytics/nn/modules/conv.py:42\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fuse\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     41\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x))\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml_env/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(destination_path, exist_ok=True)\n",
    "for severity in os.listdir(frame_path):\n",
    "    os.makedirs(os.path.join(destination_path, severity), exist_ok=True)\n",
    "    for video in os.listdir(os.path.join(frame_path, severity)):\n",
    "        os.makedirs(os.path.join(destination_path, severity, video), exist_ok=True)\n",
    "        for image in os.listdir(os.path.join(frame_path, severity, video)):\n",
    "            results = model(os.path.join(frame_path, severity, video, image), save=True, show_labels=True, show_conf=True, line_width=0)\n",
    "            for r in results:\n",
    "                im_array = r.plot(img=white_bg, labels=False, boxes=False)\n",
    "                im = Image.fromarray(im_array)  \n",
    "                im.save(os.path.join(destination_path, severity, video, image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
